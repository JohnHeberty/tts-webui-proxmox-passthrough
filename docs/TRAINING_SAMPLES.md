# Gera√ß√£o de Samples Durante Treinamento XTTS

## Problema Encontrado: cuFFT Error

Ao tentar gerar samples de √°udio durante o treinamento, encontramos um bug no XTTS:

```
RuntimeError: cuFFT error: CUFFT_INVALID_SIZE
```

### Root Cause

- **Local**: `torch.stft()` dentro de `get_conditioning_latents()`
- **Quando**: Ao carregar XTTS m√∫ltiplas vezes na GPU no mesmo processo
- **Motivo**: Estado corrompido do CUDA ap√≥s treinamento intensivo
- **Arquivo**: `TTS/tts/models/xtts.py` linha 320-365

### Tentativas Falhadas

1. ‚ùå Ajustar API (`audio_path` vs `audio`)
2. ‚ùå Corrigir sample rate (24000 ‚Üí 22050)
3. ‚ùå N√£o carregar checkpoint state_dict
4. ‚ùå Validar propriedades do √°udio de refer√™ncia
5. ‚ùå Usar apenas modelo base

**Todas falharam** - o erro persiste mesmo com modelo base na GPU.

## Solu√ß√£o Implementada: CPU Inference

### Estrat√©gia

Usar **CPU para gera√ß√£o de samples** (workaround do bug cuFFT na GPU):

```python
def generate_sample_audio(...):
    # 1. Carregar XTTS em CPU (n√£o GPU)
    tts = TTS('tts_models/multilingual/multi-dataset/xtts_v2', gpu=False)
    
    # 2. Gerar √°udio normalmente
    wav = tts.tts(text=..., language='pt', speaker_wav=...)
    
    # 3. Salvar e limpar
    sf.write(output_path, wav, 22050)
    del tts
```

### Gerenciamento de VRAM

Fluxo completo no training loop:

```python
# Ap√≥s salvar checkpoint
checkpoint_path = checkpoints_dir / f"checkpoint_epoch_{epoch}.pt"
torch.save({...}, checkpoint_path)

# 1. UNLOAD modelo de treinamento
model = model.cpu()
torch.cuda.empty_cache()

# 2. GERAR sample (em CPU, fun√ß√£o interna carrega TTS)
generate_sample_audio(checkpoint_path, epoch, settings, samples_dir, device)

# 3. RELOAD modelo de treinamento
checkpoint = torch.load(checkpoint_path)
model.load_state_dict(checkpoint['model_state_dict'])
model = model.to(device)
model.train()
```

### Trade-offs

| Aspecto | GPU (quebrado) | CPU (funciona) |
|---------|----------------|----------------|
| **Velocidade** | ~1s | ~12s |
| **cuFFT Error** | ‚ùå Sim | ‚úÖ N√£o |
| **VRAM** | Alta | Baixa |
| **Confiabilidade** | 0% | 100% |

**Decis√£o**: CPU √© **12x mais lento**, mas **funciona perfeitamente**.

## Uso

### Treinar com Samples Autom√°ticos

```bash
# Treinamento normal - samples gerados automaticamente
python3 train/scripts/train_xtts.py

# Teste r√°pido
MAX_TRAIN_SAMPLES=20 NUM_EPOCHS=2 python3 train/scripts/train_xtts.py
```

### Outputs Gerados

```
train/output/samples/
‚îú‚îÄ‚îÄ epoch_1_output.wav      # Sample gerado (s√≠ntese com XTTS)
‚îú‚îÄ‚îÄ epoch_1_reference.wav   # √Åudio de refer√™ncia (copiado)
‚îú‚îÄ‚îÄ epoch_2_output.wav
‚îú‚îÄ‚îÄ epoch_2_reference.wav
‚îî‚îÄ‚îÄ best/
    ‚îú‚îÄ‚îÄ epoch_N_output.wav  # Sample do melhor modelo
    ‚îî‚îÄ‚îÄ epoch_N_reference.wav
```

### Validar Samples

```bash
# Verificar propriedades
file train/output/samples/epoch_1_output.wav
ffprobe train/output/samples/epoch_1_output.wav

# Propriedades esperadas:
# - Sample rate: 22050 Hz
# - Canais: mono
# - Dura√ß√£o: ~7s (texto: "Ol√°, este √© um teste...")
# - Tamanho: ~310KB
```

## Configura√ß√µes

### Desabilitar Samples (se necess√°rio)

Se quiser treinar SEM gerar samples (mais r√°pido):

```python
# Em train/scripts/train_xtts.py, comentar:
# generate_sample_audio(checkpoint_path, epoch, settings, samples_dir, device)
```

### Ajustar Frequ√™ncia

Samples s√£o gerados:
- A cada `save_every_n_epochs` (padr√£o: 1)
- Quando val_loss melhora (best model)

Para mudar frequ√™ncia:

```python
# train/train_settings.py
save_every_n_epochs: int = 5  # Gerar sample a cada 5 √©pocas
```

## Monitoramento

### Logs Durante Gera√ß√£o

```
üíæ Checkpoint salvo: checkpoint_epoch_1.pt
üßπ Liberando VRAM para gera√ß√£o de samples...
   ‚úÖ Modelo de treinamento movido para CPU
üé§ Gerando sample de √°udio em CPU (workaround cuFFT)...
   √âpoca: 1
   Refer√™ncia: audio_00001.wav
   üì• Carregando XTTS em CPU...
   üîä Sintetizando √°udio (CPU - pode demorar)...
 > Processing time: 12.44s
 > Real-time factor: 1.73x
   ‚úÖ Sample gerado: epoch_1_output.wav
   ‚úÖ Refer√™ncia copiada: epoch_1_reference.wav
   üßπ Modelo de infer√™ncia descarregado
üì• Recarregando modelo de treinamento...
   ‚úÖ Modelo de treinamento restaurado na GPU
```

### Tempo Total por Sample

- Unload training model: ~1s
- Carregar XTTS CPU: ~11s
- Gerar √°udio: ~12s
- Reload training model: ~5s
- **Total: ~29s por sample**

### Performance Impact

Para treinamento com 1000 √©pocas:
- Sem samples: ~1h
- Com samples (1 por √©poca): ~1h + 8h = ~9h total
- **Recomenda√ß√£o**: `save_every_n_epochs = 10` (9h ‚Üí 1.8h overhead)

## Troubleshooting

### Sample n√£o gerado

```bash
# Verificar logs
grep "Gerando sample" train_output.log

# Se vazio, verificar:
# 1. epoch % save_every_n_epochs == 0?
# 2. Erro na fun√ß√£o? grep "Erro ao gerar" train_output.log
```

### √Åudio vazio/corrompido

```bash
# Validar arquivo
file train/output/samples/epoch_1_output.wav
# Deve mostrar: "WAVE audio, Microsoft PCM, 16 bit, mono 22050 Hz"

# Se corrompido, verificar:
# 1. √Åudio de refer√™ncia v√°lido?
ls -lh train/data/MyTTSDataset/wavs/audio_00001.wav
# 2. Espa√ßo em disco?
df -h
```

### Processo muito lento

```python
# Op√ß√£o 1: Gerar samples menos frequentes
save_every_n_epochs: int = 10  # ao inv√©s de 1

# Op√ß√£o 2: Desabilitar best_model samples
# Comentar em train_xtts.py:
# generate_sample_audio(best_model_path, ...)

# Op√ß√£o 3: Desabilitar completamente
# Comentar todas chamadas generate_sample_audio()
```

## Limita√ß√µes Conhecidas

1. **N√£o usa pesos do checkpoint**
   - Samples s√£o gerados com modelo BASE XTTS
   - N√£o com os pesos treinados (causaria cuFFT)
   - Serve apenas para validar s√≠ntese funciona

2. **CPU obrigat√≥ria**
   - N√£o h√° solu√ß√£o conhecida para cuFFT na GPU
   - Problema upstream no PyTorch/CUDA

3. **Sem voice cloning do treino**
   - Voice cloning ainda usa √°udio de refer√™ncia do dataset
   - N√£o aplica aprendizado do fine-tuning

## Pr√≥ximos Passos

Para aplicar pesos do checkpoint nos samples:

1. **Op√ß√£o A**: Gerar samples DEPOIS do treino terminar
   ```bash
   # Treinar sem samples (r√°pido)
   python3 train/scripts/train_xtts.py
   
   # Gerar samples offline
   python3 scripts/generate_checkpoint_samples.py --checkpoint checkpoint_epoch_100.pt
   ```

2. **Op√ß√£o B**: Investigar cuFFT bug upstream
   - Reportar issue no reposit√≥rio coqui-ai/TTS
   - Testar com vers√µes diferentes de PyTorch/CUDA
   - Contribuir fix se poss√≠vel

3. **Op√ß√£o C**: Usar modelo diferente
   - F5-TTS n√£o tem esse problema
   - Considerar migrar treinamento

## Refer√™ncias

- **Issue cuFFT**: https://github.com/pytorch/pytorch/issues/91640
- **XTTS Training**: https://tts.readthedocs.io/en/latest/
- **C√≥digo**: `train/scripts/train_xtts.py` linha 421-522
