# Gera√ß√£o de Samples Durante Treinamento XTTS

## Problema Encontrado: cuFFT Error

Ao tentar gerar samples de √°udio durante o treinamento, encontramos um bug persistente no XTTS:

```
RuntimeError: cuFFT error: CUFFT_INVALID_SIZE
```

### Root Cause

- **Local**: `torch.stft()` dentro de `get_conditioning_latents()`
- **Quando**: Ao usar XTTS na GPU neste ambiente espec√≠fico
- **Motivo**: Bug upstream no PyTorch/CUDA/cuFFT (n√£o relacionado ao c√≥digo)
- **Arquivo**: `TTS/tts/models/xtts.py` linha 320-365
- **Persist√™ncia**: Ocorre MESMO em subprocesso limpo isolado

### Tentativas Falhadas

1. ‚ùå Limpar contexto CUDA (empty_cache + synchronize + gc.collect)
2. ‚ùå Subprocesso Python isolado com GPU limpa
3. ‚ùå N√£o carregar checkpoint state_dict
4. ‚ùå Validar e ajustar propriedades do √°udio de refer√™ncia
5. ‚ùå Usar apenas modelo base sem fine-tuning
6. ‚ùå Diferentes sample rates e configura√ß√µes

**Todas falharam** - o erro persiste independentemente da abordagem na GPU.

## Solu√ß√£o Implementada: Subprocesso CPU

### Estrat√©gia

Usar **subprocesso isolado com CPU** para gera√ß√£o de samples:

```python
# Processo principal continua na GPU
# Ao gerar sample:
1. Salvar checkpoint
2. Descarregar modelo de treinamento (GPU ‚Üí CPU)
3. Spawn subprocesso:
   subprocess.run([
       "python3", "generate_sample_subprocess.py",
       "--reference_wav", "audio.wav",
       "--text", "texto do metadata.csv",
       "--output", "epoch_N_output.wav"
   ])
4. Subprocesso:
   - Carrega XTTS em CPU (evita cuFFT)
   - Gera √°udio
   - Salva WAV
   - Exit (mem√≥ria liberada automaticamente)
5. Recarregar modelo de treinamento (CPU ‚Üí GPU)
6. Continuar treinamento
```

### Arquitetura da Solu√ß√£o

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ PROCESSO PRINCIPAL (train_xtts.py)                    ‚îÇ
‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ ‚îÇ TREINAMENTO NA GPU                               ‚îÇ   ‚îÇ
‚îÇ ‚îÇ ‚Ä¢ Modelo XTTS carregado (GPU)                   ‚îÇ   ‚îÇ
‚îÇ ‚îÇ ‚Ä¢ Training loop                                  ‚îÇ   ‚îÇ
‚îÇ ‚îÇ ‚Ä¢ Loss decreasing                                ‚îÇ   ‚îÇ
‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îÇ                     ‚Üì                                   ‚îÇ
‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ ‚îÇ CHECKPOINT SAVE                                  ‚îÇ   ‚îÇ
‚îÇ ‚îÇ ‚Ä¢ Salvar model_state_dict                       ‚îÇ   ‚îÇ
‚îÇ ‚îÇ ‚Ä¢ Salvar optimizer_state_dict                   ‚îÇ   ‚îÇ
‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îÇ                     ‚Üì                                   ‚îÇ
‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ ‚îÇ UNLOAD TRAINING MODEL                           ‚îÇ   ‚îÇ
‚îÇ ‚îÇ ‚Ä¢ model = model.cpu()                           ‚îÇ   ‚îÇ
‚îÇ ‚îÇ ‚Ä¢ torch.cuda.empty_cache()                      ‚îÇ   ‚îÇ
‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îÇ                     ‚Üì                                   ‚îÇ
‚îÇ            subprocess.run([...])                       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                  ‚îÇ
                  ‚Üì
        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
        ‚îÇ SUBPROCESSO (generate_sample_subprocess) ‚îÇ
        ‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
        ‚îÇ ‚îÇ LOAD XTTS (CPU)                    ‚îÇ ‚îÇ
        ‚îÇ ‚îÇ ‚Ä¢ Processo limpo                   ‚îÇ ‚îÇ
        ‚îÇ ‚îÇ ‚Ä¢ gpu=False                        ‚îÇ ‚îÇ
        ‚îÇ ‚îÇ ‚Ä¢ Sem conflito cuFFT               ‚îÇ ‚îÇ
        ‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
        ‚îÇ                 ‚Üì                        ‚îÇ
        ‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
        ‚îÇ ‚îÇ GENERATE AUDIO                      ‚îÇ ‚îÇ
        ‚îÇ ‚îÇ ‚Ä¢ tts.tts(text=..., speaker_wav=...) ‚îÇ ‚îÇ
        ‚îÇ ‚îÇ ‚Ä¢ Usando CPU (~43s)                 ‚îÇ ‚îÇ
        ‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
        ‚îÇ                 ‚Üì                        ‚îÇ
        ‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
        ‚îÇ ‚îÇ SAVE WAV                            ‚îÇ ‚îÇ
        ‚îÇ ‚îÇ ‚Ä¢ sf.write(output.wav, wav, 22050)  ‚îÇ ‚îÇ
        ‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
        ‚îÇ                 ‚Üì                        ‚îÇ
        ‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
        ‚îÇ ‚îÇ EXIT                                ‚îÇ ‚îÇ
        ‚îÇ ‚îÇ ‚Ä¢ del tts                           ‚îÇ ‚îÇ
        ‚îÇ ‚îÇ ‚Ä¢ Mem√≥ria liberada automaticamente  ‚îÇ ‚îÇ
        ‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                        ‚îÇ return code 0
                        ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ PROCESSO PRINCIPAL (continua)                          ‚îÇ
‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ ‚îÇ RELOAD TRAINING MODEL                           ‚îÇ   ‚îÇ
‚îÇ ‚îÇ ‚Ä¢ checkpoint = torch.load(...)                  ‚îÇ   ‚îÇ
‚îÇ ‚îÇ ‚Ä¢ model.load_state_dict(checkpoint['...'])      ‚îÇ   ‚îÇ
‚îÇ ‚îÇ ‚Ä¢ model = model.to(device)                      ‚îÇ   ‚îÇ
‚îÇ ‚îÇ ‚Ä¢ model.train()                                 ‚îÇ   ‚îÇ
‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îÇ                     ‚Üì                                   ‚îÇ
‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ ‚îÇ CONTINUAR TREINAMENTO                           ‚îÇ   ‚îÇ
‚îÇ ‚îÇ ‚Ä¢ Pr√≥xima √©poca                                 ‚îÇ   ‚îÇ
‚îÇ ‚îÇ ‚Ä¢ Estado preservado                             ‚îÇ   ‚îÇ
‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Trade-offs

| Aspecto | GPU (quebrado) | CPU Subprocesso (funciona) |
|---------|----------------|----------------------------|
| **Velocidade** | ~3s | ~43s |
| **cuFFT Error** | ‚ùå Sim | ‚úÖ N√£o |
| **VRAM** | Alta | Nenhuma (usa RAM) |
| **Confiabilidade** | 0% | 100% |
| **Isolamento** | N/A | ‚úÖ Processo separado |
| **Auto-cleanup** | Manual | ‚úÖ Autom√°tico |

**Decis√£o**: CPU √© **14x mais lento**, mas √© a **√∫nica op√ß√£o que funciona** neste ambiente.

## Uso

### Treinar com Samples Autom√°ticos

```bash
# Treinamento normal - samples gerados automaticamente
python3 train/scripts/train_xtts.py

# Teste r√°pido
MAX_TRAIN_SAMPLES=20 NUM_EPOCHS=2 python3 train/scripts/train_xtts.py
```

### Outputs Gerados

```
train/output/samples/
‚îú‚îÄ‚îÄ epoch_1_output.wav      # Sample gerado (s√≠ntese com XTTS)
‚îú‚îÄ‚îÄ epoch_1_reference.wav   # √Åudio de refer√™ncia (copiado)
‚îú‚îÄ‚îÄ epoch_2_output.wav
‚îú‚îÄ‚îÄ epoch_2_reference.wav
‚îî‚îÄ‚îÄ best/
    ‚îú‚îÄ‚îÄ epoch_N_output.wav  # Sample do melhor modelo
    ‚îî‚îÄ‚îÄ epoch_N_reference.wav
```

### Validar Samples

```bash
# Verificar propriedades
file train/output/samples/epoch_1_output.wav
ffprobe train/output/samples/epoch_1_output.wav

# Propriedades esperadas:
# - Sample rate: 22050 Hz
# - Canais: mono
# - Dura√ß√£o: ~7s (texto: "Ol√°, este √© um teste...")
# - Tamanho: ~310KB
```

## Configura√ß√µes

### Desabilitar Samples (se necess√°rio)

Se quiser treinar SEM gerar samples (mais r√°pido):

```python
# Em train/scripts/train_xtts.py, comentar:
# generate_sample_audio(checkpoint_path, epoch, settings, samples_dir, device)
```

### Ajustar Frequ√™ncia

Samples s√£o gerados:
- A cada `save_every_n_epochs` (padr√£o: 1)
- Quando val_loss melhora (best model)

Para mudar frequ√™ncia:

```python
# train/train_settings.py
save_every_n_epochs: int = 5  # Gerar sample a cada 5 √©pocas
```

### Monitoramento

### Logs Durante Gera√ß√£o

```
üíæ Checkpoint salvo: checkpoint_epoch_1.pt
üßπ Liberando VRAM para gera√ß√£o de samples...
   ‚úÖ Modelo de treinamento movido para CPU
   üìù Texto do metadata: 'ah, agora eu estou me ouvindo na tv...'
üé§ Gerando sample de √°udio (subprocesso CPU)...
   √âpoca: 1
   Refer√™ncia: audio_00001.wav
   ‚ö†Ô∏è  Usando CPU - bug cuFFT impede uso da GPU
   üöÄ Iniciando subprocesso...
   
   [SUBPROCESSO]
   üì• Carregando XTTS em CPU...
   üîä Sintetizando √°udio em CPU (mais lento mas evita cuFFT bug)...
    > Processing time: 42.8s
    > Real-time factor: 2.54x
   ‚úÖ Sample gerado: /path/to/epoch_1_output.wav
   
   ‚úÖ Sample gerado: epoch_1_output.wav
   ‚úÖ Refer√™ncia copiada: epoch_1_reference.wav
üì• Recarregando modelo de treinamento...
   ‚úÖ Modelo de treinamento restaurado na GPU
```

### Tempo Total por Sample

- Unload training model: ~1s
- Subprocess overhead: ~2s
- Carregar XTTS CPU: ~11s
- Gerar √°udio: ~30s (depende do tamanho do texto)
- **Total: ~43s por sample**

### Performance Impact

Para treinamento com 1000 √©pocas:
- Sem samples: ~1h
- Com samples (1 por √©poca, 43s cada): ~1h + 12h = ~13h total
- **Recomenda√ß√£o**: `save_every_n_epochs = 10` (13h ‚Üí 2.2h overhead)

## Troubleshooting

### Sample n√£o gerado

```bash
# Verificar logs
grep "Gerando sample" train_output.log

# Se vazio, verificar:
# 1. epoch % save_every_n_epochs == 0?
# 2. Erro na fun√ß√£o? grep "Erro ao gerar" train_output.log
```

### √Åudio vazio/corrompido

```bash
# Validar arquivo
file train/output/samples/epoch_1_output.wav
# Deve mostrar: "WAVE audio, Microsoft PCM, 16 bit, mono 22050 Hz"

# Se corrompido, verificar:
# 1. √Åudio de refer√™ncia v√°lido?
ls -lh train/data/MyTTSDataset/wavs/audio_00001.wav
# 2. Espa√ßo em disco?
df -h
```

### Processo muito lento

```python
# Op√ß√£o 1: Gerar samples menos frequentes
save_every_n_epochs: int = 10  # ao inv√©s de 1

# Op√ß√£o 2: Desabilitar best_model samples
# Comentar em train_xtts.py:
# generate_sample_audio(best_model_path, ...)

# Op√ß√£o 3: Desabilitar completamente
# Comentar todas chamadas generate_sample_audio()
```

## Limita√ß√µes Conhecidas

1. **N√£o usa pesos do checkpoint**
   - Samples s√£o gerados com modelo BASE XTTS
   - N√£o com os pesos treinados (causaria cuFFT)
   - Serve apenas para validar s√≠ntese funciona

2. **CPU obrigat√≥ria**
   - N√£o h√° solu√ß√£o conhecida para cuFFT na GPU
   - Problema upstream no PyTorch/CUDA

3. **Sem voice cloning do treino**
   - Voice cloning ainda usa √°udio de refer√™ncia do dataset
   - N√£o aplica aprendizado do fine-tuning

## Pr√≥ximos Passos

Para aplicar pesos do checkpoint nos samples:

1. **Op√ß√£o A**: Gerar samples DEPOIS do treino terminar
   ```bash
   # Treinar sem samples (r√°pido)
   python3 train/scripts/train_xtts.py
   
   # Gerar samples offline
   python3 scripts/generate_checkpoint_samples.py --checkpoint checkpoint_epoch_100.pt
   ```

2. **Op√ß√£o B**: Investigar cuFFT bug upstream
   - Reportar issue no reposit√≥rio coqui-ai/TTS
   - Testar com vers√µes diferentes de PyTorch/CUDA
   - Contribuir fix se poss√≠vel

3. **Op√ß√£o C**: Usar modelo diferente
   - F5-TTS n√£o tem esse problema
   - Considerar migrar treinamento

## Refer√™ncias

- **Issue cuFFT**: https://github.com/pytorch/pytorch/issues/91640
- **XTTS Training**: https://tts.readthedocs.io/en/latest/
- **C√≥digo**: `train/scripts/train_xtts.py` linha 421-522
