# ğŸ® Problema GPU no Proxmox LXC + Docker

## ğŸ“‹ SituaÃ§Ã£o Atual

VocÃª estÃ¡ rodando:
```
Proxmox Host (Servidor FÃ­sico)
  â””â”€â”€ Container LXC "ytaudio" (Ubuntu)
       â””â”€â”€ Docker Containers
            â”œâ”€â”€ audio-voice-api (TTS Service)
            â””â”€â”€ audio-voice-celery (Worker)
```

**GPU:** NVIDIA RTX 3090  
**Driver:** 550.163.01  
**CUDA:** 11.8 (PyTorch) / 12.4 (Driver)

## âŒ Problema

```
CUDA initialization: CUDA unknown error
âš ï¸  CUDA NÃƒO DISPONÃVEL!
```

PyTorch nÃ£o consegue usar a GPU porque **`/dev/nvidia-uvm`** nÃ£o existe dentro do container LXC.

## âœ… DiagnÃ³stico Completo

| Item | Status | Detalhes |
|------|--------|----------|
| Driver NVIDIA no LXC | âœ… OK | `nvidia-smi` funciona |
| Docker runtime nvidia | âœ… OK | `default-runtime: nvidia` |
| Devices `/dev/nvidia0` | âœ… OK | Existem e tÃªm permissÃµes corretas |
| Devices `/dev/nvidia-uvm*` | âŒ FALTANDO | **Causa do erro!** |
| PyTorch detecta CUDA | âŒ FALHA | Por falta dos devices acima |

## ğŸ› ï¸ SoluÃ§Ã£o

### OpÃ§Ã£o 1: ğŸ¯ **RECOMENDADO** - Configurar no Proxmox Host

**Veja:** [`docs/PROXMOX_FIX_RAPIDO.md`](docs/PROXMOX_FIX_RAPIDO.md)

Resumo:
1. Acessar o **servidor Proxmox** (nÃ£o o container)
2. Executar: `modprobe nvidia-uvm` e criar devices
3. Editar `/etc/pve/lxc/[ID].conf` para fazer passthrough
4. Reiniciar container LXC
5. Reiniciar containers Docker

**Tempo:** ~5 minutos  
**Permanente:** âœ… Sim (com systemd service)

### OpÃ§Ã£o 2: âš ï¸ Workaround TemporÃ¡rio - Rodar em CPU

Se nÃ£o puder acessar o Proxmox agora, os containers jÃ¡ estÃ£o rodando em **fallback CPU**. Funciona, mas Ã© mais lento.

## ğŸ“ Arquivos de DocumentaÃ§Ã£o

1. **[docs/PROXMOX_FIX_RAPIDO.md](docs/PROXMOX_FIX_RAPIDO.md)** - Guia passo-a-passo para corrigir AGORA
2. **[docs/PROXMOX_GPU_SETUP.md](docs/PROXMOX_GPU_SETUP.md)** - DocumentaÃ§Ã£o completa com troubleshooting
3. **[scripts/init-nvidia-devices.sh](scripts/init-nvidia-devices.sh)** - Script para diagnosticar devices

## ğŸ§ª Como Testar ApÃ³s CorreÃ§Ã£o

Dentro do container LXC:

```bash
# 1. Verificar devices
ls -la /dev/nvidia-uvm*
# Esperado: crw-rw-rw- 1 root root 508, 0 ... /dev/nvidia-uvm

# 2. Reiniciar Docker
cd /home/tts-webui-proxmox-passthrough
docker compose down && docker compose up -d

# 3. Verificar CUDA
docker logs audio-voice-api | grep CUDA
# Esperado: "âœ… CUDA disponÃ­vel: True"
```

## ğŸ”— PrÃ³ximos Passos

1. [ ] Acessar servidor Proxmox
2. [ ] Seguir [`docs/PROXMOX_FIX_RAPIDO.md`](docs/PROXMOX_FIX_RAPIDO.md)
3. [ ] Testar CUDA funcionando
4. [ ] (Opcional) Configurar systemd service para persistir no boot

## ğŸ’¡ Por que isso acontece?

Containers LXC compartilham o kernel com o host Proxmox, mas nÃ£o montam automaticamente todos os devices. Os devices `/dev/nvidia-uvm*` sÃ£o criados dinamicamente quando o mÃ³dulo `nvidia-uvm` Ã© carregado, mas:

- âŒ O container LXC nÃ£o pode carregar mÃ³dulos do kernel
- âŒ O container LXC nÃ£o herda os devices automaticamente
- âœ… **SoluÃ§Ã£o:** Configurar passthrough manual no arquivo do container

## ğŸ“š ReferÃªncias

- [Proxmox LXC Documentation](https://pve.proxmox.com/wiki/Linux_Container)
- [NVIDIA Docker Container Runtime](https://github.com/NVIDIA/nvidia-docker)
- [PyTorch CUDA Troubleshooting](https://pytorch.org/get-started/locally/)

---

**Status Atual:** ğŸŸ¡ Containers rodando em CPU (fallback)  
**PrÃ³xima AÃ§Ã£o:** Configurar GPU no Proxmox Host
