# üéØ BUG cuFFT RESOLVIDO: Use Docker!

## üîç Investiga√ß√£o Completa

### Problema Descoberto

Bug **cuFFT CUFFT_INVALID_SIZE** ao sintetizar XTTS na GPU:
- Afeta **ambiente HOST** (PyTorch 2.6+ / CUDA 12.4)
- Afeta tanto **treinamento** quanto **API de produ√ß√£o**
- Ocorre em `torch.stft()` ‚Üí `torchaudio.transforms.Spectrogram`

### Causa Raiz

**Incompatibilidade entre PyTorch 2.6+ e CUDA 12.4** com biblioteca cuFFT.

Bug upstream n√£o presente em PyTorch 2.4.0.

## ‚úÖ SOLU√á√ÉO: Docker

### Ambiente que FUNCIONA

```
PyTorch:  2.4.0+cu118
CUDA:     11.8
Status:   ‚úÖ GPU funciona perfeitamente
```

### Performance

| Opera√ß√£o | Host (CPU) | Docker (GPU) | Speedup |
|----------|-----------|--------------|---------|
| **S√≠ntese XTTS** | ‚ùå Falha | ‚úÖ 5.8s | - |
| **Sample Training** | 43s (CPU) | **5.8s** (GPU) | **7.4x mais r√°pido!** |
| **Treinamento** | ‚úÖ GPU OK | ‚úÖ GPU OK | Igual |

## üöÄ Como Usar

### 1. API em Produ√ß√£o (XTTS + RVC)

```bash
# Iniciar servi√ßos
docker compose -f docker-compose-gpu.yml up -d

# Verificar sa√∫de
docker compose -f docker-compose-gpu.yml ps

# Logs
docker logs -f audio-voice-api
```

**Portas:**
- API: http://localhost:8005
- Docs: http://localhost:8005/docs

**Status Atual:**
- Container: `audio-voice-api` - ‚úÖ HEALTHY
- GPU: ‚úÖ NVIDIA GeForce RTX 3090
- XTTS s√≠ntese: ‚úÖ Funciona na GPU (confirmado por teste)

### 2. Treinamento XTTS

```bash
# Build (primeira vez)
docker compose -f docker-compose-training.yml build

# Treinar com configura√ß√£o personalizada
MAX_TRAIN_SAMPLES=100 NUM_EPOCHS=10 \
  docker compose -f docker-compose-training.yml up

# Ou editar .env:
# MAX_TRAIN_SAMPLES=1000
# NUM_EPOCHS=50
docker compose -f docker-compose-training.yml up
```

**Features:**
- ‚úÖ Treinamento na GPU (RTX 3090)
- ‚úÖ Gera√ß√£o de samples **NA GPU** durante treino (5.8s cada!)
- ‚úÖ TensorBoard autom√°tico (porta 6006)
- ‚úÖ Auto-resume de checkpoints
- ‚úÖ Texto real do `metadata.csv` nos samples

**Outputs:**
- Checkpoints: `train/output/checkpoints/`
- Samples: `train/output/samples/`
- TensorBoard logs: `train/runs/`

### 3. Monitorar TensorBoard

```bash
# Abrir em: http://localhost:6006
# M√©tricas dispon√≠veis:
# - train_loss
# - val_loss  
# - learning_rate
```

## üîß Configura√ß√£o

### Vari√°veis de Ambiente (.env)

```bash
# Treinamento
MAX_TRAIN_SAMPLES=      # Vazio = dataset completo (4429)
NUM_EPOCHS=1000
LOG_EVERY_N_STEPS=10

# API
XTTS_DEVICE=cuda
XTTS_FALLBACK_CPU=true
```

### Limites de Recursos

**API:** (docker-compose-gpu.yml)
- Memory: 12GB limit, 8GB reservado
- GPU: 1x NVIDIA (compartilhado com Celery)

**Training:** (docker-compose-training.yml)
- Memory: 20GB limit, 16GB reservado  
- GPU: 1x NVIDIA (dedicado)

## üìù Teste de Verifica√ß√£o

### Confirmar GPU Funciona

```bash
# Dentro do container API
docker compose -f docker-compose-gpu.yml exec audio-voice-service \
  python3 -c "
import torch
from TTS.api import TTS
print(f'CUDA: {torch.cuda.is_available()}')
print(f'PyTorch: {torch.__version__}')

tts = TTS('tts_models/multilingual/multi-dataset/xtts_v2', gpu=True)
print('‚úÖ XTTS carregado na GPU com sucesso!')
"
```

**Sa√≠da esperada:**
```
CUDA: True
PyTorch: 2.4.0+cu118
‚úÖ XTTS carregado na GPU com sucesso!
```

## ‚ö†Ô∏è Host vs Docker

### N√ÉO use Python host para XTTS!

```bash
# ‚ùå FALHA no host (PyTorch 2.6+cu124)
python3 -m train.scripts.train_xtts
# RuntimeError: cuFFT error: CUFFT_INVALID_SIZE

# ‚úÖ FUNCIONA no Docker (PyTorch 2.4.0+cu118)
docker compose -f docker-compose-training.yml up
# Sample gerado NA GPU: epoch_X_output.wav (5.8s)
```

### C√≥digo Afetado

**Host quebra em:**
- `app/services/xtts_service.py` ‚Üí `synthesize()` 
- `train/scripts/train_xtts.py` ‚Üí `generate_sample_audio()`
- Qualquer chamada `TTS.tts()` na GPU

**Docker funciona em:**
- ‚úÖ Tudo acima

## üéØ Recomenda√ß√µes

### Para Desenvolvimento

1. **API**: Use Docker (`docker-compose-gpu.yml`)
2. **Treinamento**: Use Docker (`docker-compose-training.yml`)
3. **Testes**: Rode dentro dos containers

### Para Produ√ß√£o

1. Deploy via Docker (imagem j√° configurada)
2. Configurar volumes persistentes:
   - `models/` - Modelos treinados
   - `voice_profiles/` - Perfis de voz
   - `uploads/`, `processed/` - Arquivos tempor√°rios
3. Monitoring: TensorBoard, logs, healthchecks

### Evitar

- ‚ùå Rodar XTTS s√≠ntese no ambiente host
- ‚ùå PyTorch 2.6+ com CUDA 12.4 para TTS
- ‚ùå Tentar "consertar" cuFFT com workarounds (n√£o funciona)

## üì¶ Arquivos Docker

### Principais

- `Dockerfile` - Imagem base (PyTorch 2.4.0+cu118)
- `docker-compose-gpu.yml` - API + Celery worker
- `docker-compose-training.yml` - Treinamento XTTS
- `docker-entrypoint.sh` - Script de inicializa√ß√£o

### Build Customizado

Se precisar modificar depend√™ncias:

```bash
# Editar requirements.txt
# Rebuild
docker compose -f docker-compose-gpu.yml build --no-cache

# Restart
docker compose -f docker-compose-gpu.yml up -d
```

## üêõ Troubleshooting

### Permiss√µes

```bash
# Diret√≥rios necess√°rios (host)
mkdir -p train/{logs,runs,output/{checkpoints,samples}}
chmod -R 777 train/{logs,runs,output}
```

### GPU n√£o detectada

```bash
# Verificar driver NVIDIA
nvidia-smi

# Verificar runtime Docker
docker run --rm --gpus all nvidia/cuda:11.8.0-base-ubuntu22.04 nvidia-smi
```

### Container sai com erro

```bash
# Ver logs completos
docker logs xtts-training

# Entrar no container
docker compose -f docker-compose-training.yml run --rm xtts-training bash
```

## üìä Resultados de Testes

### Teste 1: API S√≠ntese (Docker)
```
‚úÖ Modelo: xtts_v2 carregado na GPU
‚úÖ S√≠ntese: 6.03s de √°udio gerado
‚úÖ Tempo: 5.3s (Real-time factor: 0.283)
‚úÖ Sem erros cuFFT
```

### Teste 2: Treinamento (Docker)
```
‚úÖ √âpoca 2 completa
‚úÖ Sample gerado na GPU em 5.8s
‚úÖ Checkpoint salvo
‚úÖ Modelo restaurado na GPU
‚úÖ Sem erros cuFFT
```

### Teste 3: Host (Falha Esperada)
```
‚ùå RuntimeError: cuFFT error: CUFFT_INVALID_SIZE
‚ùå Afeta s√≠ntese XTTS
‚ùå Afeta app e treinamento igualmente
```

## üéì Li√ß√µes Aprendidas

1. **Bug n√£o √© c√≥digo** - √â incompatibilidade PyTorch/CUDA
2. **Docker isola ambiente** - PyTorch 2.4.0 n√£o tem bug
3. **GPU ~7x mais r√°pida** - Samples: 43s CPU ‚Üí 5.8s GPU
4. **App tamb√©m afetado** - N√£o s√≥ treinamento
5. **Solu√ß√£o: containeriza√ß√£o** - N√£o downgrade global

## üìÖ Hist√≥rico

- **2025-12-07**: Descoberto bug cuFFT no host
- **2025-12-07**: Confirmado Docker (PyTorch 2.4.0) funciona
- **2025-12-07**: Treinamento com samples GPU validado
- **2025-12-07**: Documenta√ß√£o completa criada

---

**Status Final:** ‚úÖ **RESOLVIDO VIA DOCKER**

Use os compose files fornecidos para API e treinamento!
