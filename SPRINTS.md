# SPRINT PLAN ‚Äì XTTS-v2 Migration & Cleanup

**Projeto**: Audio Voice Service  
**Objetivo**: Migra√ß√£o 100% XTTS-v2 + limpeza de legado F5-TTS/RVC  
**Metodologia**: Sprints incrementais (1-2 semanas cada)  
**Data**: 2024-12-07

---

## üìä Vis√£o Geral

| Sprint | Tema | Dura√ß√£o | Prioridade | Status |
|--------|------|---------|------------|--------|
| Sprint 0 | Quick Wins & Blockers | 2 dias | üî¥ CRITICAL | üìã Planejada |
| Sprint 1 | Limpeza F5-TTS/RVC | 1 semana | üî¥ HIGH | üìã Planejada |
| Sprint 2 | Ambiente Python Limpo | 1 semana | üî¥ HIGH | üìã Planejada |
| Sprint 3 | Centraliza√ß√£o de Configs | 1 semana | üü° MEDIUM | üìã Planejada |
| Sprint 4 | Pipeline de Dataset na WebUI | 2 semanas | üü° MEDIUM | üìã Planejada |
| Sprint 5 | Integra√ß√£o Checkpoints + Samples | 1 semana | üü° MEDIUM | üìã Planejada |
| Sprint 6 | Otimiza√ß√£o de Qualidade XTTS | 2 semanas | üü¢ LOW | üìã Planejada |
| Sprint 7 | Hardening & Observabilidade | 1 semana | üü¢ LOW | üìã Planejada |

**Total estimado**: ~10 semanas (2.5 meses)

---

## Sprint 0 ‚Äì Quick Wins & Blockers üöÄ

**Dura√ß√£o**: 2 dias  
**Objetivo**: Resolver problemas cr√≠ticos que bloqueiam uso imediato  
**Owner**: Tech Lead + 1 Dev

### Escopo

Corrigir bugs que impedem WebUI de funcionar corretamente.

### Tarefas

#### ‚úÖ Task 0.1: Fix extens√£o de checkpoint (.pt vs .pth)
**Prioridade**: üî¥ BLOCKER  
**Tempo estimado**: 30 minutos  
**Arquivos**:
- `app/training_api.py` (linha ~499)

**Mudan√ßa**:
```python
# Fun√ß√£o _scan_checkpoint_dir
# ANTES:
for ckpt_file in checkpoint_dir.glob("*.pth"):

# DEPOIS:
for ckpt_file in checkpoint_dir.glob("*.pt"):
```

**Teste**:
1. Rodar treino: `python3 -m train.scripts.train_xtts`
2. Abrir WebUI ‚Üí Training ‚Üí Checkpoints
3. Verificar que checkpoints aparecem na lista

---

#### ‚úÖ Task 0.2: Criar endpoint para listar samples de √°udio
**Prioridade**: üî¥ HIGH  
**Tempo estimado**: 2 horas  
**Arquivos**:
- `app/training_api.py` (novo endpoint)
- `app/webui/assets/js/app.js` (fetch)
- `app/webui/index.html` (UI)

**Implementa√ß√£o**:
```python
# Em app/training_api.py
@router.get("/samples")
async def list_samples(model_name: Optional[str] = None):
    """List training samples (epoch_N_output.wav)"""
    try:
        samples = []
        samples_root = Path("train/output/samples")
        
        if samples_root.exists():
            for wav_file in sorted(samples_root.glob("epoch_*_output.wav")):
                epoch_match = re.search(r"epoch_(\d+)", wav_file.stem)
                epoch = int(epoch_match.group(1)) if epoch_match else 0
                
                samples.append({
                    "epoch": epoch,
                    "path": f"/static/samples/{wav_file.name}",
                    "filename": wav_file.name,
                    "size_mb": round(wav_file.stat().st_size / 1024 / 1024, 2)
                })
        
        samples.sort(key=lambda x: x["epoch"], reverse=True)
        return samples
    except Exception as e:
        raise HTTPException(500, str(e))
```

**WebUI (app.js)**:
```javascript
async loadTrainingSamples() {
    const response = await this.api('/training/samples');
    const samples = await response.json();
    
    const container = document.getElementById('training-samples');
    container.innerHTML = samples.map(s => `
        <div class="sample-item">
            <span>Epoch ${s.epoch}</span>
            <audio controls src="${s.path}"></audio>
        </div>
    `).join('');
}
```

**Teste**:
1. Treinar 2 epochs
2. Abrir WebUI ‚Üí Training
3. Verificar que aparece player de √°udio para cada √©poca

---

#### ‚úÖ Task 0.3: Mount samples folder como static
**Prioridade**: üî¥ HIGH  
**Tempo estimado**: 15 minutos  
**Arquivos**:
- `app/main.py`

**Mudan√ßa**:
```python
# Em app/main.py, ap√≥s mount de /webui
app.mount("/static/samples", StaticFiles(directory="train/output/samples"), name="samples")
```

---

### Crit√©rios de Aceita√ß√£o

- [x] WebUI lista checkpoints gerados pelo treino
- [x] WebUI mostra samples de √°udio de cada √©poca
- [x] √Åudio toca direto no browser

### Depend√™ncias

Nenhuma

---

## Sprint 1 ‚Äì Limpeza F5-TTS/RVC üßπ

**Dura√ß√£o**: 1 semana  
**Objetivo**: Remover 100% de refer√™ncias a F5-TTS e RVC  
**Owner**: 2 Devs

### Escopo

Limpar c√≥digo, docs, WebUI e configs de todo legado F5-TTS e RVC.

### Tarefas

#### üìù Task 1.1: Auditoria completa de refer√™ncias
**Tempo**: 2 horas  
**A√ß√£o**:
```bash
# Buscar todas as refs
grep -r "f5-tts\|f5tts\|F5TTS\|F5-TTS" . --exclude-dir=node_modules > refs_f5.txt
grep -r "rvc\|RVC" . --exclude-dir=node_modules > refs_rvc.txt

# Revisar e classificar:
# - DELETE: c√≥digo/docs a remover
# - ARCHIVE: docs hist√≥ricos (mover para docs/archive/)
# - MARK: manter mas marcar como "removed in v2.0"
```

---

#### üìÑ Task 1.2: Limpar documenta√ß√£o
**Tempo**: 3 horas  
**Arquivos**:
- `docs/LOW_VRAM.md`
- `docs/API_PARAMETERS.md`
- `docs/ARCHITECTURE.md`
- `docs/README.md`
- `docs/V2_RELEASE_NOTES.md`

**A√ß√µes**:
1. Adicionar banner no topo de cada doc:
   ```markdown
   > ‚ö†Ô∏è **ATEN√á√ÉO**: F5-TTS e RVC foram removidos em v2.0. Este projeto usa exclusivamente XTTS-v2.
   ```

2. Se√ß√µes espec√≠ficas:
   - `docs/LOW_VRAM.md`: Remover linhas 22, 30, 32, 91, 187+
   - `docs/API_PARAMETERS.md`: Remover linhas 15, 43, 44
   - `docs/ARCHITECTURE.md`: Remover se√ß√µes RVC (linhas 29-31, 47, 49, 55-56)
   - `docs/README.md`: Remover se√ß√£o "RVC Voice Conversion" (linhas 148-151)

3. Criar `docs/archive/F5_RVC_LEGACY.md` com hist√≥rico

---

#### üé® Task 1.3: Limpar WebUI
**Tempo**: 2 horas  
**Arquivos**:
- `app/webui/index.html`
- `app/webui/assets/js/app.js`

**Mudan√ßas**:
1. `index.html` linha 56: **Remover aba "Modelos RVC"**
2. `app.js`: Remover fun√ß√µes:
   - `loadRVCModels()`
   - `uploadRVCModel()`
   - Qualquer outra ref a RVC

3. Verificar CSS/assets relacionados

---

#### üê≥ Task 1.4: Limpar Dockerfile
**Tempo**: 30 minutos  
**Arquivo**: `Dockerfile`

**Mudan√ßa**:
```dockerfile
# Linha 84 - REMOVER /app/models/rvc
# ANTES:
RUN mkdir -p /app/uploads /app/processed /app/temp \
    /app/voice_profiles /app/models /app/models/f5tts /app/models/whisper /app/models/rvc \
    /app/logs

# DEPOIS:
RUN mkdir -p /app/uploads /app/processed /app/temp \
    /app/voice_profiles /app/models /app/models/whisper /app/logs
```

---

#### üîß Task 1.5: Remover symlinks F5-TTS em Python global
**Tempo**: 30 minutos  
**A√ß√£o**:
```bash
chmod +x REMOVE_F5_SYMLINKS.sh
./REMOVE_F5_SYMLINKS.sh
# Seguir prompts interativos, confirmar remo√ß√µes
```

---

#### üóëÔ∏è Task 1.6: Remover symlink /runs
**Tempo**: 15 minutos  
**A√ß√£o**:
```bash
cd /home/tts-webui-proxmox-passthrough
rm runs  # √â symlink para train/runs
```

**Atualizar refs**:
- Buscar `"/runs"` ou `"runs/"` no c√≥digo
- Trocar por `"train/runs"`

---

### Crit√©rios de Aceita√ß√£o

- [x] Zero men√ß√µes a F5-TTS/RVC em c√≥digo Python ativo
- [x] Docs marcados como "removed" ou arquivados
- [x] WebUI sem aba RVC
- [x] Dockerfile n√£o cria pastas F5/RVC
- [x] Symlinks removidos

### Depend√™ncias

Nenhuma

---

## Sprint 2 ‚Äì Ambiente Python Limpo üêç

**Dura√ß√£o**: 1 semana  
**Objetivo**: Migrar de Python global para venv isolado  
**Owner**: DevOps + 1 Dev

### Escopo

Criar ambiente reproduz√≠vel, limpo e versionado.

### Tarefas

#### üî® Task 2.1: Criar venv no projeto
**Tempo**: 1 hora  
**A√ß√£o**:
```bash
cd /home/tts-webui-proxmox-passthrough

# Criar venv
python3.11 -m venv venv

# Ativar
source venv/bin/activate

# Upgrade pip
pip install --upgrade pip

# Instalar depend√™ncias
pip install -r requirements.txt -c constraints.txt

# Salvar freeze exato
pip freeze > requirements-lock.txt
```

---

#### üê≥ Task 2.2: Adaptar Dockerfile para usar venv
**Tempo**: 2 horas  
**Arquivo**: `Dockerfile`

**Nova estrat√©gia (multi-stage)**:
```dockerfile
# Stage 1: Build venv
FROM nvidia/cuda:11.8.0-cudnn8-runtime-ubuntu22.04 AS builder

RUN apt-get update && apt-get install -y python3.11 python3.11-venv
WORKDIR /app

COPY requirements.txt constraints.txt ./
RUN python3.11 -m venv /opt/venv
ENV PATH="/opt/venv/bin:$PATH"
RUN pip install --upgrade pip && \
    pip install -r requirements.txt -c constraints.txt

# Stage 2: Runtime
FROM nvidia/cuda:11.8.0-cudnn8-runtime-ubuntu22.04

RUN apt-get update && apt-get install -y python3.11 ffmpeg libsndfile1
COPY --from=builder /opt/venv /opt/venv

ENV PATH="/opt/venv/bin:$PATH"
WORKDIR /app

COPY . .
CMD ["python", "run.py"]
```

**Benef√≠cios**:
- Imagem final menor (sem build tools)
- Venv isolado e reproduz√≠vel
- Cache de layers otimizado

---

#### üìú Task 2.3: Atualizar scripts para usar venv
**Tempo**: 1 hora  
**Arquivos**: `scripts/*.sh`, shebang em Python scripts

**Exemplo**:
```bash
# scripts/validate-gpu.sh
#!/bin/bash
source /home/tts-webui-proxmox-passthrough/venv/bin/activate
python -c "import torch; print(torch.cuda.is_available())"
```

**Python scripts** (train/scripts/*.py):
```python
#!/home/tts-webui-proxmox-passthrough/venv/bin/python
# Ou usar /usr/bin/env python se venv ativo
```

---

#### üìã Task 2.4: Documentar setup de venv
**Tempo**: 1 hora  
**Arquivo**: `docs/DEVELOPMENT_SETUP.md`

**Conte√∫do**:
```markdown
# Development Setup

## Prerequisites
- Python 3.11
- CUDA 11.8+ (for GPU support)
- 16GB RAM, 8GB VRAM recommended

## Setup Virtual Environment

1. Create venv:
   ```bash
   python3.11 -m venv venv
   source venv/bin/activate
   ```

2. Install dependencies:
   ```bash
   pip install --upgrade pip
   pip install -r requirements.txt -c constraints.txt
   ```

3. Verify installation:
   ```bash
   python -c "import torch; print(torch.cuda.is_available())"
   ```

## Running the Service

### Development (local)
```bash
source venv/bin/activate
python run.py
```

### Production (Docker)
```bash
docker-compose up --build
```
```

---

#### üß™ Task 2.5: Testar tudo com venv
**Tempo**: 2 horas  
**Checklist**:
- [ ] API inicia sem erros
- [ ] Inference funciona (TTS b√°sico)
- [ ] Treino funciona (1 epoch teste)
- [ ] WebUI acessa API corretamente
- [ ] Celery worker conecta e processa jobs

---

#### üóëÔ∏è Task 2.6: (Opcional) Limpar Python global
**Tempo**: 30 minutos  
**A√ß√£o**: 
```bash
# CUIDADO: S√≥ fazer se n√£o houver outros projetos!
pip freeze > /tmp/global-packages.txt
pip uninstall -y -r /tmp/global-packages.txt

# Ou simplesmente n√£o usar mais (venv ativo sempre)
```

---

### Crit√©rios de Aceita√ß√£o

- [x] Venv criado e funcional
- [x] Dockerfile usa venv isolado
- [x] Scripts usam venv
- [x] Docs atualizados
- [x] Tudo funciona igual (ou melhor) que antes

### Depend√™ncias

Nenhuma (pode rodar em paralelo com Sprint 1)

---

## Sprint 3 ‚Äì Centraliza√ß√£o de Configs ‚öôÔ∏è

**Dura√ß√£o**: 1 semana  
**Objetivo**: DRY - fonte √∫nica de verdade para configs  
**Owner**: 1 Dev Senior

### Escopo

Eliminar duplica√ß√£o de configura√ß√µes entre `/app`, `/train` e `.env`.

### Tarefas

#### üìê Task 3.1: An√°lise de configs duplicadas
**Tempo**: 2 horas  
**A√ß√£o**:
1. Listar todas as vari√°veis de ambiente usadas:
   - `grep -r "os.getenv\|os.environ" app/ train/`
   - `grep -r "Field(.*env=" app/ train/`

2. Criar planilha:
   | Vari√°vel | .env | train/.env | app/settings.py | train/env_config.py | Conflito? |
   |----------|------|------------|-----------------|---------------------|-----------|
   | MAX_TRAIN_SAMPLES | ‚úÖ | ‚úÖ | ‚ùå | ‚úÖ | Sim |

---

#### üèóÔ∏è Task 3.2: Criar config central
**Tempo**: 4 horas  
**Novo arquivo**: `config/settings.py`

**Estrutura**:
```python
from pathlib import Path
from typing import Optional
from pydantic_settings import BaseSettings, SettingsConfigDict

class GlobalSettings(BaseSettings):
    """Configura√ß√µes compartilhadas entre /app e /train"""
    
    model_config = SettingsConfigDict(
        env_file=".env",
        env_file_encoding="utf-8",
        extra="ignore"
    )
    
    # === Paths ===
    project_root: Path = Path(__file__).parent.parent
    data_dir: Path = Path("data")
    models_dir: Path = Path("models")
    train_dir: Path = Path("train")
    
    @property
    def train_output_dir(self) -> Path:
        return self.train_dir / "output"
    
    @property
    def train_checkpoints_dir(self) -> Path:
        return self.train_output_dir / "checkpoints"
    
    # === Training ===
    max_train_samples: Optional[int] = None
    num_epochs: int = 1000
    log_every_n_steps: int = 10
    
    # === XTTS ===
    xtts_model_name: str = "tts_models/multilingual/multi-dataset/xtts_v2"
    xtts_device: str = "cuda"
    
    # === Whisper ===
    whisper_model: str = "base"
    whisper_num_workers: int = 4

_settings = None

def get_settings() -> GlobalSettings:
    global _settings
    if _settings is None:
        _settings = GlobalSettings()
    return _settings
```

---

#### üîÑ Task 3.3: Migrar app/settings.py para usar central
**Tempo**: 2 horas  
**Arquivo**: `app/settings.py`

**Antes**:
```python
class Settings(BaseSettings):
    xtts_model_name: str = "tts_models/..."
    # ... muitas vari√°veis
```

**Depois**:
```python
from config.settings import get_settings as get_global_settings

class AppSettings(BaseSettings):
    """Settings espec√≠ficos da API"""
    # Herda de global
    _global = get_global_settings()
    
    # Sobrescreve apenas o que √© espec√≠fico da API
    port: int = 8005
    debug: bool = False
```

---

#### üîÑ Task 3.4: Migrar train/env_config.py para usar central
**Tempo**: 2 horas  
**Arquivo**: `train/env_config.py`

**Mudan√ßa**:
```python
from config.settings import get_settings

settings = get_settings()

# Expor como antes para compatibilidade
TRAIN_ROOT = settings.train_dir
OUTPUT_DIR = settings.train_output_dir
MAX_TRAIN_SAMPLES = settings.max_train_samples
```

---

#### üìÑ Task 3.5: Atualizar .env.example
**Tempo**: 1 hora  
**A√ß√£o**:
- Remover duplicatas
- Organizar por se√ß√µes claras
- Adicionar coment√°rios explicativos

---

#### üß™ Task 3.6: Testar configs centralizadas
**Tempo**: 2 horas  
**Teste**:
1. Mudar `MAX_TRAIN_SAMPLES` em `.env`
2. Rodar treino: verificar que usa valor correto
3. API: verificar que tamb√©m usa (se aplic√°vel)

---

### Crit√©rios de Aceita√ß√£o

- [x] Uma √∫nica fonte de verdade: `config/settings.py`
- [x] Zero duplica√ß√£o de vari√°veis
- [x] `.env` limpo e organizado
- [x] App e Train usam mesma config

### Depend√™ncias

Sprint 2 (venv) recomendado antes

---

## Sprint 4 ‚Äì Pipeline de Dataset na WebUI üé®

**Dura√ß√£o**: 2 semanas  
**Objetivo**: Tornar prepara√ß√£o de dataset user-friendly  
**Owner**: 1 Frontend + 1 Backend Dev

### Escopo

Adicionar se√ß√£o na WebUI para executar pipeline de dataset:
1. Download YouTube
2. Segmenta√ß√£o
3. Transcri√ß√£o
4. Build dataset LJS

### Tarefas

#### üé® Task 4.1: Design UI de pipeline
**Tempo**: 4 horas  
**Deliverable**: Mockup ou wireframe

**Se√ß√µes**:
1. **Step 1: Download**
   - Textarea para URLs (uma por linha)
   - Bot√£o "Download"
   - Progress bar

2. **Step 2: Segment**
   - Slider min/max duration
   - Slider VAD threshold
   - Bot√£o "Segment"

3. **Step 3: Transcribe**
   - Select Whisper model (base/small/medium)
   - Checkbox "parallel mode"
   - Bot√£o "Transcribe"

4. **Step 4: Build Dataset**
   - Input dataset name
   - Bot√£o "Build"

5. **Status**
   - Real-time logs
   - Files count
   - Total duration

---

#### üîß Task 4.2: Backend - WebSocket para logs
**Tempo**: 6 horas  
**Arquivo**: `app/training_api.py`

**Implementa√ß√£o**:
```python
from fastapi import WebSocket
import asyncio

@router.websocket("/ws/pipeline")
async def pipeline_logs_ws(websocket: WebSocket):
    await websocket.accept()
    
    # Stream logs from subprocess
    process = training_state["process"]
    while process and process.poll() is None:
        line = process.stdout.readline()
        if line:
            await websocket.send_json({"log": line})
        await asyncio.sleep(0.1)
    
    await websocket.close()
```

---

#### üé® Task 4.3: Frontend - UI implementation
**Tempo**: 8 horas  
**Arquivos**:
- `app/webui/index.html` (nova se√ß√£o)
- `app/webui/assets/js/app.js` (l√≥gica)
- `app/webui/assets/css/styles.css` (estilo)

**Exemplo (HTML)**:
```html
<section id="section-dataset-pipeline">
    <h1>Dataset Pipeline</h1>
    
    <div class="card">
        <h3>Step 1: Download YouTube</h3>
        <textarea id="youtube-urls" rows="5"></textarea>
        <button onclick="app.downloadYouTube()">Download</button>
    </div>
    
    <div class="card">
        <h3>Step 2: Segment Audio</h3>
        <input type="range" id="min-duration" min="3" max="15" value="7">
        <button onclick="app.segmentAudio()">Segment</button>
    </div>
    
    <!-- ... Steps 3-4 -->
    
    <div class="card">
        <h3>Logs</h3>
        <pre id="pipeline-logs"></pre>
    </div>
</section>
```

**JS (WebSocket)**:
```javascript
connectPipelineWebSocket() {
    const ws = new WebSocket(`ws://${window.location.host}/training/ws/pipeline`);
    
    ws.onmessage = (event) => {
        const data = JSON.parse(event.data);
        const logsEl = document.getElementById('pipeline-logs');
        logsEl.textContent += data.log + '\n';
        logsEl.scrollTop = logsEl.scrollHeight;
    };
}
```

---

#### üß™ Task 4.4: Testes E2E
**Tempo**: 4 horas  
**Casos**:
1. Download 1 v√≠deo curto (5min)
2. Segmentar ‚Üí verificar arquivos gerados
3. Transcrever ‚Üí verificar metadata.csv
4. Build dataset ‚Üí verificar estrutura LJS

---

### Crit√©rios de Aceita√ß√£o

- [x] WebUI tem se√ß√£o "Dataset Pipeline"
- [x] Usu√°rio executa pipeline sem CLI
- [x] Logs em tempo real via WebSocket
- [x] Dataset final pronto para treino

### Depend√™ncias

Sprint 0 (samples fix) e Sprint 3 (configs)

---

## Sprint 5 ‚Äì Integra√ß√£o Checkpoints + Samples üìä

**Dura√ß√£o**: 1 semana  
**Objetivo**: WebUI mostra checkpoints E samples side-by-side  
**Owner**: 1 Frontend Dev

### Escopo

Melhorar UX da aba Training com:
- Lista de checkpoints
- Samples de cada √©poca
- A/B test: base vs finetuned

### Tarefas

#### üé® Task 5.1: Redesign se√ß√£o Training
**Tempo**: 3 horas  
**Mockup**: Layout em 3 colunas
- Col 1: Checkpoints list
- Col 2: Samples (√°udio players)
- Col 3: Inference test

---

#### üîß Task 5.2: Endpoint /training/checkpoint-details
**Tempo**: 2 horas  
**Arquivo**: `app/training_api.py`

**Endpoint**:
```python
@router.get("/checkpoint/{checkpoint_id}/details")
async def get_checkpoint_details(checkpoint_id: str):
    """Get checkpoint with related samples"""
    ckpt_path = Path(checkpoint_id)
    epoch = extract_epoch(ckpt_path.stem)
    
    # Find related samples
    samples_dir = Path("train/output/samples")
    samples = list(samples_dir.glob(f"epoch_{epoch}_*.wav"))
    
    return {
        "checkpoint": {
            "path": str(ckpt_path),
            "epoch": epoch,
            "size_mb": ckpt_path.stat().st_size / 1024 / 1024
        },
        "samples": [
            {
                "type": "output" if "output" in s.name else "reference",
                "path": f"/static/samples/{s.name}"
            }
            for s in samples
        ]
    }
```

---

#### üé® Task 5.3: Frontend - Checkpoint card com samples
**Tempo**: 4 horas  
**Componente**:
```javascript
async renderCheckpointCard(checkpoint) {
    const details = await this.api(`/training/checkpoint/${checkpoint.path}/details`);
    
    return `
        <div class="checkpoint-card">
            <h4>Epoch ${details.checkpoint.epoch}</h4>
            <p>${details.checkpoint.size_mb} MB</p>
            
            <div class="samples">
                ${details.samples.map(s => `
                    <div>
                        <label>${s.type}</label>
                        <audio controls src="${s.path}"></audio>
                    </div>
                `).join('')}
            </div>
            
            <button onclick="app.loadCheckpoint('${checkpoint.path}')">
                Load for Inference
            </button>
        </div>
    `;
}
```

---

#### üß™ Task 5.4: A/B Test UI
**Tempo**: 3 horas  
**Feature**: Comparar base model vs finetuned

**UI**:
```html
<div id="ab-test">
    <h3>A/B Comparison</h3>
    <input id="ab-text" placeholder="Texto para testar...">
    <button onclick="app.runABTest()">Generate Both</button>
    
    <div class="ab-results">
        <div>
            <h4>Base Model</h4>
            <audio id="ab-base" controls></audio>
        </div>
        <div>
            <h4>Finetuned (Epoch ${epoch})</h4>
            <audio id="ab-finetuned" controls></audio>
        </div>
    </div>
</div>
```

---

### Crit√©rios de Aceita√ß√£o

- [x] Checkpoints listados com samples lado-a-lado
- [x] √Åudio toca direto no browser
- [x] A/B test funciona
- [x] UX intuitiva e r√°pida

### Depend√™ncias

Sprint 0 (samples endpoint)

---

## Sprint 6 ‚Äì Otimiza√ß√£o de Qualidade XTTS üéØ

**Dura√ß√£o**: 2 semanas  
**Objetivo**: Melhorar timbre e naturalidade do √°udio gerado  
**Owner**: ML Engineer + 1 Dev

### Escopo

T√©cnicas para melhorar qualidade:
1. Implementar LoRA
2. Grid search de hiperpar√¢metros
3. Melhorar qualidade de dataset
4. Data augmentation

### Tarefas

#### üî¨ Task 6.1: Pesquisa - Target modules para LoRA no XTTS
**Tempo**: 4 horas  
**A√ß√£o**:
1. Ler c√≥digo XTTS-v2 (Coqui TTS)
2. Identificar layers trein√°veis (attention, feedforward)
3. Testar com `peft` library

**Resultado esperado**:
```python
# Em train/scripts/train_xtts.py
from peft import LoraConfig, get_peft_model

lora_config = LoraConfig(
    r=8,
    lora_alpha=16,
    target_modules=["q_proj", "v_proj", "out_proj"],  # DESCOBRIR
    lora_dropout=0.1,
    bias="none"
)

model = get_peft_model(base_model, lora_config)
```

---

#### üîß Task 6.2: Implementar LoRA no treino
**Tempo**: 6 horas  
**Arquivo**: `train/scripts/train_xtts.py`

**Mudan√ßas**:
1. Descomentar c√≥digo LoRA
2. Ajustar target_modules baseado em Task 6.1
3. Testar treino com batch_size maior (4 ‚Üí 8)

---

#### üß™ Task 6.3: Grid search de hiperpar√¢metros
**Tempo**: 8 horas (+ tempo de treino)  
**Novo arquivo**: `train/scripts/hyperparameter_search.py`

**Par√¢metros a testar**:
```python
param_grid = {
    "learning_rate": [5e-6, 1e-5, 5e-5],
    "batch_size": [4, 8],
    "lora_rank": [4, 8, 16],
    "num_epochs": [100, 500]
}
```

**M√©trica**: Loss no validation set + avalia√ß√£o humana (MOS)

---

#### üéß Task 6.4: Filtro de qualidade de dataset
**Tempo**: 6 horas  
**Arquivo**: `train/scripts/segment_audio.py`

**Adicionar**:
1. **SNR filter**: Descartar segmentos com ru√≠do alto
   ```python
   import noisereduce as nr
   
   def calculate_snr(audio, sr):
       # Signal-to-Noise Ratio
       signal_power = np.mean(audio ** 2)
       noise = nr.reduce_noise(y=audio, sr=sr)
       noise_power = np.mean((audio - noise) ** 2)
       return 10 * np.log10(signal_power / noise_power)
   ```

2. **Speaker diarization**: Descartar segmentos com m√∫ltiplos speakers
   (usar pyannote.audio se vi√°vel)

3. **Silence ratio**: Descartar se >30% sil√™ncio

---

#### üìä Task 6.5: Avalia√ß√£o sistem√°tica
**Tempo**: 4 horas  
**Criar**: `train/scripts/evaluate_quality.py`

**M√©tricas**:
1. **MOS automatizado** (usando modelo pr√©-treinado)
2. **Similarity score** (comparar voz gerada vs refer√™ncia)
3. **Intelligibility** (WER com Whisper)

---

### Crit√©rios de Aceita√ß√£o

- [x] LoRA funcionando, treino 2x mais r√°pido
- [x] Grid search encontra melhores hiperpar√¢metros
- [x] Dataset filtrado (>80% segmentos de alta qualidade)
- [x] Qualidade de timbre >= baseline (avalia√ß√£o subjetiva)

### Depend√™ncias

Sprint 2 (venv), Sprint 3 (configs)

---

## Sprint 7 ‚Äì Hardening & Observabilidade üõ°Ô∏è

**Dura√ß√£o**: 1 semana  
**Objetivo**: Produ√ß√£o-ready (monitoramento, erros, docs)  
**Owner**: DevOps + Tech Lead

### Escopo

Preparar para produ√ß√£o com:
- Monitoramento (Prometheus/Grafana)
- Logs estruturados
- Error tracking
- Docs finalizados

### Tarefas

#### üìä Task 7.1: Prometheus metrics
**Tempo**: 4 horas  
**Arquivo**: `app/metrics.py` (j√° existe?)

**Adicionar**:
```python
from prometheus_client import Counter, Histogram, Gauge

# Metrics
tts_requests_total = Counter("tts_requests_total", "Total TTS requests")
tts_duration_seconds = Histogram("tts_duration_seconds", "TTS latency")
training_loss = Gauge("training_loss", "Current training loss")
```

**Expor**: `GET /metrics` (Prometheus format)

---

#### üìù Task 7.2: Structured logging
**Tempo**: 3 horas  
**Arquivo**: `app/logging_config.py`

**Migrar para JSON logs**:
```python
import structlog

logger = structlog.get_logger()

# Usage
logger.info("tts_request", user_id=123, text_length=500, duration_ms=1200)
```

---

#### üêõ Task 7.3: Error tracking (Sentry/Rollbar)
**Tempo**: 2 horas  
**A√ß√£o**:
```python
import sentry_sdk

sentry_sdk.init(
    dsn="https://...",
    environment=settings.environment
)
```

---

#### üìö Task 7.4: Finalizar documenta√ß√£o
**Tempo**: 6 horas  
**Docs a atualizar**:
- [ ] README.md (badges, quick start)
- [ ] docs/API_REFERENCE.md (OpenAPI completo)
- [ ] docs/DEPLOYMENT.md (Docker, K8s, scaling)
- [ ] docs/TRAINING_GUIDE.md (passo-a-passo)
- [ ] docs/TROUBLESHOOTING.md (FAQ)

---

#### üß™ Task 7.5: Testes de carga
**Tempo**: 4 horas  
**Tool**: Locust ou k6

**Cen√°rios**:
1. 10 req/s de TTS b√°sico
2. 5 req/s de voice cloning
3. 1 treino concorrente

**M√©tricas**:
- Lat√™ncia p50, p95, p99
- Throughput
- Error rate

---

### Crit√©rios de Aceita√ß√£o

- [x] Metrics expostos para Prometheus
- [x] Logs estruturados em JSON
- [x] Errors rastreados (Sentry)
- [x] Docs 100% atualizados
- [x] Load tests passam (p95 < 5s)

### Depend√™ncias

Todas as sprints anteriores

---

## üéØ Roadmap Visual

```
Semana 1-2:  Sprint 0 ‚ñà‚ñà‚ñà‚ñà (CRITICAL)
             Sprint 1 ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà (Limpeza F5/RVC)
             
Semana 3-4:  Sprint 2 ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà (Python venv)
             Sprint 3 ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà (Configs)
             
Semana 5-6:  Sprint 4 ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà (Dataset UI)

Semana 7:    Sprint 5 ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà (Checkpoints+Samples)

Semana 8-9:  Sprint 6 ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà (Qualidade XTTS)

Semana 10:   Sprint 7 ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà (Hardening)
```

---

## üìã Checklists de Valida√ß√£o

### Antes de Cada Sprint
- [ ] Ler objetivos e escopo
- [ ] Verificar depend√™ncias atendidas
- [ ] Estimar tempo realista (adicionar buffer 20%)
- [ ] Alocar pessoas certas

### Durante Sprint
- [ ] Daily standup (15min)
- [ ] Atualizar board (Jira/Trello)
- [ ] Code reviews em 24h
- [ ] Testes automatizados passam

### Fim de Sprint
- [ ] Demo para stakeholders
- [ ] Retrospectiva (What went well / To improve)
- [ ] Deploy em staging
- [ ] Atualizar documenta√ß√£o

---

## üöÄ Como Executar Este Plano

### 1. Prepara√ß√£o (Dia 1)
```bash
# Clone e setup
cd /home/tts-webui-proxmox-passthrough
git checkout -b sprint-0-quick-wins

# Ler MORE.md e SPRINTS.md
cat MORE.md
cat SPRINTS.md
```

### 2. Executar Sprint 0 (Dias 1-2)
```bash
# Task 0.1: Fix checkpoint extension
vim app/training_api.py
# Mudar *.pth ‚Üí *.pt

# Task 0.2 & 0.3: Samples endpoint
vim app/training_api.py  # Adicionar endpoint
vim app/main.py          # Mount static
vim app/webui/assets/js/app.js  # Frontend

# Testar
python run.py
# Abrir WebUI ‚Üí Training ‚Üí Verificar checkpoints e samples
```

### 3. Commit & PR
```bash
git add .
git commit -m "Sprint 0: Fix checkpoints (.pt) + samples endpoint"
git push origin sprint-0-quick-wins
# Criar PR no GitHub/GitLab
```

### 4. Repetir para cada Sprint

---

## üìû Contato & Suporte

**Tech Lead**: [Seu nome]  
**Slack**: #tts-webui-dev  
**Docs**: `/docs`  
**Issues**: GitHub Issues

---

**√öltima atualiza√ß√£o**: 2024-12-07  
**Vers√£o**: 1.0
