# âœ… PROBLEMA RESOLVIDO: Checkpoints e Samples

**Data:** 2025-12-06  
**Status:** âœ… **CONFIGURAÃ‡ÃƒO ATUALIZADA**

---

## ğŸ“‹ Resumo do Problema

**Sintoma:** Treinamento nÃ£o estava salvando checkpoints numerados (`model_25000.pt`, etc.) nem gerando samples de Ã¡udio na pasta `samples/`.

**Causa:** ConfiguraÃ§Ã£o com `save_per_updates: 500` (17.5min) era muito espaÃ§ada. O treinamento foi interrompido em update 25188, antes de chegar em 25500 onde geraria o primeiro checkpoint numerado e samples.

---

## âœ… SoluÃ§Ã£o Aplicada

### MudanÃ§as no `train/config/base_config.yaml`:

```diff
checkpoints:
- save_per_updates: 500          # A cada 17.5 minutos
+ save_per_updates: 200          # A cada 7 minutos âœ…
  
- last_per_updates: 100          # Backup a cada 3.5min
+ last_per_updates: 50           # Backup a cada 1.7min âœ…
  
- keep_last_n_checkpoints: 3     # Manter 3 checkpoints
+ keep_last_n_checkpoints: 5     # Manter 5 checkpoints âœ…
  
- log_samples_per_updates: 500   # Samples a cada 17.5min
+ log_samples_per_updates: 200   # Samples a cada 7min âœ…
```

---

## ğŸ¯ Comportamento Esperado (Nova Config)

### Timeline de Salvamento:

```
Update 25000 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  â”œâ”€ 25050: Salva model_last.pt (backup rÃ¡pido)
  â”œâ”€ 25100: Salva model_last.pt
  â”œâ”€ 25150: Salva model_last.pt
  â”œâ”€ 25200: âœ¨ SALVA model_25200.pt + GERA SAMPLES âœ¨
  â”‚         â”œâ”€ update_25200_gen.wav (Ã¡udio gerado)
  â”‚         â””â”€ update_25200_ref.wav (Ã¡udio referÃªncia)
  â”œâ”€ 25250: Salva model_last.pt
  â”œâ”€ 25300: Salva model_last.pt
  â”œâ”€ 25350: Salva model_last.pt
  â”œâ”€ 25400: âœ¨ SALVA model_25400.pt + GERA SAMPLES âœ¨
  â””â”€ ...
```

### Estrutura de Arquivos Esperada:

```
train/output/ptbr_finetuned2/
â”œâ”€â”€ model_last.pt              # Sempre o mais recente (atualizado a cada 50 updates)
â”œâ”€â”€ model_25200.pt            # Checkpoint numerado #1
â”œâ”€â”€ model_25400.pt            # Checkpoint numerado #2
â”œâ”€â”€ model_25600.pt            # Checkpoint numerado #3
â”œâ”€â”€ model_25800.pt            # Checkpoint numerado #4
â”œâ”€â”€ model_26000.pt            # Checkpoint numerado #5 (mantÃ©m sÃ³ Ãºltimos 5)
â”œâ”€â”€ model_last.metadata.json
â””â”€â”€ samples/
    â”œâ”€â”€ update_25200_gen.wav  # Ãudio gerado pelo modelo
    â”œâ”€â”€ update_25200_ref.wav  # Ãudio de referÃªncia (ground truth)
    â”œâ”€â”€ update_25400_gen.wav
    â”œâ”€â”€ update_25400_ref.wav
    â”œâ”€â”€ update_25600_gen.wav
    â”œâ”€â”€ update_25600_ref.wav
    â””â”€â”€ ... (todos os samples, nÃ£o sÃ£o rotacionados)
```

---

## ğŸš€ Como Reiniciar o Treinamento

### 1. Parar treinamento atual (se rodando)

```bash
pkill -f run_training.py
```

### 2. Limpar pasta samples (opcional)

```bash
rm -rf train/output/ptbr_finetuned2/samples/*
```

### 3. Iniciar novo treinamento

```bash
cd /home/tts-webui-proxmox-passthrough
python3 -m train.run_training --epochs 1000 --batch-size 2
```

**Ou em background:**

```bash
nohup python3 -m train.run_training --epochs 1000 --batch-size 2 > /tmp/train_realtime.log 2>&1 &
echo $! > /tmp/train.pid
```

### 4. Monitorar samples (nova ferramenta!)

```bash
# Monitor automÃ¡tico (atualiza a cada 30s)
./train/scripts/monitor_samples.sh

# OU: Ver manualmente
watch -n 10 'ls -lht train/output/ptbr_finetuned2/samples/ | head -15'
```

---

## â±ï¸ Timing Esperado

Com `batch_size=2` e `grad_accumulation_steps=8`:

| Evento | Updates | Tempo | O que acontece |
|--------|---------|-------|----------------|
| Backup rÃ¡pido | 50 | ~1.7min | Salva `model_last.pt` |
| Checkpoint + Samples | 200 | ~7min | Salva `model_{N}.pt` + gera 2 Ã¡udios |
| RotaÃ§Ã£o de checkpoints | 1000 | ~35min | Remove checkpoint mais antigo |
| 1 Ã©poca completa | ~893 | ~31min | Com 14,284 samples |

**Primeiro sample esperado:** ~7 minutos apÃ³s inÃ­cio do treino (update ~25200)

---

## ğŸ“Š Uso de Disco

### Estimativa com nova config:

```
Checkpoints:
â”œâ”€â”€ model_last.pt:           5.1 GB  (sempre)
â”œâ”€â”€ model_{N}.pt Ã— 5:       25.5 GB  (Ãºltimos 5, rotacionados)
â””â”€â”€ samples/ (200 epochs):   ~2.0 GB  (200 Ã— 10MB, nÃ£o rotacionados)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Total estimado:             ~32.6 GB
```

**EspaÃ§o disponÃ­vel:** 85.4 GB  
**Uso apÃ³s 1 Ã©poca:** ~32.6 GB  
**Margem:** 52.8 GB (62% livre) âœ…

---

## âœ… Checklist de ValidaÃ§Ã£o

ApÃ³s reiniciar o treinamento, verificar:

- [ ] **~1.7min**: `model_last.pt` atualizado (check via `ls -lh`)
- [ ] **~7min**: Primeiro checkpoint `model_25200.pt` criado
- [ ] **~7min**: Samples gerados em `samples/update_25200_*.wav`
- [ ] **~14min**: Segundo checkpoint `model_25400.pt` criado
- [ ] **~35min**: Apenas 5 checkpoints mantidos (rotaÃ§Ã£o funcionando)

### Comandos de ValidaÃ§Ã£o:

```bash
# Ver Ãºltimo checkpoint salvo
ls -lht train/output/ptbr_finetuned2/model_*.pt | head -5

# Contar checkpoints numerados (esperado: max 5)
ls -1 train/output/ptbr_finetuned2/model_[0-9]*.pt | wc -l

# Contar samples (esperado: 2 por checkpoint)
ls -1 train/output/ptbr_finetuned2/samples/*.wav | wc -l

# Ouvir Ãºltimo sample gerado
ls -t train/output/ptbr_finetuned2/samples/*_gen.wav | head -1 | \
  xargs -I {} ffplay -nodisp -autoexit {}
```

---

## ğŸ§ ComparaÃ§Ã£o de Qualidade

Os samples salvam **2 arquivos por update**:

1. **`update_{N}_gen.wav`**: Ãudio gerado pelo modelo (sua sÃ­ntese)
2. **`update_{N}_ref.wav`**: Ãudio de referÃªncia (ground truth do dataset)

**Como comparar:**

```bash
# Ouvir gerado
ffplay train/output/ptbr_finetuned2/samples/update_25200_gen.wav

# Ouvir referÃªncia
ffplay train/output/ptbr_finetuned2/samples/update_25200_ref.wav
```

**Esperado:**
- InÃ­cio: `gen` bem diferente de `ref` (modelo ainda aprendendo)
- Progresso: `gen` cada vez mais parecido com `ref`
- ConvergÃªncia: `gen` praticamente igual a `ref` (overfitting se dataset pequeno)

---

## ğŸ”§ Troubleshooting

### Samples nÃ£o aparecem apÃ³s 10 minutos

```bash
# Ver log do treinamento
tail -100 /tmp/train_realtime.log | grep -E "Saved|update_"

# Verificar processo rodando
ps aux | grep run_training
```

### Checkpoints numerados nÃ£o aparecem

```bash
# Ver config carregado
grep -A5 "save_per_updates" train/config/base_config.yaml

# Ver argumentos passados para F5-TTS
tail -50 /tmp/train_realtime.log | grep "save_per_updates"
```

### Disco cheio

```bash
# Ver uso de disco
du -sh train/output/ptbr_finetuned2/*

# Limpar samples antigos (manter Ãºltimos 50)
cd train/output/ptbr_finetuned2/samples
ls -t *.wav | tail -n +101 | xargs rm -f
```

---

## ğŸ“š ReferÃªncias

- **AnÃ¡lise completa:** `TRAINING_CHECKPOINT_ANALYSIS.md`
- **Config atualizado:** `train/config/base_config.yaml`
- **Monitor de samples:** `train/scripts/monitor_samples.sh`

---

## ğŸ‰ PrÃ³ximos Passos

1. âœ… **ConfiguraÃ§Ã£o atualizada** - `save_per_updates: 200`
2. ğŸ”„ **Reiniciar treinamento** - `python3 -m train.run_training`
3. â³ **Aguardar ~7min** - Primeiro checkpoint + samples
4. ğŸ§ **Validar qualidade** - Ouvir `update_{N}_gen.wav` vs `update_{N}_ref.wav`
5. ğŸ“Š **Monitorar TensorBoard** - http://localhost:6006

**Tempo atÃ© primeira validaÃ§Ã£o de qualidade:** ~7 minutos â±ï¸

---

**Status:** âœ… Pronto para reiniciar treinamento com nova configuraÃ§Ã£o!
