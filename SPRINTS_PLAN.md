# Plano de Sprints ‚Äì F5-TTS Project

**Projeto:** Fine-tuning F5-TTS PT-BR - Transforma√ß√£o em C√≥digo Profissional  
**Tech Lead:** Engenharia de Software & ML  
**Data In√≠cio:** 06 de Dezembro de 2025  
**Vers√£o:** 1.0  
**Total de Sprints:** 8 sprints principais + 1 backlog futuro

---

## Vis√£o Geral

Este plano de sprints foi desenvolvido com base no relat√≥rio t√©cnico completo (`MORE.md`) e tem como objetivo transformar o projeto de fine-tuning F5-TTS de um estado "funcionando mas bagun√ßado" para um c√≥digo de **n√≠vel profissional** com:

- ‚úÖ Configura√ß√£o unificada e clara
- ‚úÖ Separa√ß√£o de responsabilidades (SOLID)
- ‚úÖ Pipeline de dados modular e test√°vel
- ‚úÖ Reprodutibilidade garantida
- ‚úÖ Experi√™ncia de desenvolvedor de alta qualidade
- ‚úÖ Testes automatizados
- ‚úÖ Documenta√ß√£o completa

### Estrat√©gia de Execu√ß√£o

- **Sprints 1-2:** CR√çTICO - Corrigir problemas que causam bugs em produ√ß√£o
- **Sprints 3-4:** ALTA - Refatora√ß√£o estrutural para manutenibilidade
- **Sprints 5-6:** M√âDIA - Melhorias de DX e produtividade
- **Sprints 7-8:** BAIXA-M√âDIA - Profissionaliza√ß√£o e MLOps
- **Backlog Futuro:** Ideias de longo prazo

---

## Sprint 1: Unifica√ß√£o de Configura√ß√£o e Paths

**Objetivo:** Eliminar fragmenta√ß√£o de configura√ß√£o e garantir consist√™ncia de paths cr√≠ticos.

**Dura√ß√£o Estimada:** 2-3 dias

**Prioridade:** üî¥ CR√çTICA

### Premissas / Depend√™ncias
- Nenhuma (primeiro sprint)
- Requer revis√£o de todos os arquivos de config existentes

### Entreg√°veis Principais
1. Configura√ß√£o unificada em `train/config.yaml`
2. M√≥dulo Python `train/config/loader.py` para carregar e validar config
3. Vocabul√°rio consolidado em um √∫nico lugar com valida√ß√£o de hash
4. Documenta√ß√£o de hierarquia de configura√ß√£o

### Lista de Tarefas

#### S1-T1: Criar Configura√ß√£o Unificada
- **Categoria:** Config
- **Prioridade:** ALTA
- **Descri√ß√£o:**
  - Criar `train/config/base_config.yaml` com TODAS as configs (paths, hiperpar√¢metros, dataset, audio, etc.)
  - Migrar valores de `train/.env`, `train_config.yaml`, `dataset_config.yaml`
  - Definir defaults sensatos
  - Documentar cada se√ß√£o com coment√°rios
- **Arquivos Afetados:**
  - NOVO: `train/config/base_config.yaml`
  - Refer√™ncia: `train/.env`, `train/config/train_config.yaml`, `train/config/dataset_config.yaml`
- **Impacto Esperado:** Fonte √∫nica de verdade para toda configura√ß√£o

#### S1-T2: Implementar Config Loader com Valida√ß√£o
- **Categoria:** C√≥digo
- **Prioridade:** ALTA
- **Descri√ß√£o:**
  - Criar `train/config/loader.py`
  - Usar Pydantic para valida√ß√£o de tipos e valores
  - Implementar hierarquia: defaults ‚Üí base_config.yaml ‚Üí .env overrides ‚Üí CLI args
  - Validar paths (exist√™ncia, permiss√µes)
  - Retornar objeto imut√°vel (frozen dataclass ou Pydantic BaseModel)
- **Arquivos Afetados:**
  - NOVO: `train/config/loader.py`
  - NOVO: `train/config/schemas.py` (Pydantic models)
  - Modificar: `train/utils/env_loader.py` (deprecar ou integrar)
- **Impacto Esperado:** Config validada e type-safe

#### S1-T3: Consolidar Vocabul√°rio com Hash
- **Categoria:** Data Pipeline
- **Prioridade:** ALTA
- **Descri√ß√£o:**
  - Escolher `train/config/vocab.txt` como source of truth
  - Adicionar coment√°rio no topo com SHA256 hash: `# VOCAB_HASH: sha256:abc123...`
  - Deletar c√≥pias em `train/data/vocab.txt` e `train/data/f5_dataset/vocab.txt`
  - Criar fun√ß√£o `train/utils/vocab.py::validate_vocab(path)` que verifica hash
  - Atualizar scripts para copiar/linkar de `train/config/vocab.txt`
- **Arquivos Afetados:**
  - Modificar: `train/config/vocab.txt` (adicionar hash)
  - DELETAR: `train/data/vocab.txt`, `train/data/f5_dataset/vocab.txt`
  - NOVO: `train/utils/vocab.py`
  - Modificar: scripts que usam vocab
- **Impacto Esperado:** Garantia de vocab consistente entre treino e infer√™ncia

#### S1-T4: Refatorar run_training.py para Usar Config Unificado
- **Categoria:** C√≥digo
- **Prioridade:** ALTA
- **Descri√ß√£o:**
  - Modificar `train/run_training.py` para importar `train.config.loader`
  - Remover depend√™ncia de `env_loader.py`
  - Usar config validado em vez de dict
  - Logar config completa no in√≠cio do treino (para auditoria)
- **Arquivos Afetados:**
  - Modificar: `train/run_training.py`
- **Impacto Esperado:** Treino usa config unificado

#### S1-T5: Refatorar Scripts de Infer√™ncia para Usar Config Unificado
- **Categoria:** C√≥digo
- **Prioridade:** M√âDIA
- **Descri√ß√£o:**
  - Modificar `train/scripts/AgentF5TTSChunk.py`
  - Remover paths hardcoded (linha 180-182)
  - Importar config de `train.config.loader`
- **Arquivos Afetados:**
  - Modificar: `train/scripts/AgentF5TTSChunk.py`
  - Modificar: `train/test.py`
- **Impacto Esperado:** Infer√™ncia consistente com treino

#### S1-T6: Documentar Hierarquia de Configura√ß√£o
- **Categoria:** Docs
- **Prioridade:** BAIXA
- **Descri√ß√£o:**
  - Criar `train/docs/CONFIGURATION.md`
  - Explicar hierarquia: defaults ‚Üí base_config.yaml ‚Üí .env ‚Üí CLI
  - Exemplos de uso
  - Como adicionar nova config
  - Como fazer override em deploy
- **Arquivos Afetados:**
  - NOVO: `train/docs/CONFIGURATION.md`
- **Impacto Esperado:** DX melhorado, onboarding mais r√°pido

---

## Sprint 2: Checkpoint Path e Vocoder Consistency

**Objetivo:** Garantir que fine-tuning seja usado em produ√ß√£o e que vocoder seja consistente.

**Dura√ß√£o Estimada:** 2 dias

**Prioridade:** üî¥ CR√çTICA

### Premissas / Depend√™ncias
- Sprint 1 conclu√≠do (config unificado dispon√≠vel)

### Entreg√°veis Principais
1. Fun√ß√£o utilit√°ria para resolver checkpoint path
2. API de infer√™ncia (`f5tts_engine.py`) respeitando checkpoint customizado
3. Valida√ß√£o de checkpoint antes de carregar
4. Documenta√ß√£o de formato de checkpoint

### Lista de Tarefas

#### S2-T1: Criar Fun√ß√£o Utilit√°ria para Resolver Checkpoint Path
- **Categoria:** C√≥digo
- **Prioridade:** ALTA
- **Descri√ß√£o:**
  - Criar `train/utils/checkpoint.py::resolve_checkpoint_path(config)`
  - L√≥gica de prioridade:
    1. `config.custom_checkpoint_path` (se arquivo existir)
    2. `train/output/{exp_name}/model_best.pt` (se existir)
    3. `train/output/{exp_name}/model_last.pt` (se existir)
    4. Download de HuggingFace (fallback)
  - Validar tamanho m√≠nimo (> 1GB para detectar corrompidos)
  - Logar decis√£o claramente
- **Arquivos Afetados:**
  - NOVO: `train/utils/checkpoint.py`
- **Impacto Esperado:** Checkpoint resolution consistente

#### S2-T2: Adicionar Valida√ß√£o de Checkpoint
- **Categoria:** C√≥digo
- **Prioridade:** ALTA
- **Descri√ß√£o:**
  - Em `train/utils/checkpoint.py`, adicionar `validate_checkpoint(path)`
  - Verificar: pode carregar com torch.load, tamanho > 1GB, tem keys esperadas
  - Se corrompido, renomear para `.corrupted` e tentar pr√≥ximo
  - Retornar info: `CheckpointInfo(path, size, num_keys, metadata)`
- **Arquivos Afetados:**
  - Modificar: `train/utils/checkpoint.py`
- **Impacto Esperado:** Previne uso de checkpoints corrompidos

#### S2-T3: Refatorar f5tts_engine.py para Respeitar Custom Checkpoint
- **Categoria:** C√≥digo
- **Prioridade:** ALTA
- **Descri√ß√£o:**
  - Modificar `app/engines/f5tts_engine.py::__init__()`
  - Importar `train.utils.checkpoint.resolve_checkpoint_path`
  - Usar checkpoint customizado se `F5TTS_CUSTOM_CHECKPOINT` estiver no .env
  - Remover l√≥gica de patch inline (mover para script separado se necess√°rio)
  - Logar qual checkpoint foi carregado
- **Arquivos Afetados:**
  - Modificar: `app/engines/f5tts_engine.py` (linhas 100-250)
- **Impacto Esperado:** Fine-tuning usado em produ√ß√£o

#### S2-T4: Adicionar Metadata ao Checkpoint
- **Categoria:** C√≥digo
- **Prioridade:** M√âDIA
- **Descri√ß√£o:**
  - Modificar `train/run_training.py` para salvar `model_last.metadata.json` junto com checkpoint
  - Metadata: timestamp, git_commit, config completa, vocab_hash, dataset info, metrics finais
  - Validar ao carregar: se metadata existir, logar informa√ß√µes
- **Arquivos Afetados:**
  - Modificar: `train/run_training.py` (ap√≥s salvar checkpoint)
  - NOVO: `train/utils/checkpoint.py::save_checkpoint_metadata()`
- **Impacto Esperado:** Rastreabilidade de checkpoints

#### S2-T5: Documentar Formato de Checkpoint
- **Categoria:** Docs
- **Prioridade:** BAIXA
- **Descri√ß√£o:**
  - Criar `train/docs/CHECKPOINT_FORMAT.md`
  - Explicar estrutura esperada de checkpoint (keys, prefixes, metadata)
  - Como patch √© aplicado (se necess√°rio)
  - Como validar checkpoint manualmente
- **Arquivos Afetados:**
  - NOVO: `train/docs/CHECKPOINT_FORMAT.md`
- **Impacto Esperado:** Debugging facilitado

---

## Sprint 3: Refatora√ß√£o de Pipeline de Dados - M√≥dulos

**Objetivo:** Separar pipeline de dados monol√≠tico em m√≥dulos reutiliz√°veis e test√°veis.

**Dura√ß√£o Estimada:** 4-5 dias

**Prioridade:** ‚ö†Ô∏è ALTA

### Premissas / Depend√™ncias
- Sprint 1 conclu√≠do (config unificado)
- Scripts atuais funcionando (n√£o quebrar funcionalidade)

### Entreg√°veis Principais
1. M√≥dulos organizados: `train/audio/`, `train/text/`, `train/io/`
2. Fun√ß√µes puras sem efeitos colaterais (sem I/O direto)
3. Scripts principais virando "orquestradores" finos
4. Testes unit√°rios para cada m√≥dulo

### Lista de Tarefas

#### S3-T1: Criar M√≥dulo train/audio/ com VAD e Segmenta√ß√£o
- **Categoria:** C√≥digo - Arquitetura
- **Prioridade:** ALTA
- **Descri√ß√£o:**
  - Criar estrutura:
    ```
    train/audio/
      __init__.py
      vad.py           # Voice Activity Detection
      segmentation.py  # Audio segmentation
      normalization.py # Loudness normalization
      effects.py       # Fade, filters
      io.py            # Load/save audio
    ```
  - Extrair c√≥digo de `prepare_segments_optimized.py`:
    - `vad.py::detect_voice_regions(audio, params)` (linhas 90-150)
    - `segmentation.py::segment_audio(audio, voice_regions, params)` (linhas 200-300)
    - `normalization.py::normalize_loudness(audio, target_lufs)` (linhas 350-400)
    - `effects.py::apply_fade(audio, fade_ms)`
  - Fun√ß√µes puras: recebem np.ndarray, retornam np.ndarray ou List
- **Arquivos Afetados:**
  - NOVO: `train/audio/__init__.py`, `vad.py`, `segmentation.py`, `normalization.py`, `effects.py`, `io.py`
  - Refer√™ncia: `train/scripts/prepare_segments_optimized.py`
- **Impacto Esperado:** C√≥digo modular e test√°vel

#### S3-T2: Criar M√≥dulo train/text/ com Normaliza√ß√£o e QA
- **Categoria:** C√≥digo - Arquitetura
- **Prioridade:** ALTA
- **Descri√ß√£o:**
  - Criar estrutura:
    ```
    train/text/
      __init__.py
      normalizer.py  # J√° existe! Apenas mover
      qa.py          # Quality assurance
      vocab.py       # Moved from utils
    ```
  - Mover `train/utils/text_normalizer.py` ‚Üí `train/text/normalizer.py`
  - Extrair de `transcribe_or_subtitles.py`:
    - `qa.py::check_text_quality(text, vocab)` (verifica OOV, etc.)
  - Mover `train/utils/vocab.py` (criado em S1-T3) ‚Üí `train/text/vocab.py`
- **Arquivos Afetados:**
  - MOVER: `train/utils/text_normalizer.py` ‚Üí `train/text/normalizer.py`
  - NOVO: `train/text/qa.py`
  - MOVER: `train/utils/vocab.py` ‚Üí `train/text/vocab.py`
- **Impacto Esperado:** Texto processing organizado

#### S3-T3: Criar M√≥dulo train/io/ para YouTube e Legendas
- **Categoria:** C√≥digo - Arquitetura
- **Prioridade:** M√âDIA
- **Descri√ß√£o:**
  - Criar estrutura:
    ```
    train/io/
      __init__.py
      youtube.py      # Download YouTube
      subtitles.py    # Extract subtitles
      storage.py      # File operations
    ```
  - Extrair de `download_youtube.py` e `transcribe_or_subtitles.py`:
    - `youtube.py::download_audio(url, output_path, config)`
    - `subtitles.py::download_subtitles(url, output_path, config)`
- **Arquivos Afetados:**
  - NOVO: `train/io/__init__.py`, `youtube.py`, `subtitles.py`, `storage.py`
  - Refer√™ncia: `train/scripts/download_youtube.py`, `train/scripts/transcribe_or_subtitles.py`
- **Impacto Esperado:** I/O separado de l√≥gica

#### S3-T4: Refatorar prepare_segments_optimized.py em Orquestrador
- **Categoria:** C√≥digo - Refatora√ß√£o
- **Prioridade:** ALTA
- **Descri√ß√£o:**
  - Reduzir `prepare_segments_optimized.py` de 570 linhas para ~100 linhas
  - Importar de `train.audio` e `train.io`
  - Fun√ß√£o main vira:
    ```python
    def main():
        config = load_config()
        for audio_path in get_audio_files():
            audio = audio_io.load(audio_path)
            voice_regions = vad.detect_voice_regions(audio, config.vad)
            segments = segmentation.segment_audio(audio, voice_regions, config.segment)
            normalized = [normalization.normalize(s, config.audio) for s in segments]
            audio_io.save_all(normalized, output_dir)
    ```
- **Arquivos Afetados:**
  - Modificar: `train/scripts/prepare_segments_optimized.py`
- **Impacto Esperado:** Script limpo, f√°cil de entender

#### S3-T5: Refatorar transcribe_or_subtitles.py em Orquestrador
- **Categoria:** C√≥digo - Refatora√ß√£o
- **Prioridade:** M√âDIA
- **Descri√ß√£o:**
  - Reduzir de 756 linhas para ~150 linhas
  - Importar de `train.text` e `train.io`
  - Separar l√≥gica de Whisper em `train/audio/transcription.py`
- **Arquivos Afetados:**
  - Modificar: `train/scripts/transcribe_or_subtitles.py`
  - NOVO: `train/audio/transcription.py`
- **Impacto Esperado:** C√≥digo modular

#### S3-T6: Adicionar Testes Unit√°rios para M√≥dulos
- **Categoria:** Testes
- **Prioridade:** M√âDIA
- **Descri√ß√£o:**
  - Criar `tests/train/audio/` com testes para cada m√≥dulo
  - Fixtures: √°udio sint√©tico (1s de silence, 1s de noise, 1s de speech simulado)
  - Testes:
    - `test_vad.py::test_detect_voice_in_silence()` ‚Üí deve retornar []
    - `test_segmentation.py::test_segment_audio()` ‚Üí deve retornar N segmentos
    - `test_normalization.py::test_normalize_loudness()` ‚Üí verificar LUFS alvo
  - Coverage > 80%
- **Arquivos Afetados:**
  - NOVO: `tests/train/audio/test_vad.py`, `test_segmentation.py`, etc.
  - NOVO: `tests/fixtures/audio_samples.py` (synthetic audio generator)
- **Impacto Esperado:** Confian√ßa em refatorar

---

## Sprint 4: Reprodutibilidade e MLOps B√°sico

**Objetivo:** Garantir experimentos reproduz√≠veis e adicionar versionamento de depend√™ncias.

**Dura√ß√£o Estimada:** 3 dias

**Prioridade:** ‚ö†Ô∏è ALTA

### Premissas / Depend√™ncias
- Sprint 1 conclu√≠do (config unificado)

### Entreg√°veis Principais
1. Depend√™ncias pinadas (`requirements-lock.txt`)
2. Seed aplicado globalmente
3. Registro b√°sico de experimentos (sem MLflow ainda)
4. Scripts de setup automatizado

### Lista de Tarefas

#### S4-T1: Pinar Depend√™ncias com Vers√µes Exatas
- **Categoria:** MLOps
- **Prioridade:** ALTA
- **Descri√ß√£o:**
  - Gerar `requirements-lock.txt` com `pip freeze`
  - Separar:
    - `requirements-lock.txt` (ambiente base + API)
    - `train/requirements-train-lock.txt` (treino)
  - Atualizar CI/CD para usar `-lock.txt`
  - Documentar processo de atualiza√ß√£o de deps
- **Arquivos Afetados:**
  - NOVO: `requirements-lock.txt`
  - NOVO: `train/requirements-train-lock.txt`
  - Modificar: `.github/workflows/*.yml` (se existir CI)
- **Impacto Esperado:** Reprodutibilidade garantida

#### S4-T2: Implementar Seed Global para Reprodutibilidade
- **Categoria:** C√≥digo - MLOps
- **Prioridade:** ALTA
- **Descri√ß√£o:**
  - Criar `train/utils/reproducibility.py::set_seed(seed, deterministic=True)`
  - Implementar:
    ```python
    import torch, numpy as np, random
    def set_seed(seed, deterministic=True):
        torch.manual_seed(seed)
        torch.cuda.manual_seed_all(seed)
        np.random.seed(seed)
        random.seed(seed)
        if deterministic:
            torch.backends.cudnn.deterministic = True
            torch.backends.cudnn.benchmark = False
    ```
  - Chamar no in√≠cio de `run_training.py`, `test.py`, scripts de infer√™ncia
  - Logar warning se deterministic=True (pode ser 10% mais lento)
- **Arquivos Afetados:**
  - NOVO: `train/utils/reproducibility.py`
  - Modificar: `train/run_training.py`, `train/test.py`
- **Impacto Esperado:** Experimentos reproduz√≠veis

#### S4-T3: Criar experiment.json com Metadata de Treino
- **Categoria:** MLOps
- **Prioridade:** M√âDIA
- **Descri√ß√£o:**
  - Modificar `run_training.py` para salvar `train/output/{exp_name}/experiment.json`
  - Conte√∫do:
    ```json
    {
      "timestamp": "2025-12-06T10:00:00Z",
      "git_commit": "abc123",
      "config": {...},  // config completa
      "vocab_hash": "sha256:...",
      "dataset": {
        "path": "...",
        "num_samples": 5000,
        "total_duration_hours": 10.5
      },
      "dependencies": {
        "torch": "2.1.0",
        "f5-tts": "1.1.9"
      },
      "hardware": {
        "gpu": "Tesla V100",
        "cuda": "11.8"
      }
    }
    ```
  - √ötil para reproduzir experimento depois
- **Arquivos Afetados:**
  - Modificar: `train/run_training.py`
  - NOVO: `train/utils/experiment.py::save_experiment_metadata()`
- **Impacto Esperado:** Rastreabilidade de experimentos

#### S4-T4: Criar Script de Setup Automatizado
- **Categoria:** DevOps
- **Prioridade:** M√âDIA
- **Descri√ß√£o:**
  - Criar `Makefile` na raiz:
    ```makefile
    setup:
        python3.11 -m venv .venv
        .venv/bin/pip install -r requirements-lock.txt
        .venv/bin/pip install -r train/requirements-train-lock.txt
        mkdir -p train/{data,output,runs,logs}
        @echo "‚úÖ Setup completo! Ative o venv: source .venv/bin/activate"
    
    validate:
        .venv/bin/python -m train.scripts.validate_setup
    
    test:
        .venv/bin/pytest tests/
    ```
  - Atualizar README com instru√ß√µes: `make setup`
- **Arquivos Afetados:**
  - NOVO: `Makefile`
  - Modificar: `README.md`
- **Impacto Esperado:** Onboarding em 1 comando

#### S4-T5: Criar Health Check Script
- **Categoria:** DevOps
- **Prioridade:** BAIXA
- **Descri√ß√£o:**
  - Criar `train/scripts/health_check.py`
  - Valida√ß√µes:
    - CUDA dispon√≠vel e GPU detectada
    - Dataset path existe e tem samples
    - Vocab.txt hash v√°lido
    - Disk space > 10GB
    - RAM > 8GB (warning se < 16GB)
  - Output colorido (emoji)
- **Arquivos Afetados:**
  - NOVO: `train/scripts/health_check.py`
- **Impacto Esperado:** Valida√ß√£o antes de treinar

---

## Sprint 5: Experi√™ncia de Treino Melhorada

**Objetivo:** Adicionar callbacks, m√©tricas avan√ßadas e CLI amig√°vel.

**Dura√ß√£o Estimada:** 3-4 dias

**Prioridade:** üìä M√âDIA

### Premissas / Depend√™ncias
- Sprint 2 conclu√≠do (checkpoint utils)
- Sprint 3 conclu√≠do (m√≥dulos organizados)

### Entreg√°veis Principais
1. Callbacks customizados (best model, audio samples)
2. M√©tricas al√©m de loss (MCD, dura√ß√£o)
3. CLI com argumentos validados (typer)
4. Logs estruturados (JSON)

### Lista de Tarefas

#### S5-T1: Implementar Callback para Salvar Best Model
- **Categoria:** C√≥digo - Treino
- **Prioridade:** ALTA
- **Descri√ß√£o:**
  - Criar `train/training/callbacks.py::BestModelCallback`
  - Rastrear melhor val_loss (ou metric escolhida)
  - Salvar `model_best.pt` quando m√©trica melhora
  - Integrar em `run_training.py` (se F5-TTS CLI suportar callbacks)
  - Alternativa: monitorar logs e copiar checkpoint manualmente
- **Arquivos Afetados:**
  - NOVO: `train/training/callbacks.py`
  - Modificar: `train/run_training.py`
- **Impacto Esperado:** Checkpoint best dispon√≠vel

#### S5-T2: Adicionar Callback para Gerar Audio Samples
- **Categoria:** C√≥digo - Treino
- **Prioridade:** M√âDIA
- **Descri√ß√£o:**
  - Em `train/training/callbacks.py::AudioSampleCallback`
  - A cada N epochs, gerar sample de √°udio com texto fixo
  - Salvar em `train/output/{exp_name}/samples/sample_epoch_{n}.wav`
  - Logar no TensorBoard (se poss√≠vel)
- **Arquivos Afetados:**
  - Modificar: `train/training/callbacks.py`
- **Impacto Esperado:** Valida√ß√£o auditiva durante treino

#### S5-T3: Adicionar M√©tricas Avan√ßadas (MCD)
- **Categoria:** C√≥digo - Treino
- **Prioridade:** BAIXA
- **Descri√ß√£o:**
  - Calcular MCD (Mel Cepstral Distortion) entre samples gerados e refer√™ncia
  - Usar biblioteca `pymcd` ou implementar manualmente
  - Logar no TensorBoard como scalar
  - Opcional: MOS estimado (usar modelo pr√©-treinado)
- **Arquivos Afetados:**
  - Modificar: `train/run_training.py` ou callbacks
  - NOVO: `train/training/metrics.py`
- **Impacto Esperado:** Visibilidade de qualidade

#### S5-T4: Criar CLI Amig√°vel com Typer
- **Categoria:** C√≥digo - DX
- **Prioridade:** M√âDIA
- **Descri√ß√£o:**
  - Refatorar `train/run_training.py` para usar `typer`
  - Argumentos:
    ```bash
    python -m train.run_training \
      --config train/config/base_config.yaml \
      --learning-rate 0.0002 \
      --epochs 100 \
      --batch-size 8 \
      --exp-name my_experiment
    ```
  - Validar argumentos (typer faz isso automaticamente)
  - Help text detalhado
- **Arquivos Afetados:**
  - Modificar: `train/run_training.py`
  - NOVO: `train/requirements-train-lock.txt` (adicionar typer)
- **Impacto Esperado:** CLI amig√°vel

#### S5-T5: Implementar Structured Logging com Loguru
- **Categoria:** C√≥digo - Infra
- **Prioridade:** BAIXA
- **Descri√ß√£o:**
  - Substituir `logging` por `loguru`
  - Configurar para logar em JSON:
    ```python
    logger.add("train/logs/train.json", format="{time} {level} {message}", serialize=True)
    ```
  - Adicionar contexto estruturado:
    ```python
    logger.info("Epoch completed", epoch=10, loss=0.123, lr=0.0001)
    ```
  - Facilita parsing com `jq` ou ferramentas de log
- **Arquivos Afetados:**
  - Modificar: todos os scripts em `train/`
  - NOVO: `train/utils/logging.py::setup_logger()`
- **Impacto Esperado:** Logs estruturados, f√°cil an√°lise

---

## Sprint 6: Experi√™ncia de Infer√™ncia e API Unificada

**Objetivo:** Criar interface consistente para infer√™ncia e CLI de teste r√°pido.

**Dura√ß√£o Estimada:** 3 dias

**Prioridade:** üìä M√âDIA

### Premissas / Depend√™ncias
- Sprint 1 conclu√≠do (config unificado)
- Sprint 2 conclu√≠do (checkpoint resolution)

### Entreg√°veis Principais
1. API unificada `F5TTSInference` usada por API REST e scripts
2. CLI de teste r√°pido `train.infer`
3. Service layer com cache de modelo
4. Documenta√ß√£o de uso

### Lista de Tarefas

#### S6-T1: Criar API Unificada F5TTSInference
- **Categoria:** C√≥digo - Arquitetura
- **Prioridade:** ALTA
- **Descri√ß√£o:**
  - Criar `train/inference/api.py::F5TTSInference`
  - Interface:
    ```python
    class F5TTSInference:
        def __init__(self, checkpoint_path, vocab_file, device, config):
            ...
        
        def generate(
            self,
            text: str,
            ref_audio: Path,
            ref_text: str = "",
            nfe_step: int = 32
        ) -> np.ndarray:
            ...
    ```
  - Implementa√ß√£o deve encapsular `F5TTS` da lib
  - Usado por: API REST, scripts, CLI
- **Arquivos Afetados:**
  - NOVO: `train/inference/__init__.py`, `api.py`
- **Impacto Esperado:** Interface consistente

#### S6-T2: Refatorar f5tts_engine.py para Usar API Unificada
- **Categoria:** C√≥digo - Refatora√ß√£o
- **Prioridade:** ALTA
- **Descri√ß√£o:**
  - Modificar `app/engines/f5tts_engine.py`
  - Remover l√≥gica duplicada
  - Importar `train.inference.F5TTSInference`
  - Delegar gera√ß√£o de √°udio para API unificada
- **Arquivos Afetados:**
  - Modificar: `app/engines/f5tts_engine.py`
- **Impacto Esperado:** Menos duplica√ß√£o

#### S6-T3: Refatorar AgentF5TTSChunk.py para Usar API Unificada
- **Categoria:** C√≥digo - Refatora√ß√£o
- **Prioridade:** M√âDIA
- **Descri√ß√£o:**
  - Modificar `train/scripts/AgentF5TTSChunk.py`
  - Importar `train.inference.F5TTSInference`
  - Simplificar l√≥gica (remover wrapper redundante)
- **Arquivos Afetados:**
  - Modificar: `train/scripts/AgentF5TTSChunk.py`
- **Impacto Esperado:** C√≥digo limpo

#### S6-T4: Criar CLI de Teste R√°pido
- **Categoria:** C√≥digo - DX
- **Prioridade:** M√âDIA
- **Descri√ß√£o:**
  - Criar `train/cli/infer.py`
  - Uso:
    ```bash
    python -m train.cli.infer \
      --checkpoint train/output/model_last.pt \
      --text "Ol√°, mundo!" \
      --ref-audio ref.wav \
      --output output.wav \
      --nfe-step 32
    ```
  - Usar typer para CLI
  - Logar tempo de gera√ß√£o, RTF
- **Arquivos Afetados:**
  - NOVO: `train/cli/__init__.py`, `infer.py`
- **Impacto Esperado:** Teste r√°pido p√≥s-treino

#### S6-T5: Implementar Service Layer com Cache
- **Categoria:** C√≥digo - Otimiza√ß√£o
- **Prioridade:** BAIXA
- **Descri√ß√£o:**
  - Criar `train/inference/service.py::F5TTSService` (Singleton)
  - Cachear modelo carregado em mem√≥ria
  - Lazy load: s√≥ carrega quando necess√°rio
  - Unload ap√≥s timeout (opcional)
- **Arquivos Afetados:**
  - NOVO: `train/inference/service.py`
- **Impacto Esperado:** Infer√™ncia mais r√°pida

#### S6-T6: Documentar API de Infer√™ncia
- **Categoria:** Docs
- **Prioridade:** BAIXA
- **Descri√ß√£o:**
  - Criar `train/docs/INFERENCE_API.md`
  - Exemplos de uso
  - Par√¢metros dispon√≠veis
  - Troubleshooting
- **Arquivos Afetados:**
  - NOVO: `train/docs/INFERENCE_API.md`
- **Impacto Esperado:** DX melhorado

---

## Sprint 7: Qualidade de C√≥digo e Testes

**Objetivo:** Adicionar linting, formata√ß√£o, type checking e testes automatizados.

**Dura√ß√£o Estimada:** 4 dias

**Prioridade:** üìù BAIXA-M√âDIA

### Premissas / Depend√™ncias
- Sprint 3 conclu√≠do (m√≥dulos organizados, facilitando testes)

### Entreg√°veis Principais
1. Linting e formata√ß√£o configurados (ruff, black)
2. Type checking com mypy
3. Pre-commit hooks
4. Testes unit√°rios com >70% coverage
5. Teste de integra√ß√£o end-to-end

### Lista de Tarefas

#### S7-T1: Configurar Linting com Ruff
- **Categoria:** Qualidade de C√≥digo
- **Prioridade:** M√âDIA
- **Descri√ß√£o:**
  - Criar `pyproject.toml` com config do ruff
  - Regras: E (pycodestyle), F (pyflakes), I (isort), N (naming)
  - Rodar `ruff check train/` e corrigir warnings cr√≠ticos
  - Adicionar ao Makefile: `make lint`
- **Arquivos Afetados:**
  - NOVO: `pyproject.toml`
  - Modificar: `Makefile`
- **Impacto Esperado:** C√≥digo consistente

#### S7-T2: Configurar Formata√ß√£o com Black
- **Categoria:** Qualidade de C√≥digo
- **Prioridade:** M√âDIA
- **Descri√ß√£o:**
  - Configurar black no `pyproject.toml`
  - Line length: 100
  - Rodar `black train/`
  - Adicionar ao Makefile: `make format`
- **Arquivos Afetados:**
  - Modificar: `pyproject.toml`
  - Modificar: `Makefile`
- **Impacto Esperado:** Formata√ß√£o autom√°tica

#### S7-T3: Adicionar Type Hints e Mypy
- **Categoria:** Qualidade de C√≥digo
- **Prioridade:** M√âDIA
- **Descri√ß√£o:**
  - Adicionar type hints em fun√ß√µes p√∫blicas de m√≥dulos cr√≠ticos (train/audio/, train/text/)
  - Configurar mypy no `pyproject.toml`
  - Rodar `mypy train/ --strict` (ou --ignore-missing-imports para come√ßar)
  - Corrigir erros cr√≠ticos
  - Adicionar ao Makefile: `make typecheck`
- **Arquivos Afetados:**
  - Modificar: `pyproject.toml`, `Makefile`
  - Modificar: fun√ß√µes em `train/audio/`, `train/text/`, etc.
- **Impacto Esperado:** Type safety

#### S7-T4: Configurar Pre-commit Hooks
- **Categoria:** DevOps
- **Prioridade:** BAIXA
- **Descri√ß√£o:**
  - Criar `.pre-commit-config.yaml`
  - Hooks: black, ruff, mypy (opcional)
  - Instalar: `pre-commit install`
  - Testar: `pre-commit run --all-files`
- **Arquivos Afetados:**
  - NOVO: `.pre-commit-config.yaml`
- **Impacto Esperado:** Qualidade garantida antes de commit

#### S7-T5: Adicionar Testes Unit√°rios (continua√ß√£o de S3-T6)
- **Categoria:** Testes
- **Prioridade:** ALTA
- **Descri√ß√£o:**
  - Expandir testes de S3-T6
  - Coverage > 70% em m√≥dulos cr√≠ticos (audio, text, config)
  - Usar pytest com fixtures
  - Adicionar ao Makefile: `make test`, `make coverage`
- **Arquivos Afetados:**
  - Expandir: `tests/train/`
  - NOVO: `tests/train/text/`, `tests/train/config/`, etc.
- **Impacto Esperado:** Confian√ßa em mudan√ßas

#### S7-T6: Criar Teste de Integra√ß√£o End-to-End
- **Categoria:** Testes
- **Prioridade:** M√âDIA
- **Descri√ß√£o:**
  - Criar `tests/train/test_e2e_pipeline.py`
  - Fluxo completo com dataset pequeno (5 samples):
    1. Download fake audio (synthetic ou fixture)
    2. Segment
    3. Transcribe (mock Whisper)
    4. Normalize
    5. Build dataset
    6. Train (1 epoch, batch_size=1)
    7. Infer
  - Validar: checkpoint gerado, sample de √°udio criado
  - Tempo: ~2min
- **Arquivos Afetados:**
  - NOVO: `tests/train/test_e2e_pipeline.py`
  - NOVO: `tests/fixtures/mini_dataset/` (5 samples)
- **Impacto Esperado:** Smoke test completo

---

## Sprint 8: Documenta√ß√£o Completa e MLOps Avan√ßado

**Objetivo:** Profissionalizar projeto com docs completas, MLflow e Docker para treino.

**Dura√ß√£o Estimada:** 3-4 dias

**Prioridade:** üìù BAIXA-M√âDIA

### Premissas / Depend√™ncias
- Todas as sprints anteriores conclu√≠das (c√≥digo est√°vel)

### Entreg√°veis Principais
1. Documenta√ß√£o completa (README, tutoriais, API docs)
2. MLflow integrado (opcional)
3. Docker para treino (opcional)
4. Scripts de exemplo

### Lista de Tarefas

#### S8-T1: Reorganizar e Completar READMEs
- **Categoria:** Docs
- **Prioridade:** ALTA
- **Descri√ß√£o:**
  - Atualizar `README.md` raiz com se√ß√£o "Training" linkando para `train/README.md`
  - Criar README por pasta:
    - `train/scripts/README.md`: lista scripts e uso
    - `train/audio/README.md`: descreve m√≥dulos de √°udio
    - `train/text/README.md`: descreve processamento de texto
  - Criar `train/docs/INDEX.md` listando todos os docs
- **Arquivos Afetados:**
  - Modificar: `README.md`
  - NOVO: `train/scripts/README.md`, `train/audio/README.md`, etc.
  - NOVO: `train/docs/INDEX.md`
- **Impacto Esperado:** Navega√ß√£o f√°cil

#### S8-T2: Criar Tutorial Passo-a-Passo
- **Categoria:** Docs
- **Prioridade:** ALTA
- **Descri√ß√£o:**
  - Criar `train/docs/TUTORIAL.md`
  - Se√ß√µes:
    1. Setup do ambiente (make setup)
    2. Preparar dataset (passo-a-passo)
    3. Configurar treino (editar config.yaml)
    4. Iniciar treino (python -m train.run_training)
    5. Monitorar (TensorBoard)
    6. Testar checkpoint (python -m train.cli.infer)
    7. Deploy (copiar checkpoint para API)
  - Screenshots (ou ASCII art) se poss√≠vel
- **Arquivos Afetados:**
  - NOVO: `train/docs/TUTORIAL.md`
- **Impacto Esperado:** Onboarding guiado

#### S8-T3: Criar Scripts de Exemplo
- **Categoria:** Docs + C√≥digo
- **Prioridade:** M√âDIA
- **Descri√ß√£o:**
  - Criar `train/examples/`
  - Scripts:
    - `01_quick_train.py`: treino m√≠nimo (1 epoch)
    - `02_inference_simple.py`: infer√™ncia b√°sica
    - `03_custom_dataset.py`: como criar dataset do zero
    - `04_resume_training.py`: continuar de checkpoint
  - Cada script com coment√°rios explicativos
- **Arquivos Afetados:**
  - NOVO: `train/examples/*.py`
- **Impacto Esperado:** Exemplos pr√°ticos

#### S8-T4: Integrar MLflow (Opcional)
- **Categoria:** MLOps
- **Prioridade:** BAIXA
- **Descri√ß√£o:**
  - Instalar MLflow: `pip install mlflow`
  - Modificar `run_training.py` para logar experimentos:
    ```python
    import mlflow
    with mlflow.start_run():
        mlflow.log_params(config)
        mlflow.log_metrics({"loss": loss})
        mlflow.log_artifact("model_last.pt")
    ```
  - Rodar UI: `mlflow ui --port 5000`
  - Documentar em `train/docs/MLFLOW.md`
- **Arquivos Afetados:**
  - Modificar: `train/run_training.py`
  - NOVO: `train/docs/MLFLOW.md`
- **Impacto Esperado:** Tracking de experimentos

#### S8-T5: Criar Dockerfile para Treino (Opcional)
- **Categoria:** DevOps
- **Prioridade:** BAIXA
- **Descri√ß√£o:**
  - Criar `docker/train/Dockerfile`
  - Base: `pytorch/pytorch:2.1.0-cuda11.8-cudnn8`
  - Instalar requirements-lock.txt
  - Copiar c√≥digo
  - Entrypoint: `python -m train.run_training`
  - Build: `docker build -t f5tts-train docker/train/`
  - Run: `docker run --gpus all -v $(pwd)/train:/app/train f5tts-train`
- **Arquivos Afetados:**
  - NOVO: `docker/train/Dockerfile`
  - NOVO: `docker/train/.dockerignore`
- **Impacto Esperado:** Ambiente reproduz√≠vel

#### S8-T6: Criar Script de Benchmark (Opcional)
- **Categoria:** MLOps
- **Prioridade:** BAIXA
- **Descri√ß√£o:**
  - Criar `train/scripts/benchmark.py`
  - Comparar checkpoints:
    ```bash
    python -m train.scripts.benchmark \
      --checkpoints model_epoch10.pt model_epoch50.pt \
      --test-texts test_samples.txt
    ```
  - M√©tricas: MCD, RTF, MOS estimado
  - Output: tabela Markdown
- **Arquivos Afetados:**
  - NOVO: `train/scripts/benchmark.py`
- **Impacto Esperado:** Compara√ß√£o objetiva

---

## Backlog Futuro / Ideias Extras

### Melhorias de Longo Prazo (n√£o inclu√≠das nas 8 sprints)

#### BL-1: Avalia√ß√£o Autom√°tica de MOS
- **Descri√ß√£o:** Usar modelo pr√©-treinado (ex: MOSNet) para estimar MOS de samples gerados
- **Benef√≠cio:** M√©trica de qualidade objetiva
- **Esfor√ßo:** 2-3 dias

#### BL-2: UI M√≠nima para Visualiza√ß√£o de Treino
- **Descri√ß√£o:** Dashboard web (Streamlit ou Gradio) para visualizar m√©tricas, samples, config
- **Benef√≠cio:** UX melhor que TensorBoard
- **Esfor√ßo:** 3-4 dias

#### BL-3: Suporte Multi-l√≠nguas no Pipeline
- **Descri√ß√£o:** Adaptar scripts de normaliza√ß√£o e transcri√ß√£o para outras l√≠nguas (EN, ES)
- **Benef√≠cio:** Reuso do pipeline
- **Esfor√ßo:** 2-3 dias

#### BL-4: Dataset Augmentation
- **Descri√ß√£o:** Adicionar pitch shift, time stretch, noise injection para aumentar dataset
- **Benef√≠cio:** Modelo mais robusto
- **Esfor√ßo:** 2 dias

#### BL-5: Distributed Training (Multi-GPU)
- **Descri√ß√£o:** Usar `accelerate` ou `torch.distributed` para treino multi-GPU
- **Benef√≠cio:** Treino mais r√°pido
- **Esfor√ßo:** 3-4 dias

#### BL-6: Continuous Integration (CI/CD)
- **Descri√ß√£o:** GitHub Actions para rodar testes, linting, build Docker em cada push
- **Benef√≠cio:** Qualidade garantida
- **Esfor√ßo:** 1-2 dias

#### BL-7: Versionamento de Datasets com DVC
- **Descri√ß√£o:** Usar DVC para versionar datasets e checkpoints
- **Benef√≠cio:** Reprodutibilidade total
- **Esfor√ßo:** 2 dias

#### BL-8: Notebook Interativo (Jupyter)
- **Descri√ß√£o:** Criar notebook `train/notebooks/training_demo.ipynb` com exemplos interativos
- **Benef√≠cio:** Explora√ß√£o f√°cil
- **Esfor√ßo:** 1 dia

#### BL-9: Otimiza√ß√£o de Hiperpar√¢metros (Optuna)
- **Descri√ß√£o:** Usar Optuna para buscar hiperpar√¢metros √≥timos (learning rate, batch size, etc.)
- **Benef√≠cio:** Melhor modelo
- **Esfor√ßo:** 3-4 dias

#### BL-10: API REST para Treino Remoto
- **Descri√ß√£o:** Endpoint `/api/train` para iniciar treino remotamente, monitorar via WebSocket
- **Benef√≠cio:** Treino como servi√ßo
- **Esfor√ßo:** 4-5 dias

---

## Resumo de Estimativas

| Sprint | Foco                                | Dura√ß√£o | Prioridade |
|--------|-------------------------------------|---------|------------|
| 1      | Unifica√ß√£o de Configura√ß√£o          | 2-3d    | üî¥ CR√çTICA |
| 2      | Checkpoint Path Consistency         | 2d      | üî¥ CR√çTICA |
| 3      | Refatora√ß√£o Pipeline de Dados       | 4-5d    | ‚ö†Ô∏è ALTA    |
| 4      | Reprodutibilidade e MLOps B√°sico    | 3d      | ‚ö†Ô∏è ALTA    |
| 5      | Experi√™ncia de Treino               | 3-4d    | üìä M√âDIA   |
| 6      | Experi√™ncia de Infer√™ncia           | 3d      | üìä M√âDIA   |
| 7      | Qualidade de C√≥digo e Testes        | 4d      | üìù BAIXA-M |
| 8      | Documenta√ß√£o e MLOps Avan√ßado       | 3-4d    | üìù BAIXA-M |
| **TOTAL** | **8 Sprints**                    | **24-30 dias** | - |

**Observa√ß√£o:** Estimativas s√£o para 1 desenvolvedor full-time. Com 2+ devs trabalhando em paralelo (sprints independentes), tempo total pode reduzir para ~15-20 dias.

---

## Crit√©rios de Aceita√ß√£o por Sprint

### Sprint 1
- [ ] `train/config/base_config.yaml` criado e completo
- [ ] `train/config/loader.py` com valida√ß√£o Pydantic funcionando
- [ ] Vocabul√°rio consolidado em 1 lugar com hash
- [ ] `run_training.py` usando config unificado
- [ ] CI verde (se existir)

### Sprint 2
- [ ] `train/utils/checkpoint.py::resolve_checkpoint_path()` funcionando
- [ ] `f5tts_engine.py` respeitando `F5TTS_CUSTOM_CHECKPOINT`
- [ ] Checkpoints validados antes de carregar
- [ ] `experiment.json` gerado ap√≥s treino

### Sprint 3 ‚úÖ COMPLETO
- [x] M√≥dulos `train/audio/`, `train/text/`, `train/io/` criados
- [x] Scripts reduzidos para <150 linhas (orquestradores)
- [x] Testes unit√°rios com >70% coverage em m√≥dulos cr√≠ticos

### Sprint 4 ‚úÖ COMPLETO
- [x] `requirements-lock.txt` gerado
- [x] Seed aplicado globalmente em treino e infer√™ncia
- [x] `make setup` funcionando
- [x] Health check script validando setup

### Sprint 5 ‚úÖ COMPLETO
- [x] Callbacks de best model e audio samples funcionando
- [x] CLI com typer aceita argumentos
- [x] Logs estruturados em JSON

### Sprint 6 ‚úÖ COMPLETO
- [x] `F5TTSInference` API unificada funcionando
- [x] API REST e scripts usando mesma implementa√ß√£o
- [x] CLI `train.cli.infer` funcionando

### Sprint 7 ‚úÖ COMPLETO
- [x] Linting (ruff) e formata√ß√£o (black) configurados
- [x] Mypy passando (ou com --ignore-missing-imports)
- [x] Pre-commit hooks instalados
- [x] Teste e2e passando

### Sprint 8 ‚úÖ COMPLETO
- [x] READMEs atualizados
- [x] Tutorial completo em `train/docs/TUTORIAL.md`
- [x] Scripts de exemplo funcionando
- [x] (Opcional) MLflow integrado - N√ÉO IMPLEMENTADO (opcional)

---

**Fim do Plano de Sprints**
