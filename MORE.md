# üìã An√°lise T√©cnica & Melhorias - TTS WebUI (XTTS-v2)

**Data**: 2025-12-06  
**Status**: P√≥s-remo√ß√£o F5-TTS, pr√©-implementa√ß√£o `train/` XTTS-v2  
**Tech Lead**: Claude Sonnet 4.5

---

## üéØ Contexto

Este projeto √© um servi√ßo TTS (Text-to-Speech) baseado em **XTTS-v2** (Coqui TTS) com suporte a:
- S√≠ntese de voz multil√≠ngue (foco pt-BR)
- Clonagem de voz via reference audio
- Pipeline RVC para modifica√ß√£o de voz
- API REST (FastAPI) + workers Celery
- Deploy Docker com GPU NVIDIA (CUDA 11.8)

**Recentemente completado**:
- ‚úÖ Remo√ß√£o total de F5-TTS (157 arquivos, 44k linhas, 84GB liberados)
- ‚úÖ Isolamento 100% Docker (Python VM limpo)
- ‚úÖ API funcionando com XTTS apenas

**Objetivo atual**: Criar pipeline completo de fine-tuning XTTS-v2 para pt-BR.

---

## üìä Categorias de An√°lise

### 1. üèóÔ∏è Arquitetura & Organiza√ß√£o

#### ‚úÖ Pontos Fortes
- Separa√ß√£o clara backend (FastAPI) + workers (Celery) + cache (Redis)
- Engines abstra√≠dos (`app/engines/base.py`, `xtts_engine.py`)
- Quality profiles configur√°veis por engine
- Docker Compose com NVIDIA runtime
- Volume mounts para acesso direto aos modelos (sem c√≥pia)

#### ‚ùå Problemas Identificados

1. **Falta pasta `train/` para fine-tuning XTTS-v2**
   - Severidade: **ALTA**
   - N√£o h√° estrutura para dataset preparation, training, checkpoints
   - Scripts √∫teis existem em `scripts/not_remove/` mas n√£o est√£o integrados

2. **Paths hardcoded espalhados pelo c√≥digo**
   - Severidade: M√âDIA
   - Exemplos: `/app/models/xtts/`, `/app/uploads/`, etc
   - Devem vir de `config.py` ou `.env`

3. **Documenta√ß√£o desatualizada**
   - Severidade: M√âDIA
   - `docs/LOW_VRAM.md`, `docs/QUALITY_PROFILES.md` ainda mencionam F5-TTS
   - Pode confundir novos desenvolvedores

4. **Falta namespace claro para scripts**
   - Severidade: BAIXA
   - `scripts/` mistura prod (`download_models.py`) com utils de manuten√ß√£o
   - `scripts/not_remove/` √© confuso (deveria ser `scripts/dataset/` ou similar)

#### üîß Melhorias Propostas

**P0 (Cr√≠tico)**:
- [ ] Criar estrutura `train/` completa (ver se√ß√£o 2)
- [ ] Centralizar paths em `app/config.py` usando `pathlib.Path`

**P1 (Importante)**:
- [ ] Limpar docs desatualizadas ou marcar como "DEPRECATED - F5-TTS removed"
- [ ] Renomear `scripts/not_remove/` ‚Üí `scripts/dataset/`
- [ ] Criar `scripts/training/` para scripts de treino XTTS

**P2 (Nice to have)**:
- [ ] Adicionar `pyproject.toml` completo (j√° existe stub)
- [ ] Migrar configs YAML para Pydantic Settings

---

### 2. üì¶ Data Pipeline (YouTube ‚Üí Dataset LJSpeech)

#### ‚úÖ Pontos Fortes
- Scripts funcionais em `scripts/not_remove/`:
  - `download_youtube.py` (yt-dlp)
  - `prepare_segments_optimized.py` (VAD + segmenta√ß√£o)
  - `transcribe_or_subtitles.py` (Whisper + legendas)
  - `build_metadata_csv.py` (formato LJSpeech)
- L√≥gica de VAD baseada em RMS (memory-efficient)
- Suporte a legendas como fallback

#### ‚ùå Problemas Identificados

1. **Scripts isolados, sem pipeline unificado**
   - Severidade: **ALTA**
   - Cada script roda manualmente, sem orquestra√ß√£o
   - Falta valida√ß√£o entre etapas (ex: verificar se transcri√ß√£o existe antes de build_metadata)

2. **Target de dura√ß√£o inadequado para XTTS-v2**
   - Severidade: M√âDIA
   - Scripts geram segmentos variados (3-30s)
   - XTTS-v2 ideal: **7-12s** (conforme docs oficiais)
   - Segmentos muito curtos (<5s) t√™m baixa qualidade; muito longos (>15s) OOM

3. **Sample rate inconsistente**
   - Severidade: M√âDIA
   - Alguns scripts usam 24kHz, outros 22.05kHz
   - XTTS-v2 requer **22050 Hz mono 16-bit**

4. **Normaliza√ß√£o de texto pt-BR incompleta**
   - Severidade: BAIXA
   - `normalize_transcriptions.py` existe mas falta integra√ß√£o
   - N√∫meros, siglas, timestamps n√£o s√£o expandidos consistentemente

5. **Falta valida√ß√£o de qualidade de √°udio**
   - Severidade: BAIXA
   - N√£o verifica SNR, clipping, sil√™ncios internos
   - Pode poluir dataset com amostras ruins

#### üîß Melhorias Propostas

**P0 (Cr√≠tico)**:
- [ ] Criar `train/scripts/pipeline.py` orquestrando:
  1. Download YouTube
  2. Segmenta√ß√£o VAD (target 7-12s, 22050Hz)
  3. Transcri√ß√£o Whisper
  4. Normaliza√ß√£o texto pt-BR
  5. Build LJSpeech dataset
  6. Valida√ß√£o qualidade
- [ ] Garantir **22050 Hz mono 16-bit** em todas as etapas
- [ ] Implementar filtros de dura√ß√£o: `min_duration=5s`, `max_duration=12s`

**P1 (Importante)**:
- [ ] Adicionar valida√ß√£o de SNR (threshold ~20dB)
- [ ] Detectar e remover segmentos com sil√™ncios longos internos (>1s)
- [ ] Expandir n√∫meros para texto (`"123" ‚Üí "cento e vinte e tr√™s"`)

**P2 (Nice to have)**:
- [ ] Suporte a m√∫ltiplas vozes (speaker ID no metadata.csv)
- [ ] Deduplica√ß√£o de frases repetidas (comum em podcasts)
- [ ] Data augmentation (pitch shift, tempo, reverb leve)

---

### 3. üéì Treinamento XTTS-v2

#### ‚úÖ Pontos Fortes
- Infraestrutura Docker com CUDA 11.8 + RTX 3090
- torch 2.4.0+cu118 funcionando
- coqui-tts instalado no container

#### ‚ùå Problemas Identificados

1. **N√£o existe script de treinamento**
   - Severidade: **CR√çTICA**
   - Projeto n√£o tem `xtts_train.py` ou similar
   - Sem configura√ß√£o de hiperpar√¢metros

2. **Falta modelo pretrained XTTS-v2**
   - Severidade: **ALTA**
   - N√£o h√° `models/xtts_pretrained/` com checkpoint base
   - Precisa baixar ou carregar via HuggingFace

3. **Sem suporte a LoRA**
   - Severidade: M√âDIA
   - Full fine-tune √© pesado (23GB VRAM)
   - LoRA permite treinar com 8-12GB

4. **Falta monitoramento de treino**
   - Severidade: BAIXA
   - Sem TensorBoard, WandB ou logs estruturados
   - Dif√≠cil debugar converg√™ncia

5. **Configura√ß√µes hardcoded**
   - Severidade: BAIXA
   - Batch size, epochs, LR deveriam vir de YAML/env

#### üîß Melhorias Propostas

**P0 (Cr√≠tico)**:
- [ ] Criar `train/scripts/xtts_train.py` com:
  - Carregamento modelo base XTTS-v2
  - LJSpeechDataset loader
  - Training loop com checkpoints
  - Valida√ß√£o samples a cada N epochs
- [ ] Criar `train/config/train_config.yaml`:
  ```yaml
  model:
    name: xtts_v2
    checkpoint: ./models/xtts_pretrained/model.pth
  training:
    batch_size: 4
    epochs: 50
    learning_rate: 1e-5
    max_text_length: 200
    max_audio_length: 12  # seconds
  dataset:
    path: ./train/data/MyTTSDataset
    language: pt-BR
    sample_rate: 22050
  ```
- [ ] Baixar modelo pretrained XTTS-v2:
  ```bash
  # Via Coqui TTS
  tts --model_name tts_models/multilingual/multi-dataset/xtts_v2 --list_models
  ```

**P1 (Importante)**:
- [ ] Implementar LoRA fine-tuning (par√¢metro `use_lora=True`)
- [ ] Adicionar TensorBoard logging
- [ ] Gerar √°udio samples a cada epoch (valida√ß√£o manual)
- [ ] Early stopping baseado em validation loss

**P2 (Nice to have)**:
- [ ] Mixed precision training (FP16)
- [ ] Gradient accumulation para batch_size efetivo maior
- [ ] Multi-GPU training (DataParallel)
- [ ] Curriculum learning (come√ßar com frases curtas)

---

### 4. üé§ API de Infer√™ncia & Clonagem

#### ‚úÖ Pontos Fortes
- API FastAPI funcionando (`app/main.py`)
- Engine factory pattern (`app/engines/factory.py`)
- Quality profiles configur√°veis
- Endpoint `/jobs` para TTS ass√≠ncrono
- Celery workers para processamento

#### ‚ùå Problemas Identificados

1. **Modelo fine-tunado n√£o integrado**
   - Severidade: **ALTA**
   - `xtts_engine.py` carrega apenas modelo base
   - Precisa suportar checkpoint custom em `train/output/checkpoints/`

2. **Voice cloning sem interface clara**
   - Severidade: M√âDIA
   - Endpoint `/voices/clone` existe mas docs n√£o explicam uso
   - Falta exemplo de curl com upload de reference.wav

3. **Falta endpoint de infer√™ncia direta (s√≠ncrono)**
   - Severidade: BAIXA
   - `/jobs` √© sempre ass√≠ncrono
   - √ötil ter `/tts/synthesize` para requests r√°pidos (<5s)

4. **Quality profiles ainda referenciam F5-TTS**
   - Severidade: BAIXA (j√° removido do c√≥digo, s√≥ docs)
   - Ver `docs/QUALITY_PROFILES.md`

#### üîß Melhorias Propostas

**P0 (Cr√≠tico)**:
- [ ] Modificar `app/engines/xtts_engine.py`:
  ```python
  def __init__(self, checkpoint_path: str = None):
      if checkpoint_path:
          self.model = self._load_custom_checkpoint(checkpoint_path)
      else:
          self.model = TTS("tts_models/multilingual/multi-dataset/xtts_v2")
  ```
- [ ] Adicionar env var:
  ```bash
  XTTS_CUSTOM_CHECKPOINT=/app/train/output/checkpoints/best_model.pth
  ```

**P1 (Importante)**:
- [ ] Criar endpoint s√≠ncrono:
  ```python
  @app.post("/tts/synthesize")
  async def synthesize(text: str, reference_audio: UploadFile = None):
      # Infer√™ncia direta, retorna WAV
  ```
- [ ] Documentar voice cloning no README:
  ```bash
  curl -X POST http://localhost:8005/voices/clone \
    -F "text=Ol√°, sou sua voz clonada" \
    -F "reference_audio=@speaker.wav" \
    -F "language=pt-BR"
  ```

**P2 (Nice to have)**:
- [ ] Batch inference (m√∫ltiplos textos de uma vez)
- [ ] Streaming TTS (retornar chunks de √°udio)
- [ ] Cache de embeddings de speaker (acelerar cloning)

---

### 5. üîß Ambiente & DevOps

#### ‚úÖ Pontos Fortes
- Docker Compose funcional
- Imagens otimizadas (9.8GB)
- NVIDIA runtime configurado
- Volume mounts (sem duplica√ß√£o de modelos)
- Healthchecks nos containers

#### ‚ùå Problemas Identificados

1. **Venv n√£o criada no projeto**
   - Severidade: M√âDIA
   - Desenvolvimento direto no sistema ou em Docker apenas
   - Sem `.venv/` local para IDEs

2. **Falta CI/CD**
   - Severidade: BAIXA
   - Sem GitHub Actions / GitLab CI
   - Testes manuais

3. **Logs n√£o estruturados**
   - Severidade: BAIXA
   - Logging via `print()` em alguns lugares
   - Falta JSON logging para parsing

4. **Secrets em `.env` commitado**
   - Severidade: **CR√çTICA (SEGURAN√áA)**
   - `.env` est√° no reposit√≥rio (verificar `.gitignore`)
   - API keys expostas?

#### üîß Melhorias Propostas

**P0 (Cr√≠tico)**:
- [ ] Verificar se `.env` est√° no `.gitignore`
- [ ] Criar `.env.example` sem secrets
- [ ] Rotacionar qualquer API key que esteja commitada

**P1 (Importante)**:
- [ ] Criar `ENV_SETUP.md` com:
  ```bash
  # Criar venv
  python3 -m venv .venv
  source .venv/bin/activate
  pip install -r requirements.txt
  
  # VSCode: Ctrl+Shift+P > "Python: Select Interpreter" > .venv
  ```
- [ ] Adicionar `pytest` em requirements-dev.txt
- [ ] Configurar logging estruturado (JSON) em produ√ß√£o

**P2 (Nice to have)**:
- [ ] GitHub Actions para testes
- [ ] Pre-commit hooks (black, isort, mypy)
- [ ] Docker registry privado (AWS ECR / GCP Artifact Registry)

---

### 6. ‚úÖ Qualidade de C√≥digo & Testes

#### ‚úÖ Pontos Fortes
- Type hints em alguns m√≥dulos
- Docstrings em fun√ß√µes cr√≠ticas
- Pytest configurado (`pytest.ini`)
- Alguns testes existem (`test_voice_cloning.py`)

#### ‚ùå Problemas Identificados

1. **Cobertura de testes baixa**
   - Severidade: M√âDIA
   - Maioria do c√≥digo sem testes
   - Falta testes de integra√ß√£o (API endpoints)

2. **Type hints incompletos**
   - Severidade: BAIXA
   - Muitas fun√ß√µes sem hints
   - Mypy n√£o configurado

3. **Duplica√ß√£o de c√≥digo**
   - Severidade: BAIXA
   - L√≥gica de paths repetida
   - Valida√ß√µes similares em m√∫ltiplos lugares

4. **Falta linting autom√°tico**
   - Severidade: BAIXA
   - Sem black, flake8, isort no projeto

#### üîß Melhorias Propostas

**P0 (Cr√≠tico)**:
- [ ] Adicionar testes para `train/scripts/`:
  - `test_download_youtube.py`
  - `test_segment_audio.py`
  - `test_transcribe.py`
  - `test_build_metadata.py`

**P1 (Importante)**:
- [ ] Configurar mypy:
  ```ini
  [mypy]
  python_version = 3.11
  warn_return_any = True
  warn_unused_configs = True
  disallow_untyped_defs = True
  ```
- [ ] Adicionar pre-commit:
  ```yaml
  repos:
    - repo: https://github.com/psf/black
      hooks:
        - id: black
    - repo: https://github.com/pycqa/isort
      hooks:
        - id: isort
  ```

**P2 (Nice to have)**:
- [ ] Coverage report (pytest-cov)
- [ ] Mutation testing (mutmut)
- [ ] Property-based testing (hypothesis)

---

### 7. üìö Documenta√ß√£o & DX (Developer Experience)

#### ‚úÖ Pontos Fortes
- README.md existente
- Docs em `docs/` (arquitetura, API, deployment)
- Changelog mantido
- Coment√°rios inline em c√≥digo complexo

#### ‚ùå Problemas Identificados

1. **Docs desatualizadas ap√≥s remo√ß√£o F5-TTS**
   - Severidade: M√âDIA
   - `docs/LOW_VRAM.md` - ainda menciona F5-TTS
   - `docs/QUALITY_PROFILES.md` - perfis F5-TTS documentados
   - `docs/CHANGELOG.md` - correto, mas confuso para novos devs

2. **Falta guia de contribui√ß√£o**
   - Severidade: BAIXA
   - Sem `CONTRIBUTING.md`
   - Novos devs n√£o sabem como setup ambiente

3. **API docs n√£o geradas automaticamente**
   - Severidade: BAIXA
   - FastAPI tem Swagger, mas n√£o documentado
   - Falta link no README para `http://localhost:8005/docs`

4. **Falta diagramas de arquitetura**
   - Severidade: BAIXA
   - Nenhuma imagem explicando fluxo de dados
   - Dificuldade para entender sistema rapidamente

#### üîß Melhorias Propostas

**P0 (Cr√≠tico)**:
- [ ] Atualizar docs com remo√ß√£o F5-TTS:
  - Marcar se√ß√µes obsoletas com "‚ö†Ô∏è DEPRECATED"
  - Adicionar nota: "F5-TTS removed in v2.0 - XTTS-only project"

**P1 (Importante)**:
- [ ] Criar `CONTRIBUTING.md`:
  ```markdown
  # Contributing
  
  ## Setup
  1. Clone repo
  2. Create venv: `python3 -m venv .venv`
  3. Install deps: `pip install -r requirements.txt -r requirements-dev.txt`
  4. Run tests: `pytest`
  
  ## Code Style
  - Black (line length 100)
  - isort
  - Type hints obrigat√≥rios
  
  ## Commit Messages
  - Conventional Commits: `feat:`, `fix:`, `docs:`, etc
  ```
- [ ] Adicionar no README:
  ```markdown
  ## API Documentation
  
  Acesse http://localhost:8005/docs (Swagger UI)
  ```

**P2 (Nice to have)**:
- [ ] Gerar diagramas com Mermaid:
  ```mermaid
  graph TD
    A[YouTube URL] --> B[download_youtube.py]
    B --> C[segment_audio.py]
    C --> D[transcribe_whisper.py]
    D --> E[build_metadata.py]
    E --> F[LJSpeech Dataset]
    F --> G[xtts_train.py]
    G --> H[Checkpoint]
    H --> I[API Inference]
  ```
- [ ] Gravar screencast de setup (Asciinema)
- [ ] Adicionar badges no README (build status, coverage, license)

---

## üéØ Resumo Executivo

### Problemas Cr√≠ticos (P0)

1. **Falta estrutura `train/` completa** ‚Üí Bloqueia fine-tuning
2. **Sem script de treinamento XTTS-v2** ‚Üí Core feature inexistente
3. **Modelo fine-tunado n√£o integr√°vel** ‚Üí Sem path para usar checkpoint custom
4. **Pipeline de dados desintegrado** ‚Üí Scripts isolados, sem orquestra√ß√£o
5. **Secrets em `.env` commitado** ‚Üí Risco de seguran√ßa

### Melhorias de Alto Impacto (P1)

1. Documenta√ß√£o atualizada (remover F5-TTS)
2. Valida√ß√£o de qualidade de √°udio (SNR, dura√ß√£o)
3. Suporte a LoRA fine-tuning
4. Endpoint s√≠ncrono de TTS
5. Setup de venv + CI b√°sico

### Quick Wins (P2)

1. Linting autom√°tico (black, isort)
2. Diagramas de arquitetura
3. Batch inference
4. Data augmentation

---

## üìã Pr√≥ximos Passos

Ver `SPRINTS.md` para plano detalhado de implementa√ß√£o em sprints.

**Recomenda√ß√£o**: Come√ßar pela **Sprint 1** (estrutura `train/` + pipeline dados).

---

**√öltima atualiza√ß√£o**: 2025-12-06  
**Mantido por**: Tech Lead (Claude Sonnet 4.5)
