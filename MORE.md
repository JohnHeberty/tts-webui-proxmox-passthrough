# Relat√≥rio T√©cnico ‚Äì Auditoria F5-TTS Project

**Data:** 06 de Dezembro de 2025  
**Vers√£o:** 1.0  
**Autor:** Tech Lead - An√°lise de C√≥digo e Arquitetura  
**Objetivo:** Auditoria completa do projeto de fine-tuning F5-TTS PT-BR para transforma√ß√£o em c√≥digo de n√≠vel profissional

---

## 1. Sum√°rio Executivo

### üî¥ 5-10 Principais Problemas / Riscos

1. **Config & Paths Fragmentados (CR√çTICO)**
   - Paths de dataset, checkpoints, vocoder e vocab espalhados em 5+ lugares diferentes (.env raiz, train/.env, YAML, c√≥digo Python)
   - Risco de modelo mudo/grunhidos por vocabul√°rio inconsistente entre treino e infer√™ncia

2. **Inconsist√™ncia Treino vs Infer√™ncia (ALTA)**
   - Scripts de treino (run_training.py) usam API do F5-TTS de forma diferente da infer√™ncia (AgentF5TTS, f5tts_engine.py)
   - `vocab_file`, `use_ema`, `device`, `vocoder` configurados de formas conflitantes
   - J√° existe hist√≥rico de bugs de checkpoint (ERROR.md, CHECKPOINT_FIX.md)

3. **Duplica√ß√£o de Configura√ß√£o (M√âDIA-ALTA)**
   - train/.env, train/config/train_config.yaml e train/config/dataset_config.yaml t√™m overlaps
   - Valores hardcoded em scripts Python sobrescrevem configs YAML
   - Imposs√≠vel saber qual config √© "source of truth"

4. **Vocabul√°rio Duplicado e Sem Versionamento (ALTA)**
   - 3 c√≥pias de vocab.txt em lugares diferentes (train/config/, train/data/, train/data/f5_dataset/)
   - Nenhuma garantia de que s√£o id√™nticos
   - Sem versionamento ou hash para validar consist√™ncia

5. **Pipeline de Dados Sem Separa√ß√£o de Responsabilidades (M√âDIA)**
   - Scripts gigantes que fazem tudo (download, corte, VAD, transcri√ß√£o, normaliza√ß√£o)
   - prepare_segments_optimized.py tem 570 linhas misturando l√≥gica de infra e dom√≠nio
   - Dif√≠cil testar, debugar e manter

6. **Falta de Reprodutibilidade Completa (M√âDIA)**
   - Seed definido apenas no .env (SEED=666), mas n√£o propagado consistentemente
   - Nenhum script de setup documentado para reproduzir ambiente exato
   - Vers√µes de depend√™ncias n√£o pinadas (requirements.txt usa >=, n√£o ==)

7. **Checkpoints sem Valida√ß√£o Autom√°tica (M√âDIA)**
   - run_training.py tem valida√ß√£o manual, mas n√£o √© executada antes de carregar checkpoint
   - Hist√≥rico de checkpoints corrompidos (CHECKPOINT_FIX.md)
   - Sem verifica√ß√£o de hash/tamanho esperado

8. **Logging e Debugging Insuficientes (BAIXA-M√âDIA)**
   - Logs espalhados em v√°rios arquivos sem rota√ß√£o
   - Falta de structured logging (JSON) para facilitar parsing
   - Sem n√≠veis de log configur√°veis por m√≥dulo

9. **Testes Ausentes para Pipeline de Treino (M√âDIA)**
   - Testes existem apenas para app/ (API REST), n√£o para train/
   - Nenhum teste de fuma√ßa para pipeline de dados, load de checkpoint, infer√™ncia p√≥s-treino
   - Imposs√≠vel validar mudan√ßas sem rodar pipeline completo

10. **DX (Developer Experience) Ruim (BAIXA)**
    - README gen√©rico na raiz, documenta√ß√£o de treino s√≥ em train/README.md
    - Scripts sem docstrings completas
    - Nomes de arquivos confusos (_deprecated/, scripts de experimento misturados com "oficiais")

### ‚úÖ 5-10 Principais Oportunidades

1. **Unifica√ß√£o de Configura√ß√£o**
   - Centralizar toda config em um √∫nico lugar (ex: train/config.yaml com overrides via .env)
   - Criar classes de configura√ß√£o Python (Pydantic) para valida√ß√£o e type safety

2. **Separa√ß√£o Clara de Responsabilidades**
   - Camada de dom√≠nio (TTS, Dataset, Models) separada de infra (paths, logging, CLI)
   - Utilit√°rios gen√©ricos (normaliza√ß√£o, VAD, etc.) em m√≥dulos reutiliz√°veis

3. **Pipeline de Dados Modular**
   - Quebrar scripts gigantes em fun√ß√µes/classes pequenas e test√°veis
   - Pipeline em etapas: Download ‚Üí Segment ‚Üí Transcribe ‚Üí Normalize ‚Üí Validate ‚Üí Build Dataset
   - Cada etapa com interface clara (input/output)

4. **Experi√™ncia de Treino Melhorada**
   - Callbacks personalizados (early stopping, checkpoint, metrics)
   - M√©tricas al√©m de loss (ex: MCD, MOS estimado, dura√ß√£o m√©dia)
   - CLI mais amig√°vel com argumentos validados (typer ou click)

5. **Experi√™ncia de Infer√™ncia Simplificada**
   - API unificada para infer√™ncia (mesma interface para AgentF5TTS e f5tts_engine.py)
   - CLI de teste r√°pido (python -m train.infer --checkpoint X --text "..." --output Y)
   - Service layer para encapsular l√≥gica de load/cache de modelo

6. **Documenta√ß√£o e Exemplos**
   - README por pasta (train/, train/scripts/, train/utils/)
   - Scripts de exemplo (examples/) com casos de uso reais
   - Tutorial passo-a-passo para iniciantes

7. **Testes Automatizados**
   - Testes de fuma√ßa para cada script (pytest)
   - Fixtures para datasets pequenos de teste
   - Testes de integra√ß√£o para pipeline completo (smoke test end-to-end)

8. **MLOps e Reproducibilidade**
   - Versionamento de datasets (DVC ou similar)
   - Registro de experimentos (MLflow ou Weights & Biases)
   - Scripts de setup autom√°tico (make setup, docker-compose para treino)

9. **Qualidade de C√≥digo**
   - Linting (ruff ou flake8) e formata√ß√£o (black)
   - Type hints em todas as fun√ß√µes
   - Pre-commit hooks

10. **Monitoramento e Debugging**
    - Structured logging (loguru com JSON)
    - Health checks para validar setup antes de treinar
    - Script de benchmark para comparar checkpoints

---

## 2. Erros e Problemas por Categoria

### 2.1 Config & Paths

#### **P1: Paths de Dataset Fragmentados**

**Localiza√ß√£o:**
- `.env` (raiz): `F5TTS_CUSTOM_CHECKPOINT=/app/train/output/ptbr_finetuned2/model_last.pt`
- `train/.env`: `DATASET_PATH=train/data/f5_dataset`, `OUTPUT_DIR=train/output/ptbr_finetuned2`
- `train/config/train_config.yaml`: `dataset_path: "./train/data/f5_dataset"`, `output_dir: "train/output/ptbr_finetuned2"`
- `train/config/dataset_config.yaml`: (n√£o define paths base, apenas subpaths relativos)
- C√≥digo Python hardcoded em scripts

**Descri√ß√£o:**
Existem pelo menos 4 fontes de verdade para paths cr√≠ticos:
1. .env na raiz (usado pela API de infer√™ncia)
2. train/.env (usado pelo run_training.py via env_loader.py)
3. train_config.yaml (parcialmente usado, mas sobrescrito por .env)
4. Hardcoded em scripts (ex: AgentF5TTSChunk.py linha 182: `/home/tts-webui-proxmox-passthrough/train/config/vocab.txt`)

**Impacto:**
- **CR√çTICO**: Se paths divergirem, modelo pode treinar em um dataset mas inferir esperando outro
- Dif√≠cil manter sincronizado quando mudar estrutura de pastas
- Onboarding de novos devs √© confuso

**Severidade:** ALTA

**Solu√ß√£o:**
1. Criar `train/config/paths.yaml` (ou se√ß√£o `paths:` em config unificado)
2. Todos os scripts devem importar de um √∫nico m√≥dulo `train.config.paths`
3. Usar vari√°veis de ambiente apenas para overrides em deploy (n√£o como config principal)
4. Validar paths no startup (se n√£o existir, criar ou falhar com erro claro)

---

#### **P2: Vocabul√°rio Duplicado sem Garantia de Consist√™ncia**

**Localiza√ß√£o:**
- `train/config/vocab.txt` (2546 linhas)
- `train/data/vocab.txt` (n√£o verificado se id√™ntico)
- `train/data/f5_dataset/vocab.txt` (idem)

**Descri√ß√£o:**
Existem 3 c√≥pias do vocab.txt em lugares diferentes. Nenhum script verifica se s√£o id√™nticos.

F5-TTS espera que treino e infer√™ncia usem o MESMO vocab.txt. Se forem diferentes:
- Modelo pode gerar tokens fora do vocabul√°rio ‚Üí grunhidos, ru√≠dos
- Embeddings de texto ficam misalinhados

**Impacto:**
- **ALTO**: Risco de modelo mudo ou com qualidade ruim
- Debugging dif√≠cil (bug silencioso, s√≥ aparece em produ√ß√£o)

**Severidade:** ALTA

**Solu√ß√£o:**
1. Manter vocab.txt em UM √öNICO LUGAR: `train/config/vocab.txt` (source of truth)
2. Scripts que precisam de vocab devem:
   - Copiar de `train/config/vocab.txt` para o destino
   - OU criar symlink
   - OU passar path como argumento
3. Adicionar hash/checksum no in√≠cio do arquivo (coment√°rio): `# SHA256: abc123...`
4. Script de valida√ß√£o: `python -m train.scripts.validate_vocab` que verifica hash

---

#### **P3: Checkpoint Path Inconsistente entre Treino e Infer√™ncia**

**Localiza√ß√£o:**
- Treino: `run_training.py` busca checkpoints em ordem: `train/output/`, `ckpts/`, `models/f5tts/`
- Infer√™ncia API: `f5tts_engine.py` linha 221: baixa de HuggingFace e aplica patch
- Infer√™ncia Script: `AgentF5TTSChunk.py` linha 180: usa path hardcoded `/app/train/output/ptbr_finetuned2/model_last.pt`
- .env raiz: `F5TTS_CUSTOM_CHECKPOINT=/app/train/output/ptbr_finetuned2/model_last.pt`

**Descri√ß√£o:**
Cada contexto (treino, infer√™ncia API, script de teste) tem l√≥gica diferente para localizar checkpoint.

Problema espec√≠fico:
- `f5tts_engine.py` sempre baixa modelo do HuggingFace e aplica patch (linhas 239-300)
- N√£o respeita `F5TTS_CUSTOM_CHECKPOINT` do .env para usar checkpoint local fine-tunado
- Usu√°rio treina modelo, mas API continua usando modelo base PT-BR

**Impacto:**
- **M√âDIO-ALTO**: Fine-tuning n√£o √© usado em produ√ß√£o (API ignora)
- Tempo desperdi√ßado treinando se n√£o for usado
- Confus√£o: "por que meu modelo n√£o melhorou?"

**Severidade:** ALTA

**Solu√ß√£o:**
1. Criar fun√ß√£o utilit√°ria: `train.utils.checkpoint.resolve_checkpoint_path(priority_list, fallback)`
2. Usar SEMPRE a mesma l√≥gica em treino, infer√™ncia API e scripts
3. Prioridade recomendada:
   - 1¬∫: Env var `F5TTS_CUSTOM_CHECKPOINT` (se existir arquivo)
   - 2¬∫: train/output/{exp_name}/model_last.pt
   - 3¬∫: Download do HuggingFace
4. Logar claramente qual checkpoint foi carregado

---

#### **P4: Config YAML vs .env vs Hardcoded: Quem Manda?**

**Localiza√ß√£o:**
- `train/config/train_config.yaml`: define `learning_rate: 1.0e-4`, `batch_size_per_gpu: 4`, etc.
- `train/.env`: define `LEARNING_RATE=0.0001`, `BATCH_SIZE=2`, etc.
- `train/utils/env_loader.py`: faz merge com `.env` tendo prioridade sobre YAML
- Scripts Python: alguns sobrescrevem com valores hardcoded

**Descri√ß√£o:**
Hierarquia de preced√™ncia n√£o √© clara:
- `train_config.yaml` parece ser config "oficial" (mais completo)
- Mas `env_loader.py` carrega `.env` que sobrescreve YAML
- E ainda tem hardcoded em alguns scripts

Exemplo:
```python
# train_config.yaml
batch_size_per_gpu: 4

# train/.env
BATCH_SIZE=2

# env_loader.py retorna
'batch_size': 2  # ‚Üê .env vence
```

**Impacto:**
- **M√âDIO**: Confus√£o sobre qual config est√° realmente ativa
- Dificulta reproduzir experimentos
- Erros silenciosos (mudou YAML mas n√£o teve efeito)

**Severidade:** M√âDIA

**Solu√ß√£o:**
1. Definir hierarquia clara e documentada:
   - N√≠vel 1 (padr√£o): `train/config/defaults.yaml`
   - N√≠vel 2 (override): `train/config/train_config.yaml` (usu√°rio edita)
   - N√≠vel 3 (override de deploy): `train/.env` (apenas para CI/CD)
   - N√≠vel 4 (override tempor√°rio): argumentos CLI `--learning-rate 0.0002`
2. Implementar com OmegaConf ou Hydra (bibliotecas especializadas em config)
3. Validar config no startup e logar valores finais

---

### 2.2 Treino vs Infer√™ncia

#### **P5: Uso de `vocab_file` Diferente entre Treino e Infer√™ncia**

**Localiza√ß√£o:**
- Treino: `run_training.py` chama `finetune_cli` que usa vocab padr√£o do F5-TTS (ou n√£o especifica)
- Infer√™ncia API: `f5tts_engine.py` linha 150: `load_model(vocab_file='', ...)` (usa padr√£o da lib)
- Infer√™ncia Script: `AgentF5TTSChunk.py` linha 182: `vocab_file="/home/.../train/config/vocab.txt"`
- train_config.yaml linha 18: `vocab_file: "/home/.../train/config/vocab.txt"` (mas n√£o usado no c√≥digo)

**Descri√ß√£o:**
Scripts de infer√™ncia passam `vocab_file` explicitamente, mas treino n√£o.

F5-TTS tem vocab padr√£o em `f5_tts/configs/vocab.txt` (multilingual). Se treino usa vocab padr√£o mas infer√™ncia usa customizado (ou vice-versa), embeddings ficam incompat√≠veis.

**Impacto:**
- **ALTO**: Modelo pode gerar √°udio corrompido (grunhidos, cortes)
- Bug dif√≠cil de diagnosticar (s√≥ aparece em certas palavras)

**Severidade:** ALTA

**Solu√ß√£o:**
1. Sempre especificar `vocab_file` tanto no treino quanto na infer√™ncia
2. Usar o mesmo arquivo: `train/config/vocab.txt` (source of truth)
3. Adicionar valida√ß√£o: se checkpoint foi treinado com vocab X, infer√™ncia deve usar vocab X
   - Salvar hash do vocab nos metadados do checkpoint
   - Validar na carga

---

#### **P6: `use_ema` Inconsistente**

**Localiza√ß√£o:**
- Treino: `train_config.yaml` linha 74: `use_ema: true`
- Infer√™ncia API: `f5tts_engine.py` linha 150: `use_ema=True`
- Infer√™ncia Script: `AgentF5TTSChunk.py` linha 28: `use_ema=True`
- Mas: checkpoint baixado de HuggingFace tem bug de prefix (ema. vs ema_model.)

**Descri√ß√£o:**
Todos usam `use_ema=True`, que est√° correto.

Por√©m, h√° hist√≥rico de bug no checkpoint PT-BR (ERROR.md): chaves com prefix `ema.` em vez de `ema_model.`, causando falha no load.

Solu√ß√£o foi implementada (IMPLEMENTATION_COMPLETE.md), mas c√≥digo ainda tem l√≥gica de patch em `f5tts_engine.py` (linhas 239-300). Isso adiciona complexidade e pode quebrar se formato de checkpoint mudar.

**Impacto:**
- **M√âDIO**: C√≥digo funciona, mas √© fr√°gil
- Patch hardcoded dificulta manuten√ß√£o
- Se F5-TTS mudar formato, patch pode falhar silenciosamente

**Severidade:** M√âDIA

**Solu√ß√£o:**
1. Usar checkpoints no formato correto desde o in√≠cio
2. Se patch for necess√°rio, mover para script separado: `python -m train.scripts.patch_checkpoint input.pt output.pt`
3. N√£o fazer patch em runtime (lento, arriscado)
4. Documentar formato esperado de checkpoint em `train/docs/CHECKPOINT_FORMAT.md`

---

#### **P7: Device Selection Duplicada**

**Localiza√ß√£o:**
- `f5tts_engine.py` linha 117: `self.device = self._select_device(device, fallback_to_cpu)`
- `AgentF5TTSChunk.py` linha 14: `device=None` (auto-detect na F5TTS API)
- `run_training.py`: usa `env_loader.py` que retorna `device` do .env

**Descri√ß√£o:**
Cada m√≥dulo tem l√≥gica pr√≥pria de sele√ß√£o de device:
- API Engine: m√©todo `_select_device()` com fallback
- Script: passa `None` e deixa F5TTS decidir
- Treino: l√™ do .env

N√£o h√° garantia de que todos usam mesma l√≥gica. Por exemplo:
- Se GPU n√£o estiver dispon√≠vel, API pode falhar mas script pode funcionar em CPU
- Logs diferentes dificultam debug

**Impacto:**
- **BAIXO-M√âDIO**: Funciona, mas inconsistente
- Dificulta debug (comportamento diferente entre contextos)

**Severidade:** BAIXA

**Solu√ß√£o:**
1. Criar fun√ß√£o utilit√°ria: `train.utils.device.select_device(preferred, fallback_to_cpu)`
2. Usar em todos os contextos (treino, infer√™ncia, scripts)
3. Logar decis√£o: "Using device: cuda:0 (preferred) / cpu (fallback)"

---

### 2.3 Data Pipeline / Pr√©-processamento

#### **P8: Scripts Gigantes Violam SRP (Single Responsibility Principle)**

**Localiza√ß√£o:**
- `prepare_segments_optimized.py`: 570 linhas, faz: VAD, segmenta√ß√£o, normaliza√ß√£o, resample, fade
- `transcribe_or_subtitles.py`: 756 linhas, faz: download legendas, Whisper ASR, normaliza√ß√£o, QA
- `prepare_f5_dataset.py`: 210 linhas, faz: leitura metadata, filtragem, convers√£o Arrow

**Descri√ß√£o:**
Scripts tentam fazer tudo em um arquivo monol√≠tico:
- L√≥gica de dom√≠nio (VAD, normaliza√ß√£o) misturada com infra (paths, logging, CLI)
- Fun√ß√µes enormes (ex: `iter_voice_regions` tem 100+ linhas)
- Dif√≠cil extrair para reutilizar em outros contextos

**Impacto:**
- **M√âDIO**: Manuten√ß√£o dif√≠cil, bugs escondem-se em fun√ß√µes longas
- Testes imposs√≠veis (como testar VAD sem rodar script inteiro?)
- Duplica√ß√£o (normaliza√ß√£o est√° em 2 scripts diferentes)

**Severidade:** M√âDIA

**Solu√ß√£o:**
1. Refatorar em m√≥dulos:
   ```
   train/audio/
     vad.py           # Voice Activity Detection
     segmentation.py  # Audio segmentation
     normalization.py # Audio normalization
     effects.py       # Fade, filters
   train/text/
     normalizer.py    # Text normalization (j√° existe!)
     qa.py            # Quality assurance
   train/io/
     youtube.py       # YouTube download
     subtitles.py     # Subtitle extraction
   ```
2. Scripts principais viram "orquestradores" finos que chamam fun√ß√µes

---

#### **P9: VAD Simples Demais para Casos Complexos**

**Localiza√ß√£o:**
- `prepare_segments_optimized.py` linha 90-150: implementa√ß√£o de VAD baseada em RMS energy

**Descri√ß√£o:**
VAD implementado √© baseado apenas em energia RMS (dB). Problemas:
- Falha com m√∫sica de fundo (pega tudo como voz)
- Falha com ru√≠do de fundo constante (ar condicionado, ventilador)
- Threshold fixo (-40dB) pode n√£o funcionar para todos os √°udios

F5-TTS precisa de segmentos limpos. VAD ruim pode incluir sil√™ncios ou cortar palavras.

**Impacto:**
- **M√âDIO-ALTO**: Dataset com segmentos ruins ‚Üí modelo ruim
- Usu√°rio precisa validar manualmente (trabalhoso)

**Severidade:** M√âDIA

**Solu√ß√£o:**
1. Adicionar op√ß√£o de VAD avan√ßado (Silero VAD, WebRTC VAD)
2. Fazer VAD configur√°vel no dataset_config.yaml:
   ```yaml
   segmentation:
     vad_method: "energy"  # energy, silero, webrtc
     vad_threshold: -40
   ```
3. Para casos cr√≠ticos, permitir VAD manual (Audacity, script com visualiza√ß√£o)

---

#### **P10: Normaliza√ß√£o de √Åudio Pode Ser Agressiva Demais**

**Localiza√ß√£o:**
- `dataset_config.yaml` linha 25: `target_lufs: -23.0`
- `prepare_segments_optimized.py`: usa pyloudnorm com esse valor

**Descri√ß√£o:**
LUFS -23 √© padr√£o broadcast, mas pode ser muito alto para treino TTS.

Se √°udio original √© -30 LUFS, normalizar para -23 aumenta volume +7dB. Isso pode:
- Amplificar ru√≠do de fundo
- Causar clipping (se headroom for insuficiente)
- Mudar caracter√≠sticas naturais da voz

**Impacto:**
- **BAIXO-M√âDIO**: Pode degradar qualidade do dataset
- Dif√≠cil diagnosticar (modelo parece OK mas tem artefatos sutis)

**Severidade:** BAIXA

**Solu√ß√£o:**
1. Testar diferentes valores de LUFS (-23, -24, -26)
2. Fazer an√°lise de distribui√ß√£o de loudness no dataset original
3. Considerar normaliza√ß√£o adaptativa (s√≥ normalizar se fora de range aceit√°vel)
4. Documentar escolha em `train/docs/AUDIO_PROCESSING.md`

---

#### **P11: Falta de Valida√ß√£o de Qualidade P√≥s-Processamento**

**Localiza√ß√£o:**
- `prepare_segments_optimized.py`: processa segmentos mas n√£o valida qualidade
- `validate_and_reprocess.py`: existe mas n√£o √© executado automaticamente

**Descri√ß√£o:**
Scripts de processamento n√£o validam automaticamente se output est√° bom:
- Dura√ß√£o dos segmentos (muito curtos/longos?)
- SNR (signal-to-noise ratio)
- Clipping
- Sample rate correto

Validation script existe (`validate_and_reprocess.py`) mas deve ser rodado manualmente.

**Impacto:**
- **M√âDIO**: Segmentos ruins entram no dataset
- Descoberto tarde (ap√≥s treinar)

**Severidade:** M√âDIA

**Solu√ß√£o:**
1. Integrar valida√ß√£o no final do pipeline de processamento
2. Gerar relat√≥rio: `train/data/processed/validation_report.json`
3. Incluir m√©tricas:
   - N√∫mero de segmentos
   - Dura√ß√£o min/max/m√©dia
   - SNR estimado
   - Taxa de clipping
4. Rejeitar automaticamente segmentos abaixo de threshold

---

### 2.4 Qualidade de C√≥digo & Arquitetura

#### **P12: Falta de Type Hints e Docstrings**

**Localiza√ß√£o:**
- Maioria das fun√ß√µes em `train/scripts/` n√£o tem type hints
- Docstrings incompletas ou ausentes

**Descri√ß√£o:**
Exemplo de `prepare_segments_optimized.py`:
```python
def detect_voice_in_chunk(audio_chunk: np.ndarray, sr: int, seg_config: dict):  # ‚Üê tem types
    """..."""  # ‚Üê tem docstring
    ...

def process_audio_file(input_path, output_dir, config):  # ‚Üê sem types
    # sem docstring
    ...
```

Inconsistente. Dificulta entender o que cada fun√ß√£o faz/espera.

**Impacto:**
- **BAIXO-M√âDIO**: DX ruim, erros de tipo n√£o detectados
- Onboarding lento

**Severidade:** BAIXA

**Solu√ß√£o:**
1. Adicionar type hints em todas as fun√ß√µes p√∫blicas
2. Usar mypy para valida√ß√£o est√°tica
3. Docstrings no formato Google ou NumPy
4. Pre-commit hook para garantir

---

#### **P13: Mistura de L√≥gica de Neg√≥cio e Infra**

**Localiza√ß√£o:**
- Scripts em `train/scripts/` misturam CLI parsing, logging, paths e l√≥gica de dom√≠nio

**Descri√ß√£o:**
Exemplo de padr√£o ruim:
```python
def main():
    # CLI parsing
    # Setup logging
    # Load config
    # Create directories
    # Business logic
    # Save results
    # Print summary
```

Tudo em uma fun√ß√£o. Dificulta:
- Testar apenas a l√≥gica de neg√≥cio
- Reutilizar em outros contextos (API, notebook)
- Mockar depend√™ncias (filesystem, logging)

**Impacto:**
- **M√âDIO**: C√≥digo n√£o test√°vel, n√£o reutiliz√°vel
- Duplica√ß√£o inevit√°vel

**Severidade:** M√âDIA

**Solu√ß√£o:**
1. Aplicar Arquitetura em Camadas:
   ```
   CLI layer ‚Üí Service layer ‚Üí Domain layer
   ```
2. CLI apenas faz parsing e chama service
3. Service orquestra dom√≠nio e infra
4. Dom√≠nio √© puro (sem I/O, sem logging)
5. Exemplo:
   ```python
   # Domain
   def segment_audio(audio: np.ndarray, params: SegmentParams) -> List[Segment]:
       ...
   
   # Service
   class AudioProcessingService:
       def process_file(self, input_path: Path, output_dir: Path) -> ProcessResult:
           audio = self.audio_loader.load(input_path)
           segments = segment_audio(audio, self.params)
           self.audio_saver.save_all(segments, output_dir)
           return ProcessResult(...)
   
   # CLI
   def main():
       service = AudioProcessingService(config)
       result = service.process_file(Path(args.input), Path(args.output))
       print(result)
   ```

---

#### **P14: Acoplamento Excessivo a Paths Absolutos**

**Localiza√ß√£o:**
- `AgentF5TTSChunk.py` linha 180: `/home/tts-webui-proxmox-passthrough/...`
- `train_config.yaml` linha 18: `/home/tts-webui-proxmox-passthrough/...`

**Descri√ß√£o:**
Paths absolutos hardcoded no c√≥digo. Problemas:
- N√£o funciona em outro ambiente (Docker, outro usu√°rio, CI/CD)
- Dificulta colabora√ß√£o (cada dev precisa editar)

**Impacto:**
- **BAIXO-M√âDIO**: C√≥digo n√£o port√°vel
- Onboarding frustrante

**Severidade:** BAIXA

**Solu√ß√£o:**
1. Usar paths relativos a PROJECT_ROOT
2. Definir PROJECT_ROOT dinamicamente:
   ```python
   PROJECT_ROOT = Path(__file__).parent.parent.parent.resolve()
   ```
3. Configs em YAML devem usar paths relativos
4. Se path absoluto for necess√°rio, usar env var

---

### 2.5 MLOps / Reprodutibilidade

#### **P15: Depend√™ncias N√£o Pinadas**

**Localiza√ß√£o:**
- `requirements-f5tts.txt`: `f5-tts>=1.1.9` (usa >=, n√£o ==)
- `train/requirements_train.txt`: `torch>=2.0.0`, `accelerate>=0.25.0`, etc.

**Descri√ß√£o:**
Vers√µes n√£o pinadas causam problemas:
- Hoje funciona com torch 2.1, amanh√£ sai torch 2.5 com breaking change
- Imposs√≠vel reproduzir ambiente exato
- CI/CD pode falhar aleatoriamente

**Impacto:**
- **M√âDIO**: Reprodutibilidade quebrada
- Bug "funciona na minha m√°quina"

**Severidade:** M√âDIA

**Solu√ß√£o:**
1. Gerar `requirements-lock.txt` com vers√µes exatas:
   ```bash
   pip freeze > requirements-lock.txt
   ```
2. OU usar poetry/pipenv com lock file
3. Atualizar depend√™ncias de forma controlada (n√£o autom√°tica)

---

#### **P16: Seed N√£o Propagado Consistentemente**

**Localiza√ß√£o:**
- `train/.env`: `SEED=666`
- `env_loader.py` linha 105: retorna `'seed': 666`
- Mas: n√£o h√° c√≥digo que define `torch.manual_seed()`, `np.random.seed()`, `random.seed()`

**Descri√ß√£o:**
Seed √© lido do .env mas n√£o aplicado globalmente.

Para reprodutibilidade, √© preciso:
```python
torch.manual_seed(seed)
torch.cuda.manual_seed_all(seed)
np.random.seed(seed)
random.seed(seed)
torch.backends.cudnn.deterministic = True
```

Sem isso, cada run ter√° resultados diferentes.

**Impacto:**
- **M√âDIO**: Experimentos n√£o reproduz√≠veis
- Dificulta compara√ß√£o de checkpoints

**Severidade:** M√âDIA

**Solu√ß√£o:**
1. Criar `train/utils/reproducibility.py`:
   ```python
   def set_seed(seed: int, deterministic: bool = True):
       torch.manual_seed(seed)
       ...
   ```
2. Chamar no in√≠cio de `run_training.py` e scripts de infer√™ncia
3. Documentar que determinism pode afetar performance (~10% mais lento)

---

#### **P17: Falta de Registro de Experimentos**

**Localiza√ß√£o:**
- TensorBoard √© usado (`train/runs/`), mas logs n√£o s√£o estruturados
- Nenhum registro de hiperpar√¢metros, vers√£o do c√≥digo, dataset usado

**Descri√ß√£o:**
Para reproduzir experimento, √© preciso saber:
- Hiperpar√¢metros exatos
- Vers√£o do c√≥digo (commit hash)
- Dataset usado (path, n√∫mero de amostras, dura√ß√£o)
- Modelo base (checkpoint inicial)

Atualmente, essas informa√ß√µes est√£o espalhadas (logs, .env, YAML) e n√£o s√£o versionadas juntas.

**Impacto:**
- **M√âDIO**: Imposs√≠vel reproduzir experimento depois
- "Por que esse checkpoint era bom?"

**Severidade:** M√âDIA

**Solu√ß√£o:**
1. Adicionar MLflow ou Weights & Biases
2. Logar no in√≠cio do treino:
   ```python
   mlflow.log_params({
       'learning_rate': config['learning_rate'],
       'batch_size': config['batch_size'],
       'dataset_path': config['dataset_path'],
       'git_commit': subprocess.check_output(['git', 'rev-parse', 'HEAD']).decode().strip(),
       'seed': config['seed'],
   })
   ```
3. OU criar arquivo `train/output/{exp_name}/experiment.json` com essas infos

---

#### **P18: Checkpoints sem Metadata Completo**

**Localiza√ß√£o:**
- `run_training.py` salva checkpoints via `finetune_cli`
- Formato √© controlado pela lib F5-TTS

**Descri√ß√£o:**
Checkpoints devem ter metadata:
- Vers√£o do c√≥digo
- Config completa
- M√©tricas finais (loss, epoch)
- Vocab usado (hash)
- Dataset usado

Sem isso, √© dif√≠cil saber "com o que esse checkpoint foi treinado?".

**Impacto:**
- **BAIXO-M√âDIO**: Debugging dif√≠cil
- Checkpoints "√≥rf√£os" (sem saber origem)

**Severidade:** BAIXA

**Solu√ß√£o:**
1. Ap√≥s salvar checkpoint, adicionar arquivo `model_last.metadata.json`:
   ```json
   {
     "timestamp": "2025-12-06T10:00:00Z",
     "git_commit": "abc123",
     "config": {...},
     "vocab_hash": "sha256:...",
     "dataset": {
       "path": "train/data/f5_dataset",
       "num_samples": 5000,
       "total_duration_hours": 10.5
     },
     "metrics": {
       "final_loss": 0.123,
       "final_epoch": 50
     }
   }
   ```
2. Validar ao carregar checkpoint

---

### 2.6 DX (Developer Experience) & Organiza√ß√£o do Projeto

#### **P19: README Gen√©rico, Documenta√ß√£o Fragmentada**

**Localiza√ß√£o:**
- `README.md` (raiz): foca na API REST, n√£o menciona treino
- `train/README.md`: completo mas separado
- `train/docs/`: alguns docs, mas n√£o indexados

**Descri√ß√£o:**
Novo dev clona repo e n√£o sabe:
- Onde come√ßar?
- Como treinar modelo?
- Onde est√° documenta√ß√£o de cada m√≥dulo?

**Impacto:**
- **BAIXO-M√âDIO**: Onboarding lento
- Perguntas repetidas

**Severidade:** BAIXA

**Solu√ß√£o:**
1. README.md raiz deve ter se√ß√£o "Training" com link para train/README.md
2. Criar `train/docs/INDEX.md` listando todos os docs
3. README por pasta:
   - `train/scripts/README.md`: descreve cada script
   - `train/utils/README.md`: descreve utilit√°rios
4. Adicionar diagrama de arquitetura (draw.io ou mermaid)

---

#### **P20: Nome de Arquivos Confuso**

**Localiza√ß√£o:**
- `prepare_segments_optimized.py`: por que "optimized"? Otimizado em rela√ß√£o a qu√™?
- `_deprecated/`: scripts antigos misturados no repo
- `AgentF5TTSChunk.py`: nome n√£o intuitivo (o que √© "Agent"? O que √© "Chunk"?)

**Descri√ß√£o:**
Nomes n√£o seguem conven√ß√£o clara:
- Alguns com underscore (`prepare_segments_optimized.py`)
- Outros camelCase (`AgentF5TTSChunk.py`)
- Alguns com sufixos (`_optimized`, `_or_subtitles`)

**Impacto:**
- **BAIXO**: Confus√£o, mas funciona
- DX ruim

**Severidade:** BAIXA

**Solu√ß√£o:**
1. Conven√ß√£o de nomes:
   - Scripts: `snake_case.py`
   - Classes: `CamelCase`
   - Fun√ß√µes: `snake_case`
2. Renomear:
   - `prepare_segments_optimized.py` ‚Üí `prepare_segments.py` (se √© o √∫nico, n√£o precisa sufixo)
   - `AgentF5TTSChunk.py` ‚Üí `f5tts_inference.py` ou `f5tts_cli.py`
3. Mover `_deprecated/` para fora do repo (ou deletar se n√£o precisa)

---

#### **P21: Falta de Scripts de Setup Automatizado**

**Localiza√ß√£o:**
- N√£o h√° `make setup` ou `scripts/setup.sh`
- README diz "pip install ...", mas n√£o valida

**Descri√ß√£o:**
Novo dev precisa:
1. Instalar Python 3.11
2. Criar venv
3. Instalar deps (requirements.txt + requirements-f5tts.txt + train/requirements_train.txt)
4. Baixar modelos
5. Criar diret√≥rios

Sem script automatizado, cada dev faz de forma diferente ‚Üí erros.

**Impacto:**
- **BAIXO-M√âDIO**: Onboarding lento
- Ambiente inconsistente

**Severidade:** BAIXA

**Solu√ß√£o:**
1. Criar `Makefile`:
   ```makefile
   setup:
       python3.11 -m venv .venv
       .venv/bin/pip install -r requirements.txt -r requirements-f5tts.txt -r train/requirements_train.txt
       .venv/bin/python -m train.scripts.download_models
       mkdir -p train/{data,output,runs,logs}
   
   validate:
       .venv/bin/python -m train.scripts.validate_setup
   ```
2. README: "Run `make setup` to get started"

---

## 3. Oportunidades de Melhoria

### 3.1 Experi√™ncia de Treino

#### **O1: Callbacks Personalizados para Treino**

**Descri√ß√£o:**
F5-TTS usa callbacks (early stopping j√° existe). Adicionar:
- Callback para salvar best model (baseado em val loss, n√£o apenas last)
- Callback para gerar samples de √°udio a cada N epochs (j√° existe parcialmente)
- Callback para enviar notifica√ß√£o (email/Slack) quando treino terminar

**Benef√≠cio:**
- Menos babysitting
- Valida√ß√£o autom√°tica de qualidade

**Implementa√ß√£o:**
```python
class AudioSampleCallback:
    def on_epoch_end(self, epoch, model):
        if epoch % 5 == 0:
            generate_sample(model, text="Teste", output=f"sample_epoch{epoch}.wav")

class BestModelCallback:
    def on_validation_end(self, val_loss, model):
        if val_loss < self.best_loss:
            save_checkpoint(model, "model_best.pt")
            self.best_loss = val_loss
```

---

#### **O2: M√©tricas Al√©m de Loss**

**Descri√ß√£o:**
Atualmente, apenas loss √© logado. Adicionar:
- MCD (Mel Cepstral Distortion): mede distor√ß√£o em rela√ß√£o a ref
- Dura√ß√£o m√©dia dos samples gerados
- Taxa de NaN/Inf em gradientes

**Benef√≠cio:**
- Melhor visibilidade de qualidade
- Detectar overfitting cedo

**Implementa√ß√£o:**
- Usar bibliotecas: `pymcd`, `librosa`
- Logar no TensorBoard como scalar

---

#### **O3: CLI de Treino Mais Amig√°vel**

**Descri√ß√£o:**
Atualmente: `python -m train.run_training` (sem argumentos).

Config vem de .env e YAML. Usu√°rio n√£o consegue fazer quick test com params diferentes.

**Benef√≠cio:**
- Experimenta√ß√£o r√°pida
- Valida√ß√£o de argumentos

**Implementa√ß√£o:**
Usar `typer` ou `click`:
```python
@app.command()
def train(
    config: Path = typer.Option("train/config/train_config.yaml"),
    learning_rate: float = typer.Option(None),
    epochs: int = typer.Option(None),
):
    cfg = load_config(config)
    if learning_rate:
        cfg['learning_rate'] = learning_rate
    ...
```

---

### 3.2 Experi√™ncia de Infer√™ncia

#### **O4: API Unificada para Infer√™ncia**

**Descri√ß√£o:**
Atualmente:
- API REST usa `f5tts_engine.py` (classe `F5TtsEngine`)
- Scripts usam `AgentF5TTS` (wrapper de `F5TTS` da lib)
- C√≥digo duplicado

**Benef√≠cio:**
- Mesma interface em todos os contextos
- Menos duplica√ß√£o

**Implementa√ß√£o:**
```python
class F5TTSInference:
    def __init__(self, checkpoint_path, vocab_file, device):
        ...
    
    def generate(self, text: str, ref_audio: Path, ref_text: str = "") -> np.ndarray:
        ...

# Usado por API Engine
# Usado por CLI
# Usado por notebooks
```

---

#### **O5: CLI de Teste R√°pido**

**Descri√ß√£o:**
Para testar checkpoint rapidamente:
```bash
python -m train.infer \
    --checkpoint train/output/model_last.pt \
    --text "Ol√°, mundo!" \
    --ref-audio ref.wav \
    --output output.wav
```

**Benef√≠cio:**
- Valida√ß√£o r√°pida ap√≥s treino
- N√£o precisa subir API

**Implementa√ß√£o:**
- Script `train/infer.py` (CLI)
- Usa API unificada (O4)

---

#### **O6: Service Layer para Cache de Modelo**

**Descri√ß√£o:**
Atualmente, modelo √© carregado toda vez.

Service layer pode:
- Cachear modelo em mem√≥ria
- Lazy load (s√≥ carrega quando necess√°rio)
- Unload ap√≥s timeout

**Benef√≠cio:**
- Infer√™ncia mais r√°pida (n√£o recarrega modelo)
- Economia de VRAM (unload quando n√£o usado)

**Implementa√ß√£o:**
```python
class F5TTSService:
    _instance = None
    _model = None
    
    @classmethod
    def get_instance(cls):
        if cls._instance is None:
            cls._instance = cls()
        return cls._instance
    
    def generate(self, ...):
        if self._model is None:
            self._model = load_model(...)
        return self._model.infer(...)
```

---

### 3.3 Organiza√ß√£o do C√≥digo

#### **O7: M√≥dulos Especializados**

**Descri√ß√£o:**
Criar estrutura clara:
```
train/
  audio/          # Audio processing (VAD, segment, normalize)
  text/           # Text processing (normalize, QA)
  data/           # Dataset loading, Arrow format
  models/         # Model wrappers, checkpoint utils
  training/       # Training loop, callbacks
  inference/      # Inference API
  io/             # YouTube, files, storage
  utils/          # Generic utils (device, seed, logging)
  cli/            # CLI commands
```

**Benef√≠cio:**
- C√≥digo organizado
- F√°cil encontrar o que precisa

---

#### **O8: Camada de Abstra√ß√£o para F5-TTS**

**Descri√ß√£o:**
F5-TTS √© lib externa. Criar abstra√ß√£o:
```python
class F5TTSWrapper:
    def train(self, dataset, config) -> Checkpoint:
        ...
    
    def infer(self, checkpoint, text, ref_audio) -> Audio:
        ...
```

**Benef√≠cio:**
- Se F5-TTS mudar API, s√≥ atualiza wrapper
- Facilita testes (mock do wrapper)

---

### 3.4 Documenta√ß√£o e Exemplos

#### **O9: README por Pasta**

**Descri√ß√£o:**
Cada pasta importante deve ter README:
- `train/scripts/README.md`: lista scripts e uso
- `train/utils/README.md`: descreve utilit√°rios
- `train/audio/README.md`: explica processamento de √°udio

**Benef√≠cio:**
- Documenta√ß√£o local (perto do c√≥digo)
- F√°cil navegar

---

#### **O10: Scripts de Exemplo**

**Descri√ß√£o:**
Criar pasta `train/examples/`:
- `example_01_quick_train.py`: treino m√≠nimo
- `example_02_inference.py`: infer√™ncia simples
- `example_03_custom_dataset.py`: como criar dataset

**Benef√≠cio:**
- Onboarding r√°pido
- Mostra uso correto da API

---

#### **O11: Tutorial Passo-a-Passo**

**Descri√ß√£o:**
Criar `train/docs/TUTORIAL.md`:
1. Setup do ambiente
2. Preparar dataset
3. Treinar modelo
4. Testar infer√™ncia
5. Deploy

**Benef√≠cio:**
- Guia completo para iniciantes
- Reduz perguntas

---

### 3.5 Testes Automatizados

#### **O12: Testes de Fuma√ßa para Cada Script**

**Descri√ß√£o:**
Criar `tests/train/` com testes:
- `test_prepare_segments.py`: testa segmenta√ß√£o com √°udio fake
- `test_transcribe.py`: testa transcri√ß√£o (mock Whisper)
- `test_build_metadata.py`: testa constru√ß√£o de metadata

**Benef√≠cio:**
- Detecta bugs cedo
- Confian√ßa em refatorar

**Implementa√ß√£o:**
```python
def test_segment_audio():
    audio = np.random.randn(24000)  # 1 segundo
    segments = segment_audio(audio, params)
    assert len(segments) > 0
    assert all(len(s) > 0 for s in segments)
```

---

#### **O13: Fixtures para Datasets de Teste**

**Descri√ß√£o:**
Criar mini dataset:
```
tests/fixtures/
  audio/
    sample_01.wav  # 5s
    sample_02.wav  # 10s
  metadata.csv
```

**Benef√≠cio:**
- Testes r√°pidos (n√£o precisa dataset real)
- Reproduz√≠vel

---

#### **O14: Teste de Integra√ß√£o End-to-End**

**Descri√ß√£o:**
Teste que executa pipeline completo:
1. Download fake audio
2. Segment
3. Transcribe
4. Build dataset
5. Train (1 epoch)
6. Infer

**Benef√≠cio:**
- Garante pipeline funciona
- Smoke test antes de deploy

---

### 3.6 MLOps e Reproducibilidade

#### **O15: Versionamento de Datasets (DVC)**

**Descri√ß√£o:**
Usar DVC para versionar datasets:
```bash
dvc add train/data/f5_dataset
git add train/data/f5_dataset.dvc
```

**Benef√≠cio:**
- Dataset versionado junto com c√≥digo
- Reproduzir experimentos antigos

---

#### **O16: Registro de Experimentos (MLflow)**

**Descri√ß√£o:**
Integrar MLflow:
```python
with mlflow.start_run():
    mlflow.log_params(config)
    mlflow.log_metrics({"loss": loss})
    mlflow.log_artifact("model_last.pt")
```

**Benef√≠cio:**
- Comparar experimentos facilmente
- UI web para visualizar

---

#### **O17: Docker para Treino**

**Descri√ß√£o:**
Criar `docker/train/Dockerfile`:
```dockerfile
FROM pytorch/pytorch:2.1.0-cuda11.8-cudnn8
COPY requirements.txt .
RUN pip install -r requirements.txt
...
```

**Benef√≠cio:**
- Ambiente reproduz√≠vel
- F√°cil deploy em cloud

---

### 3.7 Qualidade de C√≥digo

#### **O18: Linting e Formata√ß√£o**

**Descri√ß√£o:**
Adicionar:
- `ruff` (linter r√°pido)
- `black` (formatter)
- `isort` (organiza imports)

**Benef√≠cio:**
- C√≥digo consistente
- Menos code review sobre estilo

**Implementa√ß√£o:**
```bash
pip install ruff black isort
ruff check train/
black train/
isort train/
```

---

#### **O19: Type Checking com mypy**

**Descri√ß√£o:**
Adicionar mypy:
```bash
mypy train/ --strict
```

**Benef√≠cio:**
- Detecta erros de tipo
- Documenta√ß√£o viva (types)

---

#### **O20: Pre-commit Hooks**

**Descri√ß√£o:**
Criar `.pre-commit-config.yaml`:
```yaml
repos:
  - repo: https://github.com/psf/black
    hooks:
      - id: black
  - repo: https://github.com/astral-sh/ruff-pre-commit
    hooks:
      - id: ruff
```

**Benef√≠cio:**
- Qualidade garantida antes de commit
- Menos erros no CI

---

### 3.8 Monitoramento e Debugging

#### **O21: Structured Logging com Loguru**

**Descri√ß√£o:**
Substituir logging padr√£o por loguru:
```python
from loguru import logger

logger.add("train/logs/train.json", format="{time} {level} {message}", serialize=True)
logger.info("Training started", config=config)
```

**Benef√≠cio:**
- Logs estruturados (JSON)
- F√°cil parsing/an√°lise

---

#### **O22: Health Check Script**

**Descri√ß√£o:**
Script que valida setup antes de treinar:
```python
python -m train.scripts.health_check

‚úÖ CUDA dispon√≠vel: Tesla V100
‚úÖ Dataset encontrado: 5000 samples
‚úÖ Vocab consistente: SHA256 match
‚úÖ Disk space: 50GB dispon√≠vel
‚ö†Ô∏è  RAM: 8GB (recomendado: 16GB)
```

**Benef√≠cio:**
- Detecta problemas antes de treinar
- Evita falhas no meio do treino

---

#### **O23: Script de Benchmark**

**Descri√ß√£o:**
Comparar checkpoints:
```python
python -m train.scripts.benchmark \
    --checkpoints model_epoch10.pt model_epoch50.pt \
    --test-set test_samples.txt

# Output:
| Checkpoint      | MCD  | RTF  | MOS (est) |
|-----------------|------|------|-----------|
| model_epoch10   | 5.2  | 1.5  | 3.8       |
| model_epoch50   | 4.1  | 1.4  | 4.2       |
```

**Benef√≠cio:**
- Compara√ß√£o objetiva
- Decidir qual checkpoint usar

---

## 4. Recomenda√ß√µes Priorit√°rias

### üî¥ Prioridade CR√çTICA (Sprint 1-2)

1. **[P1] Unificar Configura√ß√£o de Paths**
   - Resolver duplica√ß√£o de paths em .env, YAML e c√≥digo
   - Criar m√≥dulo `train.config.paths` (source of truth)
   - **Impacto:** Elimina risco de modelo usar dataset/vocab errado

2. **[P2] Garantir Consist√™ncia de Vocabul√°rio**
   - Consolidar vocab.txt em um √∫nico lugar com hash
   - Validar que treino e infer√™ncia usam mesmo vocab
   - **Impacto:** Previne modelo mudo/grunhidos

3. **[P5] Validar vocab_file em Treino e Infer√™ncia**
   - Sempre especificar vocab_file explicitamente
   - Adicionar valida√ß√£o de hash no checkpoint
   - **Impacto:** Qualidade de √°udio garantida

### ‚ö†Ô∏è Prioridade ALTA (Sprint 3-4)

4. **[P3] Corrigir Checkpoint Path para Fine-tuning**
   - f5tts_engine.py deve respeitar `F5TTS_CUSTOM_CHECKPOINT`
   - Criar fun√ß√£o utilit√°ria para resolver checkpoint path
   - **Impacto:** Fine-tuning usado em produ√ß√£o

5. **[P8] Refatorar Scripts Gigantes**
   - Quebrar em m√≥dulos menores (audio/, text/, io/)
   - Separar l√≥gica de neg√≥cio de infra
   - **Impacto:** C√≥digo test√°vel e manuten√≠vel

6. **[P15] Pinar Depend√™ncias**
   - Gerar requirements-lock.txt com vers√µes exatas
   - **Impacto:** Reprodutibilidade garantida

### üìä Prioridade M√âDIA (Sprint 5-6)

7. **[P4] Definir Hierarquia de Config Clara**
   - Documentar preced√™ncia: defaults ‚Üí YAML ‚Üí .env ‚Üí CLI
   - Implementar com OmegaConf ou Hydra
   - **Impacto:** Menos confus√£o

8. **[P16] Aplicar Seed Globalmente**
   - Criar utils/reproducibility.py
   - Chamar no in√≠cio de treino e infer√™ncia
   - **Impacto:** Experimentos reproduz√≠veis

9. **[O12-O14] Adicionar Testes Automatizados**
   - Testes de fuma√ßa para cada script
   - Fixtures para datasets de teste
   - Teste end-to-end
   - **Impacto:** Confian√ßa em refatorar

10. **[O1-O3] Melhorar Experi√™ncia de Treino**
    - Callbacks personalizados
    - M√©tricas al√©m de loss
    - CLI mais amig√°vel
    - **Impacto:** Produtividade

### üìù Prioridade BAIXA (Backlog)

11. **[P19-P21] Melhorar DX**
    - README organizado
    - Scripts de setup
    - Conven√ß√£o de nomes
    - **Impacto:** Onboarding

12. **[O15-O17] MLOps Avan√ßado**
    - DVC para datasets
    - MLflow para experimentos
    - Docker para treino
    - **Impacto:** Profissionaliza√ß√£o

13. **[O18-O20] Qualidade de C√≥digo**
    - Linting, formata√ß√£o, type checking
    - Pre-commit hooks
    - **Impacto:** Consist√™ncia

---

## 5. Refer√™ncias Utilizadas

### F5-TTS Oficial

- **PyPI:** https://pypi.org/project/f5-tts/
- **HuggingFace:** https://huggingface.co/firstpixel/F5-TTS-pt-br
- **GitHub:** https://github.com/SWivid/F5-TTS

### Boas Pr√°ticas

- **Clean Architecture:** Robert C. Martin
- **SOLID Principles:** Design patterns para OOP
- **MLOps Best Practices:** ML Code Smells (Google, 2020)
- **Python Type Hints:** PEP 484, mypy documentation
- **Config Management:** OmegaConf, Hydra docs

### Ferramentas Recomendadas

- **Linting:** ruff (https://github.com/astral-sh/ruff)
- **Formatting:** black (https://github.com/psf/black)
- **Type Checking:** mypy (https://mypy.readthedocs.io/)
- **Config:** OmegaConf (https://omegaconf.readthedocs.io/)
- **Logging:** loguru (https://loguru.readthedocs.io/)
- **Experiments:** MLflow (https://mlflow.org/)
- **Dataset Versioning:** DVC (https://dvc.org/)

---

**Fim do Relat√≥rio MORE.md**
