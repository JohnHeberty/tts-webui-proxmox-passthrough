services:
  audio-voice-service:
    build: .
    container_name: audio-voice-api
    runtime: nvidia
    ports:
      - "${PORT:-8005}:8005"
    volumes:
      - ./app:/app/app
      - ./uploads:/app/uploads
      - ./processed:/app/processed
      - ./temp:/app/temp
      - ./voice_profiles:/app/voice_profiles
      - ./models:/app/models
      - ./logs:/app/logs
      - /usr/lib/x86_64-linux-gnu/libnvidia-ml.so.1:/usr/lib/x86_64-linux-gnu/libnvidia-ml.so.1:ro
      - /usr/lib/x86_64-linux-gnu/libcuda.so.1:/usr/lib/x86_64-linux-gnu/libcuda.so.1:ro
    env_file:
      - .env
    environment:
      - PYTHONPATH=/app
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
      - XTTS_DEVICE=cuda
      - XTTS_MODEL=tts_models/multilingual/multi-dataset/xtts_v2
      - XTTS_FALLBACK_CPU=true
      - MPLCONFIGDIR=/app/temp/.matplotlib
    deploy:
      resources:
        limits:
          memory: 8G
        reservations:
          memory: 4G
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:8005/ || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 90s

  celery-worker:
    build: .
    container_name: audio-voice-celery
    runtime: nvidia
    command: python -m celery -A app.celery_config worker --loglevel=info --concurrency=1 --pool=solo --queues=audio_voice_queue
    volumes:
      - ./app:/app/app
      - ./uploads:/app/uploads
      - ./processed:/app/processed
      - ./temp:/app/temp
      - ./voice_profiles:/app/voice_profiles
      - ./models:/app/models
      - ./logs:/app/logs
      - /usr/lib/x86_64-linux-gnu/libnvidia-ml.so.1:/usr/lib/x86_64-linux-gnu/libnvidia-ml.so.1:ro
      - /usr/lib/x86_64-linux-gnu/libcuda.so.1:/usr/lib/x86_64-linux-gnu/libcuda.so.1:ro
    env_file:
      - .env
    environment:
      - PYTHONPATH=/app
      - C_FORCE_ROOT=true
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
      - XTTS_DEVICE=cuda
      - XTTS_MODEL=tts_models/multilingual/multi-dataset/xtts_v2
      - XTTS_FALLBACK_CPU=true
      - MPLCONFIGDIR=/app/temp/.matplotlib
    deploy:
      resources:
        limits:
          memory: 8G
        reservations:
          memory: 4G
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    restart: unless-stopped
    depends_on:
      audio-voice-service:
        condition: service_healthy

  # nginx-webui service REMOVED - using /webui2 endpoint directly
  # Reason: Simplify architecture, improve code quality
  # See: DECISAO_REMOVER_NGINX.md for full justification
