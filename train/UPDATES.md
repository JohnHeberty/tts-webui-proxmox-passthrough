# ğŸš€ AtualizaÃ§Ãµes do Training Pipeline - Dezembro 2024

## âœ¨ Novas Funcionalidades

### ğŸ›‘ Early Stopping AutomÃ¡tico
O pipeline agora para automaticamente se o modelo nÃ£o melhorar por 3 epochs consecutivas.

**ConfiguraÃ§Ã£o** (`train/config/train_config.yaml`):
```yaml
training:
  early_stop_patience: 3      # Para apÃ³s 3 epochs sem melhora
  early_stop_min_delta: 0.001 # Melhora mÃ­nima considerada (0.1%)
```

**Uso**:
```bash
# Com early stopping (recomendado)
python3 -m train.train_with_early_stopping

# Sem early stopping (treinamento completo)
python3 -m train.run_training
```

**BenefÃ­cios**:
- â±ï¸ **Economiza tempo**: Para quando o modelo convergiu
- ğŸ’° **Economiza recursos**: NÃ£o desperdiÃ§a GPU/eletricidade
- ğŸ“Š **Evita overfitting**: Para antes do modelo decorar o dataset

---

### ğŸ”„ Retomada AutomÃ¡tica de Treinamento

O pipeline detecta automaticamente checkpoints anteriores e continua de onde parou.

**DetecÃ§Ã£o automÃ¡tica**:
```bash
# Se existir checkpoint em train/output/ptbr_finetuned/, continua automaticamente
python3 -m train.run_training
```

**ForÃ§ar novo treinamento**:
```bash
# Ignorar checkpoints e comeÃ§ar do zero
python3 -m train.run_training --fresh-start
```

**Checkpoint manual**:
```bash
# Continuar de um checkpoint especÃ­fico
python3 -m train.run_training --resume train/output/ptbr_finetuned/model_500.pt
```

**Como funciona**:
1. Verifica se existe `model_last.pt` no output dir
2. Se nÃ£o, procura por `model_*.pt` (model_500.pt, model_1000.pt, etc)
3. Carrega o checkpoint mais recente automaticamente
4. Continua treinamento do ponto exato onde parou

---

### ğŸ“Š RelatÃ³rio Completo de MÃ©tricas

Novo script de anÃ¡lise que mostra **mÃ©tricas reais** do treinamento.

**Executar**:
```bash
python3 -m train.scripts.test_model
```

**Output exemplo**:
```
================================================================================
ğŸ“Š RELATÃ“RIO COMPLETO DE MÃ‰TRICAS - F5-TTS FINE-TUNING
================================================================================

ğŸ“ˆ EVOLUÃ‡ÃƒO DO TREINAMENTO
--------------------------------------------------------------------------------
Epoch      Loss            Updates         Melhora        
--------------------------------------------------------------------------------
1          0.6760          75              -              
2          0.5860          150             +13.31%        
3          0.5450          225             +7.00%         
4          0.5000          300             +8.26%         
5          0.4750          375             +5.00%         
6          0.4520          450             +4.84%         
7          0.4450          525             +1.55%         
8          0.4420          600             +0.67%         
9          0.4380          675             +0.90%         
10         0.4350          750             +0.68%         
--------------------------------------------------------------------------------
ğŸ“Š Loss inicial: 0.6760
ğŸ“Š Loss final: 0.4350
ğŸ“Š ReduÃ§Ã£o total: 35.65%
ğŸ“Š Total de updates: 750

ğŸ’¾ CHECKPOINTS SALVOS
--------------------------------------------------------------------------------
ğŸ“ model_500.pt
   Tamanho: 5124.8 MB
   ParÃ¢metros: 366 tensores

ğŸ“ model_last.pt
   Tamanho: 5124.8 MB
   ParÃ¢metros: 366 tensores

ğŸ”Š AMOSTRAS DE ÃUDIO GERADAS
--------------------------------------------------------------------------------
   update_500_gen.wav (392.1 KB)
   update_500_ref.wav (392.1 KB)

ğŸ“Š LOGS DO TENSORBOARD
--------------------------------------------------------------------------------
   ğŸ“‚ runs/None
      9 arquivo(s) de eventos

ğŸ’¡ Para visualizar no TensorBoard:
   export PATH="$HOME/.local/bin:$PATH"
   tensorboard --logdir=runs
   Acesse: http://localhost:6006
```

**InformaÃ§Ãµes incluÃ­das**:
- âœ… EvoluÃ§Ã£o do loss epoch por epoch
- âœ… Percentual de melhora entre epochs
- âœ… Checkpoints salvos (tamanho, parÃ¢metros)
- âœ… Amostras de Ã¡udio geradas
- âœ… LocalizaÃ§Ã£o dos logs do TensorBoard

---

### ğŸ“Š TensorBoard Funcionando

TensorBoard agora estÃ¡ **validado e funcionando**.

**Iniciar TensorBoard**:
```bash
# Adicionar ao PATH
export PATH="$HOME/.local/bin:$PATH"

# Iniciar servidor
tensorboard --logdir=runs

# Acessar no navegador
# http://localhost:6006
```

**MÃ©tricas visualizadas**:
- ğŸ“‰ Training loss ao longo do tempo
- ğŸ“Š Learning rate schedule
- ğŸ”Š Amostras de Ã¡udio (geradas vs referÃªncia)
- ğŸ“ˆ Gradientes e pesos do modelo

**LocalizaÃ§Ã£o dos logs**:
- DiretÃ³rio: `./runs/`
- Arquivos: `events.out.tfevents.*`

---

## ğŸ¯ Workflow Recomendado

### 1ï¸âƒ£ Primeiro Treinamento (do zero)
```bash
# Treinar com early stopping
python3 -m train.train_with_early_stopping
```

O treinamento:
- âœ… Carrega modelo prÃ©-treinado pt-br (363/364 layers)
- âœ… Treina atÃ© 10 epochs OU atÃ© convergir
- âœ… Para automaticamente se nÃ£o melhorar por 3 epochs
- âœ… Salva checkpoints a cada 100 updates
- âœ… Gera amostras de Ã¡udio a cada 500 updates

### 2ï¸âƒ£ Continuar Treinamento
```bash
# Detecta automaticamente Ãºltimo checkpoint e continua
python3 -m train.run_training

# OU com early stopping
python3 -m train.train_with_early_stopping
```

### 3ï¸âƒ£ Treinar Mais Epochs (se parou cedo)
```bash
# Aumentar epochs no config
vim train/config/train_config.yaml
# Alterar: epochs: 20

# Continuar treinamento
python3 -m train.run_training
```

### 4ï¸âƒ£ Analisar Resultados
```bash
# Ver mÃ©tricas completas
python3 -m train.scripts.test_model

# Visualizar no TensorBoard
export PATH="$HOME/.local/bin:$PATH"
tensorboard --logdir=runs
# Abrir http://localhost:6006
```

---

## âš™ï¸ ConfiguraÃ§Ã£o

### Early Stopping

**Habilitar** (`train/config/train_config.yaml`):
```yaml
training:
  early_stop_patience: 3       # Parar apÃ³s 3 epochs sem melhora
  early_stop_min_delta: 0.001  # Melhora mÃ­nima de 0.1%
```

**Desabilitar**:
```yaml
training:
  early_stop_patience: 0  # Desabilitado
```

### Checkpoints

**FrequÃªncia de salvamento**:
```yaml
checkpoints:
  save_per_updates: 500        # Checkpoint completo a cada 500 updates
  last_per_updates: 100        # Checkpoint "last" a cada 100 updates
  keep_last_n_checkpoints: 5   # Manter apenas 5 checkpoints
```

### TensorBoard

**Logging**:
```yaml
logging:
  logger: "tensorboard"  # ou "wandb" ou null
  log_samples: true      # Gerar amostras de Ã¡udio
```

---

## ğŸ“ Estrutura de Outputs

```
train/output/ptbr_finetuned/
â”œâ”€â”€ model_500.pt          # Checkpoint @ 500 updates
â”œâ”€â”€ model_last.pt         # Ãšltimo checkpoint (mais recente)
â””â”€â”€ samples/
    â”œâ”€â”€ update_500_gen.wav  # Ãudio gerado @ update 500
    â””â”€â”€ update_500_ref.wav  # Ãudio referÃªncia

runs/
â””â”€â”€ None/
    â””â”€â”€ events.out.tfevents.*  # Logs do TensorBoard

train/logs/
â”œâ”€â”€ training.log               # Log completo
â””â”€â”€ training_interactive.log   # Log interativo (Ãºltimas execuÃ§Ãµes)
```

---

## ğŸ› Troubleshooting

### TensorBoard nÃ£o inicia

**Problema**: `tensorboard: command not found`

**SoluÃ§Ã£o**:
```bash
# Adicionar .local/bin ao PATH
export PATH="$HOME/.local/bin:$PATH"

# Testar
tensorboard --version
```

### Early Stopping muito agressivo

**Problema**: Para cedo demais

**SoluÃ§Ã£o**: Aumentar patience
```yaml
training:
  early_stop_patience: 5  # Aumentar para 5 epochs
```

### Checkpoint nÃ£o detectado

**Problema**: NÃ£o continua automaticamente

**Verificar**:
```bash
ls -lh train/output/ptbr_finetuned/
```

**ForÃ§ar manualmente**:
```bash
python3 -m train.run_training --resume train/output/ptbr_finetuned/model_last.pt
```

### MÃ©tricas nÃ£o aparecem

**Problema**: `test_model.py` nÃ£o mostra dados

**Verificar logs**:
```bash
# Log deve existir
ls -lh train/logs/training_interactive.log

# Ver conteÃºdo
tail -100 train/logs/training_interactive.log
```

---

## ğŸ“š DocumentaÃ§Ã£o Adicional

- **README Principal**: `train/README.md` - Pipeline completo
- **Quick Start**: `train/QUICKSTART.md` - Comandos rÃ¡pidos
- **Este arquivo**: `train/UPDATES.md` - Novas funcionalidades

---

## âœ… Checklist de ValidaÃ§Ã£o

Antes de treinar, verifique:

- [ ] TensorBoard instalado e funcionando
- [ ] Config atualizado (`train/config/train_config.yaml`)
- [ ] Dataset preparado (`train/data/f5_dataset/raw.arrow`)
- [ ] Modelo prÃ©-treinado baixado (`models/f5tts/pt-br/`)
- [ ] Early stopping configurado (se desejado)

ApÃ³s treinamento:

- [ ] Checkpoints salvos (`train/output/ptbr_finetuned/`)
- [ ] MÃ©tricas visualizadas (`python3 -m train.scripts.test_model`)
- [ ] TensorBoard conferido (http://localhost:6006)
- [ ] Amostras de Ã¡udio geradas (`train/output/ptbr_finetuned/samples/`)

---

**Data**: Dezembro 2024  
**VersÃ£o**: 2.0 - Early Stopping + Retomada AutomÃ¡tica + MÃ©tricas Completas
