# F5-TTS Text Processing Modules

M√≥dulos de processamento de texto para o pipeline de treinamento F5-TTS.

## M√≥dulos Dispon√≠veis

### üìù `normalizer.py` - Text Normalization
Normaliza√ß√£o de texto para s√≠ntese de voz.

**Principais fun√ß√µes:**
- `TextNormalizer(config)` - Classe principal de normaliza√ß√£o
- `normalize(text)` - Normaliza texto completo
- `convert_numbers_to_words(text)` - Converte n√∫meros para extenso
- `clean_text(text)` - Remove caracteres especiais

**Caracter√≠sticas:**
- ‚úÖ Converte n√∫meros para extenso (PT-BR)
- ‚úÖ Normaliza pontua√ß√£o
- ‚úÖ Remove caracteres especiais
- ‚úÖ Lowercase opcional
- ‚úÖ Replacements customiz√°veis

**Exemplo:**
```python
from train.text import TextNormalizer

normalizer = TextNormalizer(config={
    "lowercase": True,
    "convert_numbers_to_words": True,
    "numbers_lang": "pt_BR",
    "remove_special_chars": True,
})

text = "Ol√°! Tenho 25 anos e 100 reais."
normalized = normalizer.normalize(text)
# Output: "ol√° tenho vinte e cinco anos e cem reais"
```

---

### üî§ `vocab.py` - Vocabulary Management
Gerenciamento de vocabul√°rio e caracteres permitidos.

**Principais fun√ß√µes:**
- `load_vocab(path)` - Carrega vocabul√°rio de arquivo
- `build_vocab(texts)` - Constr√≥i vocabul√°rio de textos
- `validate_vocab(vocab)` - Valida vocabul√°rio
- `compute_vocab_hash(vocab)` - Hash para verificar mudan√ßas

**Exemplo:**
```python
from train.utils.vocab import load_vocab, validate_vocab

# Carregar vocabul√°rio
vocab = load_vocab("train/config/vocab.txt")

# Validar
info = validate_vocab(vocab, verbose=True)
print(f"Vocab size: {info.size}, unique chars: {info.unique_chars}")
```

---

### üîç `qa.py` - Text Quality Assurance
Quality checks para textos do dataset.

**Principais fun√ß√µes:**
- `check_text_quality(text, config)` - Verifica qualidade do texto
- `detect_oov_ratio(text, vocab)` - Detecta caracteres fora do vocab
- `check_speech_rate(text, duration)` - Valida taxa de fala
- `filter_poor_quality(texts)` - Filtra textos de baixa qualidade

**Checks realizados:**
- ‚úÖ Comprimento m√≠nimo/m√°ximo
- ‚úÖ Caracteres out-of-vocabulary (OOV)
- ‚úÖ Taxa de fala (chars/segundo)
- ‚úÖ Presen√ßa de m√∫sica/ru√≠do markers
- ‚úÖ Propor√ß√£o de palavras v√°lidas

**Exemplo:**
```python
from train.text.qa import check_text_quality

result = check_text_quality(
    text="Este √© um texto de exemplo.",
    duration=2.5,
    vocab=vocab,
    config={
        "min_text_length": 10,
        "max_text_length": 500,
        "min_speech_rate": 5.0,
        "max_speech_rate": 25.0,
    }
)

if result.is_valid:
    print("‚úÖ Texto v√°lido")
else:
    print(f"‚ùå Problemas: {result.issues}")
```

---

## Pipeline Completo

Exemplo de pipeline de processamento de texto:

```python
from train.text import TextNormalizer
from train.text.qa import check_text_quality
from train.utils.vocab import load_vocab

# 1. Carregar vocab
vocab = load_vocab("train/config/vocab.txt")

# 2. Criar normalizer
normalizer = TextNormalizer(config={
    "lowercase": True,
    "convert_numbers_to_words": True,
    "numbers_lang": "pt_BR",
    "remove_special_chars": True,
    "allowed_chars": vocab,
})

# 3. Normalizar texto
raw_text = "Ol√°! Tenho 25 anos."
text = normalizer.normalize(raw_text)

# 4. Validar qualidade
qa_result = check_text_quality(
    text=text,
    duration=2.0,
    vocab=vocab,
    config={
        "min_text_length": 10,
        "max_text_length": 500,
        "oov_ratio_threshold": 0.1,
    }
)

if qa_result.is_valid:
    print(f"‚úÖ Texto processado: {text}")
else:
    print(f"‚ùå Texto rejeitado: {qa_result.issues}")
```

---

## Configura√ß√£o Recomendada

### Para Portugu√™s Brasileiro

```python
text_config = {
    # Normaliza√ß√£o
    "lowercase": True,
    "convert_numbers_to_words": True,
    "numbers_lang": "pt_BR",
    "normalize_punctuation": True,
    "remove_special_chars": True,
    
    # Caracteres permitidos (PT-BR)
    "allowed_chars": (
        "abcdefghijklmnopqrstuvwxyz"
        "√°√†√¢√£√©√™√≠√≥√¥√µ√∫√ß"
        "ABCDEFGHIJKLMNOPQRSTUVWXYZ"
        "√Å√Ä√Ç√É√â√ä√ç√ì√î√ï√ö√á"
        "0123456789 .,!?;:-'\"()"
    ),
    
    # Replacements
    "replacements": {
        "...": ".",
        "!!": "!",
        "??": "?",
        "  ": " ",
    },
    
    # Quality filters
    "min_text_length": 10,
    "max_text_length": 500,
    "min_word_count": 2,
    "oov_ratio_threshold": 0.1,
    "min_speech_rate": 5.0,
    "max_speech_rate": 25.0,
    
    # Cleanup
    "remove_lines_with": [
        "[m√∫sica]",
        "[aplausos]",
        "[risos]",
        "‚ô™",
    ],
}
```

---

## Convers√£o de N√∫meros

O m√≥dulo converte n√∫meros para extenso em portugu√™s:

```python
from train.text import TextNormalizer

normalizer = TextNormalizer({"convert_numbers_to_words": True})

examples = [
    "25" ‚Üí "vinte e cinco",
    "100" ‚Üí "cem",
    "1000" ‚Üí "mil",
    "2023" ‚Üí "dois mil e vinte e tr√™s",
    "3.14" ‚Üí "tr√™s ponto quatorze",
    "50%" ‚Üí "cinquenta por cento",
]
```

---

## Quality Checks

### Detec√ß√£o de OOV (Out-of-Vocabulary)

```python
from train.text.qa import detect_oov_ratio

text = "Caf√© com a√ß√∫car @ 10h!"
oov_ratio, oov_chars = detect_oov_ratio(text, vocab)

if oov_ratio > 0.1:  # > 10% OOV
    print(f"‚ö†Ô∏è High OOV ratio: {oov_ratio:.1%}")
    print(f"   Unknown chars: {oov_chars}")
```

### Taxa de Fala

```python
from train.text.qa import check_speech_rate

text = "Este √© um texto de exemplo com v√°rias palavras."
duration = 2.5  # segundos
chars_per_sec = len(text) / duration

if 5.0 <= chars_per_sec <= 25.0:
    print("‚úÖ Speech rate OK")
else:
    print(f"‚ùå Abnormal speech rate: {chars_per_sec:.1f} chars/s")
```

---

## Testes

Para testar os m√≥dulos de texto:

```bash
pytest tests/train/text/ -v
```

---

## Depend√™ncias

```bash
pip install num2words unidecode
```

---

## Refer√™ncias

- **num2words**: Convers√£o de n√∫meros para extenso
- **Text Normalization**: [Speech Synthesis Best Practices](https://arxiv.org/abs/1711.00350)

---

**Autor:** F5-TTS Training Pipeline  
**Vers√£o:** 1.0  
**Data:** 2025-12-06
