# ğŸ™ï¸ Pipeline de Treinamento F5-TTS PortuguÃªs Brasileiro

**Pipeline completo e reprodutÃ­vel para fine-tuning do modelo `firstpixel/F5-TTS-pt-br` usando vÃ­deos do YouTube**

Este diretÃ³rio contÃ©m toda a infraestrutura necessÃ¡ria para treinar modelos customizados de TTS em portuguÃªs brasileiro, desde o download de vÃ­deos do YouTube atÃ© o modelo final pronto para uso.

---

## ğŸ“‹ Ãndice

- [VisÃ£o Geral](#-visÃ£o-geral)
- [PrÃ©-requisitos](#-prÃ©-requisitos)
- [InstalaÃ§Ã£o](#-instalaÃ§Ã£o)
- [Fluxo Completo](#-fluxo-completo)
  - [1. Preparar Lista de VÃ­deos](#1-preparar-lista-de-vÃ­deos)
  - [2. Download de Ãudio](#2-download-de-Ã¡udio)
  - [3. SegmentaÃ§Ã£o](#3-segmentaÃ§Ã£o)
  - [4. TranscriÃ§Ã£o](#4-transcriÃ§Ã£o)
  - [5. Construir Metadata](#5-construir-metadata)
  - [6. Preparar Dataset](#6-preparar-dataset)
  - [7. Treinar Modelo](#7-treinar-modelo)
- [ConfiguraÃ§Ã£o](#-configuraÃ§Ã£o)
- [Estrutura de DiretÃ³rios](#-estrutura-de-diretÃ³rios)
- [SoluÃ§Ã£o de Problemas](#-soluÃ§Ã£o-de-problemas)
- [PrÃ³ximos Passos](#-prÃ³ximos-passos)

---

## ğŸ¯ VisÃ£o Geral

Este pipeline automatiza todo o processo de fine-tuning do F5-TTS:

```mermaid
graph LR
    A[VÃ­deos YouTube] --> B[Download Ãudio]
    B --> C[SegmentaÃ§Ã£o 3-12s]
    C --> D[TranscriÃ§Ã£o/Legendas]
    D --> E[Dataset F5-TTS]
    E --> F[Fine-tuning]
    F --> G[Modelo Treinado]
```

**Principais caracterÃ­sticas:**

- âœ… **Zero configuraÃ§Ã£o manual**: Lista de vÃ­deos â†’ Modelo treinado
- âœ… **Suporta legendas do YouTube**: PreferÃªncia por legendas oficiais (melhor qualidade)
- âœ… **Fallback para Whisper**: TranscriÃ§Ã£o automÃ¡tica quando nÃ£o hÃ¡ legendas
- âœ… **Processamento otimizado**: VAD, normalizaÃ§Ã£o de loudness, segmentaÃ§Ã£o inteligente
- âœ… **Preprocessamento pt-br**: Lowercase, num2words, normalizaÃ§Ã£o de pontuaÃ§Ã£o
- âœ… **CompatÃ­vel com F5-TTS oficial**: Usa mesmas ferramentas e formato de dataset
- âœ… **Checkpoints periÃ³dicos**: NÃ£o perde progresso em caso de falha
- âœ… **TensorBoard/W&B**: Monitoramento em tempo real

---

## ğŸ”§ PrÃ©-requisitos

### Sistema

- **Python**: 3.8 ou superior
- **CUDA**: Recomendado para GPU (opcional para CPU)
- **ffmpeg**: Para processamento de Ã¡udio
  ```bash
  # Ubuntu/Debian
  sudo apt install ffmpeg
  
  # macOS
  brew install ffmpeg
  
  # Windows
  choco install ffmpeg
  ```

### GPU (Recomendado)

- **VRAM mÃ­nima**: 6GB (para batch_size=4)
- **VRAM recomendada**: 8-12GB
- **Para GPUs menores**: Ajustar `batch_size_per_gpu` e `grad_accumulation_steps` em `train_config.yaml`

---

## ğŸ“¦ InstalaÃ§Ã£o

### 1. Instalar DependÃªncias Python

```bash
# Navegar atÃ© o diretÃ³rio do projeto
cd /path/to/tts-webui-proxmox-passthrough

# Criar ambiente virtual (recomendado)
python -m venv venv
source venv/bin/activate  # Linux/Mac
# ou
.\venv\Scripts\activate  # Windows

# Instalar dependÃªncias
pip install -r train/requirements_train.txt
```

### 2. Verificar InstalaÃ§Ã£o

```bash
# Verificar ffmpeg
ffmpeg -version

# Verificar CUDA (se disponÃ­vel)
python -c "import torch; print(f'CUDA disponÃ­vel: {torch.cuda.is_available()}')"

# Verificar F5-TTS
python -c "from f5_tts.model import CFM; print('F5-TTS OK!')"
```

---

## ğŸš€ Fluxo Completo

### 1. Preparar Lista de VÃ­deos

Edite o arquivo `train/data/videos.csv` com os links dos vÃ­deos do YouTube:

```csv
id,youtube_url,speaker,emotion,language,split,notes
1,https://www.youtube.com/watch?v=XXXXXXXXXXX,narrator1,neutral,pt-br,train,DocumentÃ¡rio sobre histÃ³ria
2,https://www.youtube.com/watch?v=YYYYYYYYYYY,narrator1,happy,pt-br,train,VÃ­deo educativo
3,https://www.youtube.com/watch?v=ZZZZZZZZZZZ,speaker_male,neutral,pt-br,val,Podcast
```

**Dicas para selecionar vÃ­deos:**

- âœ… Ãudio limpo, sem mÃºsica de fundo
- âœ… Fala clara e pausada
- âœ… Legendas disponÃ­veis (preferencialmente manuais)
- âœ… Variedade de tÃ³picos para generalizaÃ§Ã£o
- âš ï¸ Evitar: vÃ­deos com mÃºltiplos falantes, mÃºsica alta, ruÃ­do excessivo

**Quanto Ã¡udio vocÃª precisa?**

- **MÃ­nimo**: 30 minutos (~10 vÃ­deos curtos)
- **Recomendado**: 2-5 horas (~20-50 vÃ­deos)
- **Ideal**: 10+ horas (100+ vÃ­deos)

---

### 2. Download de Ãudio

Baixa Ã¡udio dos vÃ­deos e converte para WAV mono 24kHz:

```bash
python -m train.scripts.download_youtube
```

**O que acontece:**

- Baixa apenas Ã¡udio (nÃ£o vÃ­deo completo)
- Converte para WAV mono 24kHz
- Aplica retry automÃ¡tico em caso de falhas
- Skip de arquivos jÃ¡ baixados
- Salva em `train/data/raw/`

**SaÃ­da esperada:**

```
ğŸ“¥ Iniciando download de 10 vÃ­deos...

[1/10] Processando vÃ­deo 1...
â¬‡ï¸  Baixando [1]: https://www.youtube.com/watch?v=... (tentativa 1/3)
âœ… video_00001.wav baixado com sucesso!
   TÃ­tulo: Como funciona a IA
   DuraÃ§Ã£o: 625.3s

...

âœ… Sucessos: 10
â­ï¸  Pulados: 0
âŒ Falhas: 0
ğŸ“ Arquivos salvos em: train/data/raw
```

---

### 3. SegmentaÃ§Ã£o

Processa Ã¡udios, aplicando VAD e segmentando em trechos de 3-12 segundos:

```bash
python -m train.scripts.prepare_segments
```

**O que acontece:**

- Voice Activity Detection (VAD) para encontrar segmentos com fala
- SegmentaÃ§Ã£o em trechos de 3-12s
- NormalizaÃ§Ã£o de loudness (LUFS)
- ConversÃ£o para mono 24kHz 16-bit
- Salva em `train/data/processed/wavs/`

**SaÃ­da esperada:**

```
ğŸ“„ Processando: video_00001.wav
   DuraÃ§Ã£o total: 625.32s
   Segmentos com voz detectados: 45
   Segmentos finais: 52
   âœ… 52 segmentos salvos

...

ğŸ“ Arquivos originais processados: 10
âœ‚ï¸  Segmentos gerados: 487
â±ï¸  DuraÃ§Ã£o mÃ©dia: 7.32s
â±ï¸  DuraÃ§Ã£o total: 0.99h
ğŸ“ Segmentos salvos em: train/data/processed/wavs
```

---

### 4. TranscriÃ§Ã£o

Transcreve Ã¡udio usando legendas do YouTube (preferencial) ou Whisper:

```bash
python -m train.scripts.transcribe_or_subtitles
```

**O que acontece:**

1. **Tenta baixar legendas do YouTube** (mais rÃ¡pido e preciso)
   - Legendas manuais (melhor)
   - Legendas automÃ¡ticas (fallback)
2. **Se nÃ£o houver legendas, usa Whisper** (mais lento)
   - TranscriÃ§Ã£o automÃ¡tica de alta qualidade
3. **Preprocessamento de texto**:
   - Lowercase
   - NÃºmeros â†’ palavras (`num2words`)
   - NormalizaÃ§Ã£o de pontuaÃ§Ã£o
   - RemoÃ§Ã£o de caracteres especiais
4. **Salva em** `train/data/processed/transcriptions.json`

**SaÃ­da esperada:**

```
ETAPA 1: DOWNLOAD DE LEGENDAS DO YOUTUBE
==========================================

ğŸ” Buscando legendas para video_1...
   âœ… Legendas encontradas: video_00001.pt.vtt
   âœ… 12543 caracteres extraÃ­dos

...

ETAPA 2: TRANSCRIÃ‡ÃƒO DE SEGMENTOS
==========================================

[1/487] processed/wavs/video_00001_seg0000.wav
   ğŸ“ Usando legendas do YouTube
   âœ… 89 caracteres: a inteligÃªncia artificial estÃ¡ revolucionando o mundo moderno...

[50/487] processed/wavs/video_00003_seg0012.wav
   ğŸ¤ Transcrevendo com Whisper (openai/whisper-base)...
   âœ… 76 caracteres: neste vÃ­deo vamos explorar como a tecnologia mudou...

...

ğŸ“ Segmentos transcritos: 487
ğŸ“Š Legendas do YouTube: 8 vÃ­deos
ğŸ“„ TranscriÃ§Ãµes salvas em: train/data/processed/transcriptions.json
```

---

### 5. Construir Metadata

Gera `metadata.csv` no formato F5-TTS:

```bash
python -m train.scripts.build_metadata_csv
```

**O que acontece:**

- LÃª transcriÃ§Ãµes de `transcriptions.json`
- Copia/organiza WAVs para `f5_dataset/wavs/`
- Gera `metadata.csv` no formato: `wavs/audio_00001.wav|texto aqui`
- Salva `duration.json` com duraÃ§Ãµes

**SaÃ­da esperada:**

```
ğŸ“ Organizando arquivos WAV...
   Processados 100/487...
   Processados 200/487...
   ...
   âœ… 487 arquivos organizados

âœ… metadata.csv salvo: train/data/f5_dataset/metadata.csv
   487 linhas

âœ… duration.json salvo: train/data/f5_dataset/duration.json

ğŸ“Š Total de amostras: 487
â±ï¸  DuraÃ§Ã£o total: 0.99h
â±ï¸  DuraÃ§Ã£o mÃ©dia: 7.32s
ğŸ“ Dataset em: train/data/f5_dataset
```

---

### 6. Preparar Dataset

Converte para formato Arrow (usado pelo F5-TTS):

```bash
python -m train.scripts.prepare_f5_dataset
```

**O que acontece:**

- LÃª `metadata.csv`
- Valida arquivos e duraÃ§Ãµes
- Gera `raw.arrow` (formato Arrow)
- Copia `vocab.txt` do modelo base pt-br
- Atualiza `duration.json`

**SaÃ­da esperada:**

```
ğŸ“„ Lendo metadata.csv...
   487 linhas encontradas

âœ… 487 amostras vÃ¡lidas (0 ignoradas)

ğŸ’¾ Salvando dataset em formato Arrow...
âœ… raw.arrow salvo: train/data/f5_dataset/raw.arrow

ğŸ’¾ Atualizando duration.json...
âœ… duration.json atualizado

ğŸ“ Configurando vocab.txt...
âœ… vocab.txt copiado de: models/f5tts/pt-br/vocab.txt

==========================================
DATASET F5-TTS PRONTO!
==========================================
ğŸ“Š Total de amostras: 487
â±ï¸  DuraÃ§Ã£o total: 0.99h
â±ï¸  DuraÃ§Ã£o mÃ©dia: 7.32s
ğŸ“ Vocab size: 245 caracteres
ğŸ“ Dataset salvo em: train/data/f5_dataset
   - raw.arrow
   - duration.json
   - vocab.txt
   - wavs/
==========================================
```

---

### 7. Treinar Modelo

Inicia o fine-tuning do F5-TTS pt-br:

```bash
python -m train.run_training
```

**OpÃ§Ãµes:**

```bash
# Usar config customizada
python -m train.run_training --config train/config/my_config.yaml

# Retomar treino de checkpoint
python -m train.run_training --resume train/output/ptbr_finetuned/last.pt

# Override dataset path
python -m train.run_training --dataset-path /caminho/custom/dataset
```

**O que acontece:**

1. Carrega configuraÃ§Ã£o de `train_config.yaml`
2. Inicializa modelo F5-TTS (DiT ou UNetT)
3. Carrega checkpoint base `firstpixel/F5-TTS-pt-br`
4. Configura Trainer (optimizer, scheduler, EMA, etc.)
5. Carrega dataset do Arrow
6. Inicia treinamento:
   - Salva checkpoints a cada N updates
   - Loga mÃ©tricas (TensorBoard/W&B)
   - Gera samples de Ã¡udio (se `log_samples: true`)

**SaÃ­da esperada:**

```
==========================================
F5-TTS FINE-TUNING - PORTUGUÃŠS BRASILEIRO
==========================================
Modelo base: firstpixel/F5-TTS-pt-br
Config: train/config/train_config.yaml

ğŸ“ Dataset: train/data/f5_dataset

==========================================
INICIALIZAÃ‡ÃƒO DO MODELO
==========================================
ğŸ“ Usando tokenizer: pinyin
ğŸ—ï¸  Inicializando modelo DiT...
âœ… Modelo criado: 450.2M parÃ¢metros
ğŸ“¥ Carregando checkpoint base: ./models/f5tts/pt-br/model_last.safetensors
âœ… Checkpoint EMA carregado

==========================================
CONFIGURAÃ‡ÃƒO DO TREINAMENTO
==========================================
ğŸ’» Device: cuda
ğŸ‹ï¸  Configurando Trainer...
âœ… Trainer configurado

==========================================
CARREGAMENTO DO DATASET
==========================================
ğŸ“š Carregando dataset: ptbr_youtube_custom
âœ… Dataset carregado: 487 amostras

==========================================
INICIANDO TREINAMENTO
==========================================
Epochs: 10
Batch size: 4
Grad accumulation: 4
Learning rate: 0.0001
Output dir: train/output/ptbr_finetuned
==========================================

Epoch 1/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [03:42<00:00, 7.41s/update]
loss: 0.4532, lr: 0.000100

Checkpoint saved: train/output/ptbr_finetuned/checkpoint_500.pt
Audio samples saved: train/output/ptbr_finetuned/samples/sample_500_*.wav

...

==========================================
âœ… TREINAMENTO CONCLUÃDO!
==========================================
Checkpoints salvos em: train/output/ptbr_finetuned

Para usar o modelo treinado:
  1. Encontre o checkpoint em train/output/ptbr_finetuned/
  2. Teste com o script de inferÃªncia
  3. Integre na API (prÃ³xima tarefa)
==========================================
```

---

## âš™ï¸ ConfiguraÃ§Ã£o

### `train_config.yaml` (Treinamento)

Principais parÃ¢metros:

```yaml
# Modelo base
model:
  base_model: "firstpixel/F5-TTS-pt-br"
  checkpoint_path: "./models/f5tts/pt-br/model_last.safetensors"

# HiperparÃ¢metros
training:
  learning_rate: 1.0e-4
  batch_size_per_gpu: 4  # Ajuste conforme sua VRAM
  grad_accumulation_steps: 4
  epochs: 10

# Checkpoints
checkpoints:
  output_dir: "./train/output/ptbr_finetuned"
  save_per_updates: 500
  keep_last_n_checkpoints: 5
```

**Para GPUs com pouca VRAM (4-6GB):**

```yaml
training:
  batch_size_per_gpu: 2  # Reduzir batch size
  grad_accumulation_steps: 8  # Aumentar accumulation
  
advanced:
  gradient_checkpointing: true  # Economiza VRAM
```

### `dataset_config.yaml` (PreparaÃ§Ã£o de Dados)

Principais parÃ¢metros:

```yaml
# SegmentaÃ§Ã£o
segmentation:
  min_duration: 3.0  # MÃ­nimo 3s
  max_duration: 12.0  # MÃ¡ximo 12s
  use_vad: true  # Voice Activity Detection

# TranscriÃ§Ã£o
transcription:
  prefer_youtube_subtitles: true  # Tentar legendas primeiro
  asr:
    model: "openai/whisper-base"  # tiny, base, small, medium, large

# Preprocessamento
text_preprocessing:
  lowercase: true
  convert_numbers_to_words: true
```

---

## ğŸ“ Estrutura de DiretÃ³rios

```
train/
â”œâ”€â”€ README.md                      # Esta documentaÃ§Ã£o
â”œâ”€â”€ __init__.py
â”œâ”€â”€ run_training.py                # Script principal de treinamento
â”‚
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ train_config.yaml          # ConfiguraÃ§Ã£o de treinamento
â”‚   â””â”€â”€ dataset_config.yaml        # ConfiguraÃ§Ã£o de preparaÃ§Ã£o
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ download_youtube.py        # 1. Download de Ã¡udio
â”‚   â”œâ”€â”€ prepare_segments.py        # 2. SegmentaÃ§Ã£o
â”‚   â”œâ”€â”€ transcribe_or_subtitles.py # 3. TranscriÃ§Ã£o
â”‚   â”œâ”€â”€ build_metadata_csv.py      # 4. Construir metadata
â”‚   â””â”€â”€ prepare_f5_dataset.py      # 5. Preparar dataset Arrow
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ videos.csv                 # Lista de vÃ­deos do YouTube
â”‚   â”œâ”€â”€ raw/                       # Ãudio baixado (WAV 24kHz)
â”‚   â”œâ”€â”€ subtitles/                 # Legendas do YouTube
â”‚   â”œâ”€â”€ processed/
â”‚   â”‚   â”œâ”€â”€ wavs/                  # Segmentos processados
â”‚   â”‚   â”œâ”€â”€ segments_mapping.json  # Mapping segmentos â†’ vÃ­deos
â”‚   â”‚   â””â”€â”€ transcriptions.json    # TranscriÃ§Ãµes
â”‚   â””â”€â”€ f5_dataset/                # Dataset final F5-TTS
â”‚       â”œâ”€â”€ raw.arrow              # Dataset Arrow
â”‚       â”œâ”€â”€ duration.json          # DuraÃ§Ãµes
â”‚       â”œâ”€â”€ vocab.txt              # VocabulÃ¡rio
â”‚       â”œâ”€â”€ metadata.csv           # Metadata (path|text)
â”‚       â””â”€â”€ wavs/                  # WAVs organizados
â”‚
â”œâ”€â”€ output/
â”‚   â””â”€â”€ ptbr_finetuned/            # Checkpoints do modelo treinado
â”‚       â”œâ”€â”€ checkpoint_500.pt
â”‚       â”œâ”€â”€ checkpoint_1000.pt
â”‚       â”œâ”€â”€ last.pt
â”‚       â””â”€â”€ samples/               # Samples de Ã¡udio (se log_samples=true)
â”‚
â””â”€â”€ logs/
    â”œâ”€â”€ download_youtube.log
    â”œâ”€â”€ prepare_segments.log
    â”œâ”€â”€ transcribe.log
    â”œâ”€â”€ build_metadata.log
    â”œâ”€â”€ prepare_f5_dataset.log
    â”œâ”€â”€ training.log
    â””â”€â”€ tensorboard/               # TensorBoard logs
```

---

## ğŸ” SoluÃ§Ã£o de Problemas

### Erro: `ffmpeg nÃ£o encontrado`

```bash
# Ubuntu/Debian
sudo apt install ffmpeg

# macOS
brew install ffmpeg

# Windows
choco install ffmpeg
```

### Erro: `CUDA out of memory`

Reduza batch size em `train_config.yaml`:

```yaml
training:
  batch_size_per_gpu: 2  # Era 4
  grad_accumulation_steps: 8  # Era 4

advanced:
  gradient_checkpointing: true
```

### Erro: `yt-dlp nÃ£o consegue baixar vÃ­deo`

Alguns vÃ­deos tÃªm restriÃ§Ãµes de download. Tente:

1. Verificar se o vÃ­deo Ã© pÃºblico
2. Atualizar yt-dlp: `pip install --upgrade yt-dlp`
3. Usar outro vÃ­deo

### Dataset muito pequeno (< 30 minutos)

O modelo pode overfittar. SoluÃ§Ãµes:

1. Adicionar mais vÃ­deos ao `videos.csv`
2. Reduzir nÃºmero de epochs
3. Usar data augmentation (TODO: implementar)

### TranscriÃ§Ã£o com Whisper muito lenta

Whisper Ã© lento em CPU. OpÃ§Ãµes:

1. Usar GPU: `device: cuda` em `dataset_config.yaml`
2. Usar modelo menor: `model: openai/whisper-tiny`
3. Preferir vÃ­deos com legendas: `prefer_youtube_subtitles: true`

### Checkpoints ocupando muito espaÃ§o

Configure em `train_config.yaml`:

```yaml
checkpoints:
  keep_last_n_checkpoints: 3  # Manter apenas 3
  save_per_updates: 1000  # Salvar menos frequentemente
```

---

## ğŸ¯ PrÃ³ximos Passos

ApÃ³s concluir o treinamento:

### 1. Testar o Modelo

```bash
# TODO: Criar script de inferÃªncia
python -m train.scripts.test_inference \
    --checkpoint train/output/ptbr_finetuned/checkpoint_1000.pt \
    --text "olÃ¡, como vocÃª estÃ¡?" \
    --ref-audio samples/ref.wav \
    --output test_output.wav
```

### 2. Avaliar Qualidade

- Escutar samples gerados em `train/output/ptbr_finetuned/samples/`
- Comparar com modelo base `firstpixel/F5-TTS-pt-br`
- Avaliar naturalidade, pronÃºncia, prosÃ³dia

### 3. Integrar na API

**OpÃ§Ã£o A: Substituir modelo padrÃ£o**

```bash
# Copiar checkpoint para models/
cp train/output/ptbr_finetuned/checkpoint_1000.pt \
   models/f5tts/pt-br/model_finetuned.safetensors
```

Atualizar `.env`:

```bash
F5TTS_MODEL=models/f5tts/pt-br/model_finetuned.safetensors
```

**OpÃ§Ã£o B: Criar novo engine/preset** (PrÃ³xima tarefa)

- Adicionar engine `f5tts-custom` em `engines/factory.py`
- Criar quality profile `f5tts_custom_high_quality`
- Expor via API `/quality-profiles`

### 4. Continuar Treinamento (Opcional)

Se quiser mais epochs:

```bash
python -m train.run_training \
    --resume train/output/ptbr_finetuned/last.pt
```

Ajustar `epochs` em `train_config.yaml` antes.

---

## ğŸ“š ReferÃªncias

- **F5-TTS Original**: https://github.com/SWivid/F5-TTS
- **firstpixel/F5-TTS-pt-br**: https://huggingface.co/firstpixel/F5-TTS-pt-br
- **Whisper (OpenAI)**: https://github.com/openai/whisper
- **yt-dlp**: https://github.com/yt-dlp/yt-dlp

---

## ğŸ“ Notas

### âš ï¸ IMPORTANTE: NÃ£o Quebra API Atual

- âœ… Todo cÃ³digo de treinamento estÃ¡ isolado em `/train`
- âœ… API de produÃ§Ã£o (`/app`) nÃ£o Ã© alterada
- âœ… Modelos de inferÃªncia atuais continuam funcionando
- âœ… Checkpoint treinado NÃƒO Ã© usado automaticamente

Para usar o modelo treinado, vocÃª deve **manualmente** integrÃ¡-lo na API (Tarefa futura).

### ğŸ”’ LicenÃ§a

O modelo base `firstpixel/F5-TTS-pt-br` Ã© licenciado sob **CC-BY-NC-4.0** (nÃ£o comercial).

Certifique-se de respeitar os termos de licenÃ§a ao usar modelos derivados.

---

**âœ¨ Boa sorte com o treinamento! âœ¨**

Para dÃºvidas ou problemas, consulte os logs em `train/logs/` ou abra uma issue.
