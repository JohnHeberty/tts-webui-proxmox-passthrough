# ğŸ™ï¸ Pipeline de Treinamento F5-TTS PortuguÃªs Brasileiro

**Pipeline completo e otimizado para fine-tuning do modelo `firstpixel/F5-TTS-pt-br` usando vÃ­deos do YouTube**

---

## ğŸ“‹ Ãndice

- [VisÃ£o Geral](#-visÃ£o-geral)
- [PrÃ©-requisitos](#-prÃ©-requisitos)
- [InstalaÃ§Ã£o RÃ¡pida](#-instalaÃ§Ã£o-rÃ¡pida)
- [Pipeline Completo](#-pipeline-completo)
- [Scripts DisponÃ­veis](#-scripts-disponÃ­veis)
- [Estrutura de DiretÃ³rios](#-estrutura-de-diretÃ³rios)
- [OtimizaÃ§Ãµes e Melhorias](#-otimizaÃ§Ãµes-e-melhorias)
- [SoluÃ§Ã£o de Problemas](#-soluÃ§Ã£o-de-problemas)

---

## ğŸ¯ VisÃ£o Geral

Pipeline automatizado para treinar modelos F5-TTS em portuguÃªs brasileiro a partir de vÃ­deos do YouTube.

**Fluxo do Pipeline:**

```
VÃ­deos YouTube â†’ Download Ãudio â†’ SegmentaÃ§Ã£o â†’ TranscriÃ§Ã£o â†’ NormalizaÃ§Ã£o â†’ 
ValidaÃ§Ã£o QA â†’ Dataset F5-TTS â†’ Treinamento â†’ Modelo Treinado
```

**CaracterÃ­sticas:**

- âœ… **Otimizado para Baixa MemÃ³ria**: Processamento em streaming (<500MB RAM)
- âœ… **TranscriÃ§Ã£o Multi-Modelo**: Whisper Base (rÃ¡pido) + Medium (qualidade)
- âœ… **NormalizaÃ§Ã£o Inteligente**: NÃºmeros, %, moedas â†’ forma falada
- âœ… **ValidaÃ§Ã£o AutomÃ¡tica**: Detecta e re-processa transcriÃ§Ãµes problemÃ¡ticas
- âœ… **Retomada de Progresso**: Suporta interrupÃ§Ã£o e continuaÃ§Ã£o
- âœ… **Formato F5-TTS Nativo**: Dataset em Arrow format compatÃ­vel

---

## ğŸ”§ PrÃ©-requisitos

### Sistema

```bash
# Ubuntu/Debian
sudo apt install ffmpeg python3.11 python3-pip

# Verificar instalaÃ§Ã£o
ffmpeg -version
python3 --version  # >= 3.8
```

### Hardware

- **CPU**: Qualquer (GPU recomendada para treinamento)
- **RAM**: 8GB+ (segmentaÃ§Ã£o otimizada usa <500MB)
- **GPU**: NVIDIA com 8GB+ VRAM (opcional, mas recomendado)
- **Disco**: ~10GB para 2-3h de Ã¡udio

---

## ğŸ“¦ InstalaÃ§Ã£o RÃ¡pida

```bash
# 1. Clonar repositÃ³rio (se ainda nÃ£o tiver)
cd /home/tts-webui-proxmox-passthrough

# 2. Instalar dependÃªncias
pip3 install -r train/requirements_train.txt

# 3. Verificar instalaÃ§Ã£o
python3 -c "import whisper, torch; print('âœ… Tudo instalado!')"
```

---

## ğŸš€ Pipeline Completo

### Etapa 1: Preparar Lista de VÃ­deos

Edite `train/data/videos.csv` com URLs do YouTube:

```csv
# ComentÃ¡rios comeÃ§am com #
# Formato: id,youtube_url,speaker,emotion,language,split,notes

1,https://www.youtube.com/watch?v=XXXXXXXXXXX,narrator1,neutral,pt-br,train,FinanÃ§as
2,https://www.youtube.com/watch?v=YYYYYYYYYYY,narrator1,neutral,pt-br,train,Empreendedorismo
3,https://www.youtube.com/watch?v=ZZZZZZZZZZZ,narrator2,neutral,pt-br,val,Marketing
```

**Dicas:**
- âœ… Ãudio limpo, sem mÃºsica de fundo forte
- âœ… Um falante principal por vÃ­deo
- âœ… Fala clara e natural
- âš ï¸ Evite: mÃºltiplos falantes, mÃºsica alta, ruÃ­do

**Quantidade recomendada:**
- MÃ­nimo: 30 min (~10 vÃ­deos)
- Ideal: 2-5 horas (~20-50 vÃ­deos)

---

### Etapa 2: Download de Ãudio

```bash
python3 -m train.scripts.simple_download
```

**O que faz:**
- Baixa apenas Ã¡udio (economia de banda)
- Converte para WAV mono 24kHz 16-bit
- Ignora comentÃ¡rios (#) no CSV
- Retry automÃ¡tico em falhas
- Salva em `train/data/raw/`

**SaÃ­da esperada:**
```
ğŸ“¥ Iniciando download de 11 vÃ­deos...
[1/11] video_00001.wav - âœ… Sucesso (625s)
[2/11] video_00002.wav - âœ… Sucesso (842s)
...
âœ… 11/11 vÃ­deos baixados com sucesso
```

---

### Etapa 3: SegmentaÃ§Ã£o Otimizada

```bash
python3 -m train.scripts.prepare_segments_optimized
```

**O que faz:**
- **Processamento em streaming**: Carrega Ã¡udio em chunks de 30s
- **VAD simples**: DetecÃ§Ã£o de voz por RMS threshold
- **SegmentaÃ§Ã£o 3-12s**: Trechos ideais para F5-TTS
- **BaixÃ­ssimo uso de RAM**: <500MB (vs 27GB do script antigo!)
- **Garbage collection agressivo**: Libera memÃ³ria continuamente

**SaÃ­da esperada:**
```
ğŸ§ Processando: video_00001.wav
   âœ‚ï¸  1197 segmentos criados
   ğŸ’¾ Salvos em: train/data/processed/wavs/
   ğŸ§  RAM: ~450MB
```

**Arquivos gerados:**
- `train/data/processed/wavs/video_XXXXX_segXXXX.wav` (Ã¡udio)
- `train/data/processed/segments_mapping.json` (metadados)

---

### Etapa 4: TranscriÃ§Ã£o com Whisper

```bash
python3 -m train.scripts.transcribe_segments
```

**O que faz:**
- **Modelo Base**: TranscriÃ§Ã£o rÃ¡pida em lote
- **Batch processing**: 10 segmentos por vez
- **GestÃ£o de memÃ³ria**: Libera GPU entre batches
- **Retomada automÃ¡tica**: Continua de onde parou
- **PÃ³s-processamento**: Lowercase, limpeza de espaÃ§os

**ConfiguraÃ§Ã£o** (`train/config/dataset_config.yaml`):
```yaml
asr:
  model: "openai/whisper-base"  # RÃ¡pido
  language: "pt"
  batch_size: 10
```

**SaÃ­da esperada:**
```
ğŸ¤ Transcrevendo 1197 segmentos...
[1/1197] video_00001_seg0000.wav
   âœ… "novecentos reais por semana de dentro da sua casa..."
[2/1197] video_00001_seg0001.wav
   âœ… "usando o mercado livre sem trÃ¢nsito sem..."
...
âœ… 1197/1197 transcritos
ğŸ’¾ Salvo em: train/data/processed/transcriptions.json
```

**Tempo estimado:**
- Base model: ~2-4 horas para 1200 segmentos (RTX 3090)
- Medium model: ~5-8 horas

---

### Etapa 5: NormalizaÃ§Ã£o de Texto

```bash
python3 -m train.scripts.normalize_transcriptions
```

**O que faz:**
- **NÃºmeros â†’ Palavras**: `2025` â†’ `"dois mil e vinte e cinco"`
- **Percentuais**: `3%` â†’ `"trÃªs porcento"`
- **Moeda**: `R$ 100` â†’ `"cem reais"`
- **SÃ­mbolos**: `&` â†’ `"e"`, `/` â†’ `"barra"`
- **Ordinais**: `1Âº` â†’ `"primeiro"`
- **Preserva original**: Cria backup antes de modificar

**Biblioteca utilizada**: `num2words` com suporte pt_BR

**SaÃ­da esperada:**
```
ğŸ“ Normalizando 1196 transcriÃ§Ãµes...

Exemplo 1:
   Original:    "Em 2025 tivemos 3% de crescimento"
   Normalizado: "em dois mil e vinte e cinco tivemos trÃªs porcento de crescimento"

Exemplo 2:
   Original:    "Custa R$ 1.500,00"
   Normalizado: "custa mil e quinhentos reais"

âœ… 79/1196 normalizadas (6.6%)
ğŸ’¾ Backup salvo: transcriptions_backup_XXXXXXXX.json
```

---

### Etapa 6: ValidaÃ§Ã£o e Re-processamento

```bash
python3 -m train.scripts.validate_and_reprocess
```

**O que detecta:**
- âŒ Caracteres invÃ¡lidos (%, /, \, etc)
- âŒ Palavras repetidas excessivamente (>5x)
- âŒ Letras isoladas com pontuaÃ§Ã£o
- âŒ Textos muito curtos (<3 palavras)
- âŒ Muitas palavras nÃ£o-portuguesas (>70%)
- âŒ SequÃªncias repetidas suspeitas

**O que faz:**
- Re-transcreve Ã¡udios problemÃ¡ticos com **Whisper Medium** (mais preciso)
- Valida novo texto
- Atualiza JSON se aprovado
- Gera relatÃ³rio de problemas

**SaÃ­da esperada:**
```
ğŸ” Validando 1196 transcriÃ§Ãµes...

ğŸ“ˆ Resultados:
   âœ… VÃ¡lidas: 1092 (91.3%)
   âŒ InvÃ¡lidas: 104 (8.7%)

âš ï¸  Problemas encontrados:
   - Caracteres invÃ¡lidos: 17
   - Palavras repetidas: 6
   - Letras isoladas: 12

â“ Re-processar 104 Ã¡udios com modelo 'medium'? [s/N]: s

ğŸ”„ Re-processando...
[1/104] video_00001_seg0000.wav
   âœ… Novo texto vÃ¡lido!
...
âœ… 98/104 re-processados com sucesso
```

---

### Etapa 7: Construir Metadata

```bash
python3 -m train.scripts.build_metadata_csv
```

**O que faz:**
- Combina transcriÃ§Ãµes + metadados de Ã¡udio
- Cria `metadata.csv` no formato F5-TTS
- Filtra segmentos invÃ¡lidos
- Valida duraÃ§Ã£o, texto, caminhos

**Formato do metadata.csv:**
```csv
audio_path|text|duration|speaker
wavs/video_00001_seg0000.wav|novecentos reais por semana...|12.0|narrator1
wavs/video_00001_seg0001.wav|usando o mercado livre sem...|8.5|narrator1
```

**SaÃ­da esperada:**
```
ğŸ“Š Construindo metadata...
   TranscriÃ§Ãµes: 1196
   Ãudios vÃ¡lidos: 1196
   Metadata gerado: 1196 linhas

ğŸ’¾ Salvo em: train/data/processed/metadata.csv
```

---

### Etapa 8: Preparar Dataset F5-TTS

```bash
python3 -m train.scripts.prepare_f5_dataset
```

**O que faz:**
- Converte `metadata.csv` â†’ formato Arrow
- Cria splits train/val
- Calcula estatÃ­sticas do dataset
- Prepara para F5-TTS trainer

**SaÃ­da esperada:**
```
ğŸ¯ Preparando dataset F5-TTS...

ğŸ“Š EstatÃ­sticas:
   Total de amostras: 1196
   DuraÃ§Ã£o total: 2.8h
   Train: 1076 (90%)
   Val: 120 (10%)

ğŸ’¾ Dataset salvo em: train/output/dataset/
   â”œâ”€â”€ train.arrow
   â”œâ”€â”€ val.arrow
   â””â”€â”€ metadata.json
```

---

### Etapa 9: Treinar Modelo

```bash
python3 -m train.run_training
```

**ConfiguraÃ§Ã£o** (`train/config/train_config.yaml`):
```yaml
model:
  base_model: "firstpixel/F5-TTS-pt-br"
  
training:
  epochs: 10
  batch_size_per_gpu: 4
  learning_rate: 1e-5
  gradient_accumulation_steps: 4
  
hardware:
  mixed_precision: "fp16"  # RTX 3090
  num_gpus: 1
```

**SaÃ­da esperada:**
```
ğŸš€ Iniciando treinamento F5-TTS...
   Base: firstpixel/F5-TTS-pt-br
   GPU: NVIDIA RTX 3090 (24GB)
   Samples: 1076 train, 120 val

Epoch 1/10
[â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ] 269/269 - loss: 0.245
ValidaÃ§Ã£o: loss=0.198

...

âœ… Treinamento concluÃ­do!
ğŸ’¾ Modelo salvo em: train/output/checkpoints/final/
```

**Tempo estimado:**
- RTX 3090: ~2-4 horas (10 epochs, 1200 samples)
- RTX 3060: ~4-8 horas

---

## ğŸ“œ Scripts DisponÃ­veis

### Scripts de Processamento

| Script | FunÃ§Ã£o | Uso |
|--------|--------|-----|
| `simple_download.py` | Download de Ã¡udio do YouTube | `python -m train.scripts.simple_download` |
| `prepare_segments_optimized.py` | SegmentaÃ§Ã£o otimizada (streaming) | `python -m train.scripts.prepare_segments_optimized` |
| `transcribe_segments.py` | TranscriÃ§Ã£o com Whisper Base | `python -m train.scripts.transcribe_segments` |
| `normalize_transcriptions.py` | NormalizaÃ§Ã£o de texto (nÃºmeros, %, etc) | `python -m train.scripts.normalize_transcriptions` |
| `validate_and_reprocess.py` | ValidaÃ§Ã£o QA + re-processamento | `python -m train.scripts.validate_and_reprocess` |
| `build_metadata_csv.py` | Gerar metadata.csv | `python -m train.scripts.build_metadata_csv` |
| `prepare_f5_dataset.py` | Converter para formato F5-TTS | `python -m train.scripts.prepare_f5_dataset` |
| `run_training.py` | Treinar modelo F5-TTS | `python -m train.run_training` |

### Scripts Legados (nÃ£o usar)

| Script | Status | Motivo |
|--------|--------|--------|
| `prepare_segments.py` | âš ï¸ Obsoleto | Consumia 27GB RAM, use `prepare_segments_optimized.py` |
| `transcribe_or_subtitles.py` | âš ï¸ Obsoleto | Legendas do YouTube nÃ£o funcionaram bem |
| `download_youtube.py` | âš ï¸ Obsoleto | Problemas com CSV, use `simple_download.py` |

### UtilitÃ¡rios

| MÃ³dulo | FunÃ§Ã£o |
|--------|--------|
| `train/utils/text_normalizer.py` | NormalizaÃ§Ã£o de texto (classe `TextNormalizer`) |

---

## ğŸ“ Estrutura de DiretÃ³rios

```
train/
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ dataset_config.yaml      # Config de processamento
â”‚   â””â”€â”€ train_config.yaml         # Config de treinamento
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ videos.csv                # Lista de vÃ­deos (INPUT)
â”‚   â”œâ”€â”€ raw/                      # Ãudios baixados
â”‚   â”‚   â”œâ”€â”€ video_00001.wav
â”‚   â”‚   â””â”€â”€ ...
â”‚   â””â”€â”€ processed/
â”‚       â”œâ”€â”€ wavs/                 # Segmentos (3-12s)
â”‚       â”‚   â”œâ”€â”€ video_00001_seg0000.wav
â”‚       â”‚   â””â”€â”€ ...
â”‚       â”œâ”€â”€ segments_mapping.json # Metadados dos segmentos
â”‚       â”œâ”€â”€ transcriptions.json   # TranscriÃ§Ãµes normalizadas
â”‚       â””â”€â”€ metadata.csv          # Dataset final
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ simple_download.py
â”‚   â”œâ”€â”€ prepare_segments_optimized.py
â”‚   â”œâ”€â”€ transcribe_segments.py
â”‚   â”œâ”€â”€ normalize_transcriptions.py
â”‚   â”œâ”€â”€ validate_and_reprocess.py
â”‚   â”œâ”€â”€ build_metadata_csv.py
â”‚   â”œâ”€â”€ prepare_f5_dataset.py
â”‚   â””â”€â”€ ...
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ text_normalizer.py        # NormalizaÃ§Ã£o de texto
â”‚   â””â”€â”€ ...
â”œâ”€â”€ logs/                          # Logs de execuÃ§Ã£o
â”œâ”€â”€ output/
â”‚   â”œâ”€â”€ dataset/                   # Dataset Arrow
â”‚   â””â”€â”€ checkpoints/               # Modelos treinados
â”œâ”€â”€ requirements_train.txt
â””â”€â”€ README.md
```

---

## âš¡ OtimizaÃ§Ãµes e Melhorias

### 1. SegmentaÃ§Ã£o Ultra Otimizada â­

**EvoluÃ§Ã£o das VersÃµes:**

| VersÃ£o | RAM Pico | Velocidade | Features |
|--------|----------|------------|----------|
| V1 Original | 27 GB | Lento | Carrega tudo na RAM |
| V2 Optimized | 400 MB | MÃ©dio | Chunks + GC estratÃ©gico |
| **V3 Ultra** | **185 MB** | **RÃ¡pido** | Streaming nativo + paralelo |

**V3 Ultra (`prepare_segments_v2.py`)** - â­ **RECOMENDADO**

**TÃ©cnicas AvanÃ§adas:**
- âœ… `soundfile.blocks` para streaming zero-copy
- âœ… Object pooling (reutiliza meter, buffers)
- âœ… Processamento paralelo opcional
- âœ… VAD stateful com contexto entre blocos
- âœ… Batch I/O otimizado
- âœ… Suporta arquivos maiores que RAM disponÃ­vel

**Uso:**
```bash
# Processamento sequencial (RAM limitada)
python3 -m train.scripts.prepare_segments_v2

# Processamento paralelo (mÃ¡xima velocidade)
python3 -m train.scripts.prepare_segments_v2 --parallel --workers 4
```

**Benchmark (arquivo 2h @ 48kHz):**
- MemÃ³ria: 185 MB (vs 27 GB original = **99.3% reduÃ§Ã£o**)
- Tempo: 3 min com 4 cores (vs 18 min = **83% mais rÃ¡pido**)
- Qualidade: Mesma precisÃ£o de segmentaÃ§Ã£o

ğŸ“– **Guia completo:** `train/scripts/OPTIMIZATION_GUIDE.md`

### 2. TranscriÃ§Ã£o Multi-Modelo

**EstratÃ©gia:**
- **Whisper Base**: TranscriÃ§Ã£o inicial rÃ¡pida (bulk processing)
- **Whisper Medium**: Re-processamento de Ã¡udios com problemas
- ValidaÃ§Ã£o automÃ¡tica detecta erros e aciona modelo melhor

### 3. NormalizaÃ§Ã£o de Texto

**Biblioteca:** `num2words` (pt_BR nativo)

**ConversÃµes:**
```python
"2025" â†’ "dois mil e vinte e cinco"
"3%" â†’ "trÃªs porcento"
"R$ 100" â†’ "cem reais"
"1Âº" â†’ "primeiro"
"&" â†’ "e"
```

**BenefÃ­cios:**
- Modelo aprende nÃºmeros falados naturalmente
- Elimina caracteres problemÃ¡ticos (%, /, \)
- Melhora consistÃªncia do treinamento

### 4. Sistema de ValidaÃ§Ã£o QA

**Checks automÃ¡ticos:**
- Caracteres invÃ¡lidos
- Palavras repetidas >5x
- Letras isoladas com pontuaÃ§Ã£o
- Textos muito curtos
- Palavras nÃ£o-portuguesas >70%

**AÃ§Ã£o:**
- Re-processamento com Whisper Medium
- RelatÃ³rio de problemas
- Backup automÃ¡tico

---

## ğŸ› SoluÃ§Ã£o de Problemas

### Erro: "KeyError: 'youtube_url'"

**Causa:** Linhas de comentÃ¡rio (#) no `videos.csv`

**SoluÃ§Ã£o:** Scripts atualizados ignoram linhas com `#`. Se usar script antigo:
```python
# Adicionar antes de processar CSV
lines = [l for l in lines if not l.startswith('#')]
```

### Erro: "RuntimeError: Model whisper-base not found"

**Causa:** Nome do modelo incorreto

**SoluÃ§Ã£o:** Usar apenas `base`, `medium`, `large` (sem prefixo `whisper-`)

```yaml
# dataset_config.yaml
asr:
  model: "openai/whisper-base"  # Correto
```

### Consumo Alto de RAM (>10GB)

**Causa:** Usando `prepare_segments.py` antigo

**SoluÃ§Ã£o:** Usar `prepare_segments_optimized.py`
```bash
python3 -m train.scripts.prepare_segments_optimized
```

### TranscriÃ§Ãµes com Caracteres Estranhos (%, /, \)

**SoluÃ§Ã£o:** Executar normalizaÃ§Ã£o
```bash
python3 -m train.scripts.normalize_transcriptions
```

### CUDA Out of Memory

**SoluÃ§Ã£o 1:** Reduzir batch size
```yaml
# train_config.yaml
training:
  batch_size_per_gpu: 2  # era 4
  gradient_accumulation_steps: 8  # era 4
```

**SoluÃ§Ã£o 2:** Usar FP16
```yaml
hardware:
  mixed_precision: "fp16"
```

---

## ğŸ“Š EstatÃ­sticas de Exemplo

**Projeto Atual (11 vÃ­deos):**
- âœ… Ãudios baixados: 11 (2h 45min)
- âœ… Segmentos gerados: 1197
- âœ… TranscriÃ§Ãµes vÃ¡lidas: 1092 (91.3%)
- âœ… Re-processadas: 104 (8.7%)
- âœ… Normalizadas: 79 (6.6%)
- âœ… Dataset final: ~2.8h de Ã¡udio limpo

**Tempo Total:**
- Download: ~15 min
- SegmentaÃ§Ã£o: ~8 min
- TranscriÃ§Ã£o Base: ~2.5h
- ValidaÃ§Ã£o + Re-processamento: ~30 min
- NormalizaÃ§Ã£o: <1 min
- **Total: ~3.5 horas**

---

## ğŸ“ PrÃ³ximos Passos

ApÃ³s treinar seu modelo:

1. **Testar o modelo**
   ```bash
   python -c "from f5_tts import F5TTS; model = F5TTS.from_pretrained('train/output/checkpoints/final'); model.infer('OlÃ¡ mundo')"
   ```

2. **Integrar na aplicaÃ§Ã£o principal**
   - Copiar checkpoint para `models/f5tts/custom/`
   - Atualizar `app/engines/f5tts_engine.py`

3. **Iterar e melhorar**
   - Adicionar mais vÃ­deos
   - Ajustar hyperparameters
   - Experimentar com diferentes vozes

---

## ğŸ“š ReferÃªncias

- [F5-TTS Original](https://github.com/SWivid/F5-TTS)
- [F5-TTS Portuguese](https://huggingface.co/firstpixel/F5-TTS-pt-br)
- [OpenAI Whisper](https://github.com/openai/whisper)
- [num2words](https://github.com/savoirfairelinux/num2words)

---

## ğŸ“ Changelog

### 2025-12-02 - Melhorias Majors

- âœ… **SegmentaÃ§Ã£o otimizada**: ReduÃ§Ã£o de RAM de 27GB â†’ <500MB
- âœ… **Sistema de validaÃ§Ã£o QA**: Detecta e re-processa problemas
- âœ… **NormalizaÃ§Ã£o de texto**: NÃºmeros, %, moeda â†’ forma falada
- âœ… **Multi-modelo**: Base (rÃ¡pido) + Medium (qualidade)
- âœ… **DocumentaÃ§Ã£o completa**: README atualizado com todos os detalhes

---

**Desenvolvido com â¤ï¸ para a comunidade de TTS em portuguÃªs brasileiro**
