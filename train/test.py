#!/usr/bin/env python3
"""
F5-TTS Test Script - GeraÃ§Ã£o de Ã¡udio direto via CLI
Baseado no notebook.ipynb convertido para execuÃ§Ã£o standalone
Refatorado para usar sistema de configuraÃ§Ã£o unificado
"""

import argparse
from datetime import datetime
from pathlib import Path
import sys
import time

import soundfile as sf
import torch


# Add project root to path
PROJECT_ROOT = Path(__file__).parent.parent.resolve()
sys.path.insert(0, str(PROJECT_ROOT))

# F5-TTS imports
from f5_tts.infer.utils_infer import (
    infer_process,
    load_model,
    load_vocoder,
)
from f5_tts.model import DiT

# Unified config
from train.config.loader import load_config


def main():
    # Parse arguments
    parser = argparse.ArgumentParser(
        description="F5-TTS Test - Direct Audio Generation",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  # Basic test with defaults
  python -m train.test
  
  # Custom checkpoint
  python -m train.test --checkpoint model_50000.pt
  
  # Custom text
  python -m train.test --text "OlÃ¡, este Ã© um teste de sÃ­ntese de voz."
  
  # Force CPU
  python -m train.test --device cpu
        """,
    )

    parser.add_argument(
        "--checkpoint",
        type=str,
        default="model_last.pt",
        help="Checkpoint filename (default: model_last.pt)",
    )
    parser.add_argument("--text", type=str, help="Text to synthesize (overrides ref text)")
    parser.add_argument("--ref-audio", type=str, help="Reference audio file")
    parser.add_argument("--ref-text", type=str, help="Reference audio transcription")
    parser.add_argument(
        "--device", type=str, choices=["cuda", "cpu", "auto"], help="Device (default: from config)"
    )
    parser.add_argument(
        "--output",
        type=str,
        default="test_output.wav",
        help="Output filename (default: test_output.wav)",
    )

    args = parser.parse_args()

    # Load unified config
    cli_overrides = {}
    if args.device:
        cli_overrides["hardware"] = {"device": args.device}

    config = load_config(cli_overrides=cli_overrides if cli_overrides else None)

    print("=" * 80)
    print("ğŸ™ï¸  F5-TTS TEST - GERAÃ‡ÃƒO DE ÃUDIO NATIVA")
    print("=" * 80)

    # 1. Device configuration
    device = config.hardware.device
    if device == "auto":
        device = "cuda" if torch.cuda.is_available() else "cpu"

    print(f"\nğŸ¯ Device: {device}")
    if torch.cuda.is_available():
        print(f"âœ… CUDA: {torch.cuda.get_device_name(0)}")
        print(f"âœ… VRAM: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB")

    # 2. Paths from config
    TRAIN_DIR = PROJECT_ROOT / "train"
    OUTPUT_DIR = PROJECT_ROOT / config.paths.output_dir
    CHECKPOINT_PATH = OUTPUT_DIR / args.checkpoint
    SAMPLES_DIR = OUTPUT_DIR / "samples"
    TEST_OUTPUT_DIR = TRAIN_DIR
    VOCAB_FILE = PROJECT_ROOT / config.paths.vocab_file

    print(f"\nğŸ“ Checkpoint: {CHECKPOINT_PATH}")
    print(f"ğŸ“ Output dir: {TEST_OUTPUT_DIR}")
    print(f"ğŸ“ Vocab: {VOCAB_FILE}")

    if not CHECKPOINT_PATH.exists():
        print("âŒ Checkpoint nÃ£o encontrado!")
        print(f"\nAvailable checkpoints in {OUTPUT_DIR}:")
        if OUTPUT_DIR.exists():
            for f in sorted(OUTPUT_DIR.glob("*.pt")):
                size_gb = f.stat().st_size / (1024**3)
                print(f"  - {f.name} ({size_gb:.2f} GB)")
        return 1

    checkpoint_size = CHECKPOINT_PATH.stat().st_size / (1024**3)
    print(f"ğŸ“Š Checkpoint: {checkpoint_size:.2f} GB")

    # 3. Load model
    print("\nğŸ”„ Carregando modelo F5-TTS...")

    # Use model config from unified config
    model_cfg = dict(
        dim=config.model.dim,
        depth=config.model.depth,
        heads=config.model.heads,
        ff_mult=config.model.ff_mult,
        text_dim=config.model.text_dim,
        conv_layers=config.model.conv_layers,
    )

    model = load_model(
        model_cls=DiT,
        model_cfg=model_cfg,
        ckpt_path=str(CHECKPOINT_PATH),
        mel_spec_type=config.mel_spec.mel_spec_type,
        vocab_file=str(VOCAB_FILE) if VOCAB_FILE.exists() else "",
        ode_method="euler",
        use_ema=config.model.use_ema,
        device=device,
    )
    print(
        f"âœ… Modelo carregado! ParÃ¢metros: {sum(p.numel() for p in model.parameters()) / 1e6:.1f}M"
    )

    # 4. Load vocoder
    print("\nğŸ”„ Carregando vocoder Vocos...")
    vocoder = load_vocoder(vocoder_name="vocos", is_local=False, local_path="")
    print("âœ… Vocoder carregado!")

    # 5. Reference audio
    ref_audio_path = SAMPLES_DIR / "update_33200_ref.wav"
    if not ref_audio_path.exists():
        print(f"âŒ Ãudio de referÃªncia nÃ£o encontrado: {ref_audio_path}")
        return 1

    audio_info, sr_info = sf.read(str(ref_audio_path))
    duration_info = len(audio_info) / sr_info
    print(f"\nâœ… Ãudio de referÃªncia: {ref_audio_path.name}")
    print(f"ğŸ“Š Sample rate: {sr_info} Hz | Duration: {duration_info:.2f}s")

    # 6. Texts
    ref_text = "OlÃ¡, este Ã© um teste de sÃ­ntese de voz com o modelo F5-TTS fine-tuned em portuguÃªs brasileiro."

    gen_text = """
    Bem-vindo ao teste de geraÃ§Ã£o de voz usando F5-TTS. 
    Este modelo foi treinado especificamente para portuguÃªs brasileiro, 
    garantindo naturalidade e expressividade em cada palavra falada.
    A tecnologia de flow matching permite uma sÃ­ntese de alta qualidade, 
    mantendo as caracterÃ­sticas Ãºnicas da voz de referÃªncia.
    """.strip()

    print(f"\nğŸ“ Texto de referÃªncia: {ref_text[:80]}...")
    print(f"ğŸ“ Texto para gerar: {len(gen_text)} caracteres")

    # 7. Generate audio
    print("\n" + "=" * 80)
    print("ğŸ™ï¸  GERANDO ÃUDIO COM GPU...")
    print("=" * 80)

    start_time = time.time()

    # Tentar usar GPU (device original do modelo)
    inference_device = device
    print(f"ğŸš€ Usando device: {inference_device}")

    try:
        audio_output, sample_rate, _ = infer_process(
            ref_audio=str(ref_audio_path),
            ref_text=ref_text,
            gen_text=gen_text,
            model_obj=model,
            vocoder=vocoder,
            mel_spec_type="vocos",
            show_info=print,
            progress=None,
            target_rms=0.1,
            cross_fade_duration=0.0,
            nfe_step=32,  # Training match
            cfg_strength=2.0,  # Training match
            sway_sampling_coef=-1.0,  # Training match
            speed=1.0,
            fix_duration=None,
            device=inference_device,
        )
        print(f"âœ… GeraÃ§Ã£o concluÃ­da com {inference_device.upper()}")

    except RuntimeError as e:
        if "cuFFT" in str(e) or "CUDA" in str(e):
            print(f"\nâš ï¸  Erro CUDA detectado: {e}")
            print("ğŸ”„ Tentando novamente com CPU...")

            # Fallback para CPU
            model.to("cpu")
            audio_output, sample_rate, _ = infer_process(
                ref_audio=str(ref_audio_path),
                ref_text=ref_text,
                gen_text=gen_text,
                model_obj=model,
                vocoder=vocoder,
                mel_spec_type="vocos",
                show_info=print,
                progress=None,
                target_rms=0.1,
                cross_fade_duration=0.0,
                nfe_step=32,
                cfg_strength=2.0,
                sway_sampling_coef=-1.0,
                speed=1.0,
                fix_duration=None,
                device="cpu",
            )
            model.to(device)  # Restaurar para GPU
            print("âœ… GeraÃ§Ã£o concluÃ­da com CPU (fallback)")
        else:
            raise  # Re-raise se nÃ£o for erro CUDA

    generation_time = time.time() - start_time

    # 8. Save audio
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    output_filename = f"f5tts_test_{timestamp}.wav"
    output_path = TEST_OUTPUT_DIR / output_filename

    sf.write(str(output_path), audio_output, sample_rate)

    # 9. Stats
    audio_duration = len(audio_output) / sample_rate if sample_rate > 0 else 0
    rtf = generation_time / audio_duration if audio_duration > 0 else 0

    print("\n" + "=" * 80)
    print("âœ… ÃUDIO GERADO COM SUCESSO!")
    print("=" * 80)
    print(f"ğŸ’¾ Arquivo: {output_path}")
    print(f"â±ï¸  Tempo de geraÃ§Ã£o: {generation_time:.2f}s")
    print(f"ğŸ“Š Sample rate: {sample_rate} Hz")
    print(f"ğŸ“Š DuraÃ§Ã£o do Ã¡udio: {audio_duration:.2f}s")
    print(f"ğŸ“Š RTF (Real-Time Factor): {rtf:.2f}x")
    print(f"ğŸ“Š Tamanho: {output_path.stat().st_size / 1024:.1f} KB")
    print("=" * 80)

    return 0


if __name__ == "__main__":
    try:
        sys.exit(main())
    except KeyboardInterrupt:
        print("\nâš ï¸  Interrompido pelo usuÃ¡rio")
        sys.exit(1)
    except Exception as e:
        print(f"\nâŒ Erro: {e}")
        import traceback

        traceback.print_exc()
        sys.exit(1)
