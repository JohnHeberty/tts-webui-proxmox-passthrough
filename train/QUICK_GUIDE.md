# ğŸš€ GUIA RÃPIDO - Training Pipeline v2.0

## âœ… Checklist Completo

### âœ… 1. TensorBoard - VALIDADO âœ“
```bash
export PATH="$HOME/.local/bin:$PATH"
tensorboard --logdir=runs --host=0.0.0.0 --port=6006
# Acesse: http://localhost:6006
```
**Status**: âœ… Funcionando (v2.20.0)

### âœ… 2. MÃ©tricas Completas - IMPLEMENTADO âœ“
```bash
python3 -m train.scripts.test_model
```
**Mostra**:
- âœ… EvoluÃ§Ã£o do loss por epoch (com % de melhora)
- âœ… Checkpoints salvos (tamanho, parÃ¢metros, data)
- âœ… Amostras de Ã¡udio geradas
- âœ… Logs do TensorBoard
- âœ… Resumo final

### âœ… 3. Early Stopping - IMPLEMENTADO âœ“
```bash
# Com early stopping automÃ¡tico (recomendado)
python3 -m train.train_with_early_stopping
```
**ConfiguraÃ§Ã£o**: `train/config/train_config.yaml`
```yaml
training:
  early_stop_patience: 3       # Para apÃ³s 3 epochs sem melhora
  early_stop_min_delta: 0.001  # Melhora mÃ­nima de 0.1%
```

### âœ… 4. Retomada AutomÃ¡tica - IMPLEMENTADO âœ“
```bash
# Continua automaticamente se houver checkpoint
python3 -m train.run_training

# ForÃ§ar novo treinamento (ignorar checkpoints)
python3 -m train.run_training --fresh-start

# Checkpoint especÃ­fico
python3 -m train.run_training --resume path/to/model.pt
```

---

## ğŸ¯ Comandos Essenciais

### Treinar (do zero ou continuando)
```bash
# Com early stopping (RECOMENDADO)
python3 -m train.train_with_early_stopping

# Sem early stopping (treinamento completo)
python3 -m train.run_training

# ForÃ§ar novo treinamento
python3 -m train.run_training --fresh-start
```

### Ver MÃ©tricas
```bash
# RelatÃ³rio completo
python3 -m train.scripts.test_model

# Ver log em tempo real
tail -f train/logs/training_interactive.log
```

### TensorBoard
```bash
# Iniciar
export PATH="$HOME/.local/bin:$PATH"
tensorboard --logdir=runs --port=6006

# Acessar
# http://localhost:6006
```

### Verificar Dataset
```bash
# Ver arquivos
ls -lh train/data/f5_dataset/

# Contar amostras
python3 -c "from datasets import load_from_disk; d=load_from_disk('train/data/f5_dataset/raw'); print(f'{len(d)} amostras')"
```

### Checkpoints
```bash
# Listar
ls -lh train/output/ptbr_finetuned/

# Ver Ãºltimo checkpoint
ls -lt train/output/ptbr_finetuned/*.pt | head -1
```

---

## ğŸ“Š Exemplo de Output - MÃ©tricas Completas

```
================================================================================
ğŸ“Š RELATÃ“RIO COMPLETO DE MÃ‰TRICAS - F5-TTS FINE-TUNING
================================================================================

ğŸ“ˆ EVOLUÃ‡ÃƒO DO TREINAMENTO
--------------------------------------------------------------------------------
Epoch      Loss            Updates         Melhora        
--------------------------------------------------------------------------------
1          0.4990          49              -              
2          0.4670          104             +6.41%         
3          0.4910          217             -5.14%         
4          0.4890          231             +0.41%         
5          0.4610          326             +5.73%         
6          0.4520          450             +1.95%         
7          0.4450          458             +1.55%         
8          0.4660          575             -4.72%         
9          0.4540          626             +2.58%         
10         0.4600          677             -1.32%         
--------------------------------------------------------------------------------
ğŸ“Š Loss inicial: 0.4990
ğŸ“Š Loss final: 0.4600
ğŸ“Š ReduÃ§Ã£o total: 7.82%
ğŸ“Š Total de updates: 677

ğŸ’¾ CHECKPOINTS SALVOS
--------------------------------------------------------------------------------
ğŸ“ model_500.pt
   Caminho: train/output/ptbr_finetuned/model_500.pt
   Tamanho: 5124.8 MB
   Modificado: 2025-12-02 22:29:53
   Tipo: F5-TTS Checkpoint (EMA)
   ParÃ¢metros: 366 tensores

ğŸ“ model_last.pt
   Caminho: train/output/ptbr_finetuned/model_last.pt
   Tamanho: 5124.8 MB
   Modificado: 2025-12-02 22:40:41
   Tipo: F5-TTS Checkpoint (EMA)
   ParÃ¢metros: 366 tensores

ğŸ”Š AMOSTRAS DE ÃUDIO GERADAS
--------------------------------------------------------------------------------
   update_500_gen.wav (392.1 KB)
   update_500_ref.wav (392.1 KB)

ğŸ“Š LOGS DO TENSORBOARD
--------------------------------------------------------------------------------
   ğŸ“‚ None
      9 arquivo(s) de eventos

ğŸ’¡ Para visualizar no TensorBoard:
   export PATH="$HOME/.local/bin:$PATH"
   tensorboard --logdir=runs
   Acesse: http://localhost:6006

================================================================================
âœ… RESUMO FINAL
================================================================================
âœ“ Treinamento: 10 epochs completadas
âœ“ Loss: 0.4990 â†’ 0.4600 (7.8% reduÃ§Ã£o)
âœ“ Checkpoints: 2 modelo(s) salvo(s)
âœ“ Amostras: 2 arquivo(s) de Ã¡udio
================================================================================
```

---

## ğŸ”§ Troubleshooting RÃ¡pido

### TensorBoard nÃ£o inicia
```bash
# Adicionar ao PATH
export PATH="$HOME/.local/bin:$PATH"

# Verificar instalaÃ§Ã£o
pip3 show tensorboard

# Testar
tensorboard --version
```

### MÃ©tricas nÃ£o aparecem
```bash
# Verificar log existe
ls -lh train/logs/training_interactive.log

# Ver Ãºltimas linhas
tail -50 train/logs/training_interactive.log
```

### Checkpoint nÃ£o detectado
```bash
# Ver checkpoints disponÃ­veis
ls -lh train/output/ptbr_finetuned/

# ForÃ§ar checkpoint especÃ­fico
python3 -m train.run_training --resume train/output/ptbr_finetuned/model_last.pt
```

---

## ğŸ“ Estrutura de Arquivos

```
train/
â”œâ”€â”€ run_training.py                    # Script principal de treinamento
â”œâ”€â”€ train_with_early_stopping.py      # ğŸ†• Wrapper com early stopping
â”œâ”€â”€ config/
â”‚   â””â”€â”€ train_config.yaml              # ConfiguraÃ§Ã£o (early stopping aqui!)
â”œâ”€â”€ data/
â”‚   â””â”€â”€ f5_dataset/
â”‚       â”œâ”€â”€ raw.arrow                   # Dataset (1194 amostras)
â”‚       â”œâ”€â”€ duration.json
â”‚       â”œâ”€â”€ vocab.txt
â”‚       â””â”€â”€ wavs/
â”œâ”€â”€ output/
â”‚   â””â”€â”€ ptbr_finetuned/
â”‚       â”œâ”€â”€ model_500.pt                # Checkpoint @ 500 updates
â”‚       â”œâ”€â”€ model_last.pt               # Ãšltimo checkpoint
â”‚       â””â”€â”€ samples/                    # Amostras de Ã¡udio
â”œâ”€â”€ logs/
â”‚   â”œâ”€â”€ training.log                    # Log geral
â”‚   â””â”€â”€ training_interactive.log        # Log interativo
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ test_model.py                   # ğŸ†• AnÃ¡lise de mÃ©tricas
â””â”€â”€ utils/
    â””â”€â”€ early_stopping.py               # ğŸ†• Early stopping callback

runs/                                   # TensorBoard logs
â””â”€â”€ None/
    â””â”€â”€ events.out.tfevents.*
```

---

## âš¡ Performance

### Treinamento Atual
- **Hardware**: NVIDIA RTX 3090 24GB
- **Dataset**: 1194 amostras (2h 56min)
- **Tempo**: ~28 minutos (10 epochs)
- **Loss**: 0.499 â†’ 0.460 (7.8% melhora)

### Com Early Stopping
- **Epochs reais**: Pode parar em 5-7 epochs
- **Tempo estimado**: ~15-20 minutos
- **BenefÃ­cio**: 30-40% mais rÃ¡pido

---

## ğŸ“š DocumentaÃ§Ã£o

- **Este guia**: `train/QUICK_GUIDE.md` - Comandos essenciais
- **AtualizaÃ§Ãµes**: `train/UPDATES.md` - Novas funcionalidades
- **README completo**: `train/README.md` - Pipeline completo
- **Quick Start**: `train/QUICKSTART.md` - InÃ­cio rÃ¡pido

---

**VersÃ£o**: 2.0  
**Data**: Dezembro 2024  
**Status**: âœ… Todas funcionalidades validadas e testadas
