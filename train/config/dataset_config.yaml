# ========================================
# DATASET PREPARATION CONFIGURATION
# ========================================
# Configuração para preparação de dataset do YouTube para F5-TTS pt-br

# ========================================
# AUDIO PROCESSING
# ========================================
audio:
  # Sample rate (F5-TTS usa 24kHz)
  target_sample_rate: 24000
  
  # Audio format
  format: "wav"
  channels: 1  # mono
  bit_depth: 16
  
  # Audio normalization
  normalize_audio: true
  target_lufs: -20.0  # Loudness target em LUFS
  
  # Clipping prevention
  headroom_db: -1.0  # Headroom para evitar clipping

# ========================================
# SEGMENTATION
# ========================================
segmentation:
  # Duração dos segmentos (em segundos)
  min_duration: 3.0
  max_duration: 12.0
  target_duration: 8.0  # Duração ideal
  
  # Voice Activity Detection (VAD)
  use_vad: true
  vad_threshold: -40  # Threshold em dB para considerar silêncio
  vad_frame_size: 512  # Frame size para VAD
  
  # Silence removal
  remove_silence: true
  silence_threshold_db: -40
  min_silence_duration: 0.3  # Mínimo de silêncio para cortar (segundos)
  
  # Overlap entre segmentos (para evitar cortes bruscos)
  segment_overlap: 0.1  # 100ms de overlap

# ========================================
# TRANSCRIPTION
# ========================================
transcription:
  # Método primário: legendas do YouTube ou ASR
  prefer_youtube_subtitles: true
  
  # ASR (Automatic Speech Recognition)
  asr:
    # Nome do modelo usado pelo whisper.load_model
    # Valores válidos: tiny, base, small, medium, large, large-v2
    model: "base"             # modelo principal (rápido)

    # Modelo (ou mesmo modelo) para retranscrição de alta precisão
    # Se sua GPU aguentar, você pode trocar para "medium" ou "large-v2"
    high_precision_model: "base"

    device: "cuda"            # "cuda" ou "cpu"
    language: "pt"
    task: "transcribe"        # "transcribe" ou "translate"
    
    # Parâmetros padrão do Whisper
    beam_size: 5
    best_of: 5
    temperature: 0.0

    # Parâmetros para modo de alta precisão (quando retranscreve)
    # Usados quando high_precision=True
    hp_beam_size: 8
    hp_best_of: 8
    hp_temperature: 0.0
    
    # (opcional) Se você for usar algum wrapper com VAD, pode aproveitar isso,
    # mas o script atual não usa esses parâmetros ainda:
    use_vad_filter: true
    vad_filter_min_silence_duration: 0.5

# ========================================
# TEXT PREPROCESSING
# ========================================
text_preprocessing:
  # Normalização para F5-TTS pt-br (recomendações do modelo)
  lowercase: true
  
  # Conversão de números para palavras
  convert_numbers_to_words: true
  numbers_lang: "pt_BR"
  
  # Normalização de pontuação
  normalize_punctuation: true
  
  # Remover caracteres especiais/ruídos
  remove_special_chars: true
  allowed_chars: "abcdefghijklmnopqrstuvwxyzáàâãéêíóôõúçABCDEFGHIJKLMNOPQRSTUVWXYZÁÀÂÃÉÊÍÓÔÕÚÇ0123456789 .,!?;:-'\"()"
  
  # Substituições específicas
  replacements:
    "...": "."
    "!!": "!"
    "??": "?"
    "  ": " "
  
  # Filtros de qualidade por tamanho
  min_text_length: 10    # caracteres
  max_text_length: 500   # caracteres
  # (opcional) Mínimo de palavras para aceitar um segmento
  min_word_count: 2

  # Limpeza de bordas bugadas (palavras quebradas no começo/fim do segmento)
  cleanup_segment_edges: true

  # Lógica de retranscrição com modelo mais preciso quando
  # há muitas palavras fora do vocabulário (OOV)
  retranscribe_on_oov: true
  # Proporção mínima de palavras desconhecidas para considerar texto ruim
  oov_ratio_threshold: 0.6        # 60%
  # Quantidade mínima absoluta de palavras desconhecidas
  oov_min_unknowns: 4
  # Quantidade mínima de palavras no segmento para ativar a checagem
  oov_min_total_words: 8

  # Vocabulário externo opcional (um termo por linha, em minúsculo)
  # Se você criar esse arquivo, descomente e ajuste o caminho:
  # vocab_file: "train/resources/pt_br_vocab.txt"
  
  # Remover linhas com termos/ruídos indesejados
  remove_lines_with:
    - "[música]"
    - "[aplausos]"
    - "[risos]"
    - "♪"
    - "�"


# ========================================
# YOUTUBE DOWNLOAD
# ========================================
youtube:
  # Download options (yt-dlp)
  audio_format: "bestaudio"
  audio_quality: "best"
  
  # Rate limiting
  rate_limit: "1M"  # 1MB/s para evitar bloqueios
  
  # Retry logic
  max_retries: 3
  retry_delay: 5  # segundos
  
  # Subtitles
  subtitles:
    download_auto_subs: true  # Baixar legendas automáticas se não houver manuais
    subtitle_formats: ["vtt", "srt"]
    subtitle_langs: ["pt", "pt-BR"]

# ========================================
# DATASET SPLIT
# ========================================
split:
  # Train/Val split
  train_ratio: 0.95
  val_ratio: 0.05
  
  # Shuffle antes do split
  shuffle: true
  random_seed: 42

# ========================================
# QUALITY FILTERS
# ========================================
quality_filters:
  # Audio quality
  min_snr_db: 10.0  # Signal-to-Noise Ratio mínimo
  
  # Duração
  skip_too_short: true
  skip_too_long: true
  
  # Taxa de fala (caracteres por segundo)
  min_speech_rate: 5.0
  max_speech_rate: 25.0
  
  # Detecção de música/ruído
  skip_music: true
  music_detection_threshold: 0.3  # Threshold para classificador de música

# ========================================
# OUTPUT
# ========================================
output:
  # Formato do dataset (Arrow/Parquet)
  format: "arrow"
  
  # Metadata CSV (formato F5-TTS: path|text)
  metadata_filename: "metadata.csv"
  metadata_separator: "|"
  
  # Organização de arquivos
  wavs_subdir: "wavs"
  
  # Vocab file
  generate_vocab: false  # Usar vocab do modelo base pt-br
  
  # Duration JSON
  save_duration_json: true

# ========================================
# ADVANCED
# ========================================
advanced:
  # Multiprocessing
  num_workers: 4
  chunk_size: 100  # Processar N arquivos por vez
  
  # Caching
  cache_downloads: true
  cache_dir: "./train/data/cache"
  
  # Logging
  verbose: true
  log_file: "./train/logs/data_preparation.log"
