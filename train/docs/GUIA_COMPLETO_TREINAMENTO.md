# üéì Guia Completo de Treinamento XTTS-v2

**Vers√£o:** v2.0.1  
**Data:** 10 de Dezembro de 2025

## üìã √çndice

1. [Introdu√ß√£o](#introdu√ß√£o)
2. [Pr√©-requisitos](#pr√©-requisitos)
3. [Prepara√ß√£o do Dataset](#prepara√ß√£o-do-dataset)
4. [Configura√ß√£o](#configura√ß√£o)
5. [Treinamento](#treinamento)
6. [Problemas Comuns](#problemas-comuns)
7. [Refer√™ncias](#refer√™ncias)

---

## üéØ Introdu√ß√£o

Este guia explica como treinar (fine-tune) um modelo XTTS-v2 para sua pr√≥pria voz usando LoRA (Low-Rank Adaptation), uma t√©cnica eficiente que requer menos recursos.

### O que voc√™ vai precisar?

- **GPU NVIDIA** com no m√≠nimo 8GB VRAM (recomendado 12GB+)
- **√Åudio de refer√™ncia**: 30-60 minutos de √°udio limpo da voz alvo
- **Tempo**: 2-4 horas para preparar dataset + 6-12 horas de treinamento
- **Conhecimento b√°sico**: Linha de comando Linux/Terminal

### ‚ö†Ô∏è IMPORTANTE - Estado Atual (v2.0)

O script `train_xtts.py` est√° em **modo TEMPLATE**:
- ‚úÖ Estrutura completa implementada
- ‚úÖ Configura√ß√£o via Pydantic Settings
- ‚ö†Ô∏è Modelo XTTS placeholder (n√£o carrega modelo real)
- ‚ö†Ô∏è Dataset dummy (n√£o treina com dados reais)

**Para treinar modelo XTTS REAL**, voc√™ precisa:
1. Instalar biblioteca TTS: `pip install TTS`
2. Implementar `load_pretrained_model()` com TTS API
3. Implementar `create_dataset()` com TTS.tts.datasets
4. Implementar `train_step()` com XTTS forward pass

---

## üîß Pr√©-requisitos

### Hardware

```bash
# Verificar GPU
nvidia-smi

# Verificar VRAM (m√≠nimo 8GB)
nvidia-smi --query-gpu=memory.total --format=csv
```

**Recomenda√ß√µes:**
- **8GB VRAM**: Batch size 1-2, epochs curtos
- **12GB VRAM**: Batch size 2-4, treinamento completo
- **24GB+ VRAM**: Batch size 8+, parallel training

### Software

```bash
# Python 3.11+
python3 --version

# CUDA 11.8+
nvcc --version

# PyTorch com CUDA
python3 -c "import torch; print(torch.cuda.is_available())"
```

### Depend√™ncias

```bash
cd /home/tts-webui-proxmox-passthrough

# Instalar depend√™ncias base
pip install -r requirements.txt

# Para treinamento REAL (ainda n√£o implementado)
# pip install TTS peft transformers<4.40
```

---

## üìä Prepara√ß√£o do Dataset

### Op√ß√£o 1: Baixar do YouTube (Mais F√°cil)

```bash
# 1. Baixar v√≠deos/√°udios
python3 -m train.scripts.download_youtube

# Siga as instru√ß√µes:
# - Cole URLs de v√≠deos do YouTube
# - Escolha qualidade de √°udio (best/128k/64k)
# - √Åudios salvos em: train/data/raw/
```

**Dicas:**
- Use v√≠deos com **boa qualidade de √°udio**
- Evite m√∫sica de fundo ou ru√≠dos
- Prefira **conte√∫do falado**: podcasts, entrevistas, aulas
- Baixe **30-60 minutos** de √°udio total

### Op√ß√£o 2: Usar Seus Pr√≥prios √Åudios

```bash
# Copiar √°udios para pasta raw
mkdir -p train/data/raw
cp /caminho/seus/audios/*.mp3 train/data/raw/

# Formatos aceitos: MP3, WAV, M4A, OGG, FLAC
```

### 2. Segmentar √Åudio em Chunks

```bash
# Dividir √°udio longo em chunks de 5-15 segundos
python3 -m train.scripts.segment_audio

# Configura√ß√µes em: train/config/dataset_config.yaml
# - min_duration: 5.0 (m√≠nimo 5s)
# - max_duration: 15.0 (m√°ximo 15s)
# - silence_threshold: -40dB (ajustar se necess√°rio)

# Resultado: train/data/processed/segments/
```

**O que acontece:**
- Detecta sil√™ncios para dividir naturalmente
- Remove segmentos muito curtos ou longos
- Normaliza volume
- Converte para WAV mono 22050Hz

### 3. Transcrever com Whisper

```bash
# Op√ß√£o A: Parallel (15x mais r√°pido - RECOMENDADO)
python3 -m train.scripts.transcribe_audio_parallel

# Op√ß√£o B: Serial (mais lento)
python3 -m train.scripts.transcribe_audio

# Configura√ß√µes:
# - Modelo: medium (padr√£o) ou large
# - Workers: auto-detect baseado em VRAM
# - Resultado: train/data/processed/transcriptions/
```

**Tempo estimado:**
- 1 hora de √°udio com `medium` parallel: ~4-6 minutos
- 1 hora de √°udio com `large` parallel: ~8-12 minutos

### 4. Gerar Metadata LJSpeech

```bash
# Criar dataset final formato LJSpeech
python3 -m train.scripts.build_ljs_dataset

# Sa√≠da: train/data/MyTTSDataset/
# ‚îú‚îÄ‚îÄ wavs/                    # √Åudios processados
# ‚îú‚îÄ‚îÄ metadata.csv             # Todos samples
# ‚îú‚îÄ‚îÄ metadata_train.csv       # 90% treino
# ‚îî‚îÄ‚îÄ metadata_val.csv         # 10% valida√ß√£o
```

**Formato metadata.csv:**
```
wavs/audio_001.wav|Texto transcrito aqui
wavs/audio_002.wav|Outro texto transcrito
```

### 5. Validar Dataset

```bash
# Verificar estat√≠sticas
cd train/data/MyTTSDataset
wc -l metadata*.csv

# Esperado:
# - 500-5000 samples (m√≠nimo 100)
# - 15-60 minutos total
# - Taxa 90/10 train/val
```

---

## ‚öôÔ∏è Configura√ß√£o

### v2.0: Pydantic Settings (Sem YAML!)

**M√©todo 1: Usar Defaults**

```bash
# Simplesmente rode - usa configura√ß√µes otimizadas
python3 -m train.scripts.train_xtts
```

**M√©todo 2: Vari√°veis de Ambiente**

```bash
# Customizar via export
export TRAIN_NUM_EPOCHS=50
export TRAIN_LEARNING_RATE=0.00001
export TRAIN_BATCH_SIZE=4
export TRAIN_USE_LORA=true

python3 -m train.scripts.train_xtts
```

**M√©todo 3: Arquivo .env**

```bash
# Criar train/.env
cat > train/.env << 'EOF'
# Hardware
TRAIN_DEVICE=cuda
TRAIN_CUDA_DEVICE_ID=0

# Dataset
TRAIN_DATASET_DIR=train/data/MyTTSDataset
TRAIN_BATCH_SIZE=2
TRAIN_NUM_WORKERS=4

# Model & LoRA
TRAIN_USE_LORA=true
TRAIN_LORA_RANK=8
TRAIN_LORA_ALPHA=16

# Training
TRAIN_NUM_EPOCHS=1000
TRAIN_LEARNING_RATE=0.00001
TRAIN_USE_AMP=false

# Logging
TRAIN_SAVE_EVERY_N_EPOCHS=10
TRAIN_USE_TENSORBOARD=true
EOF

# Rodar com .env
python3 -m train.scripts.train_xtts
```

### Par√¢metros Principais

| Par√¢metro | Default | Descri√ß√£o | Quando Ajustar |
|-----------|---------|-----------|----------------|
| `num_epochs` | 1000 | N√∫mero de √©pocas | Reduzir para testes (10-50) |
| `batch_size` | 2 | Samples por batch | Aumentar se VRAM > 12GB |
| `learning_rate` | 1e-5 | Taxa de aprendizado | Reduzir se loss inst√°vel |
| `use_lora` | true | Usar LoRA | Manter true (mais eficiente) |
| `lora_rank` | 8 | LoRA rank | Aumentar para 16-32 se VRAM permite |
| `use_amp` | false | Mixed precision | Ativar para economizar VRAM |
| `save_every_n_epochs` | 10 | Frequ√™ncia checkpoint | Reduzir para 1-5 |

---

## üöÄ Treinamento

### Modo Template (Atual)

```bash
# Rodar script em modo demonstra√ß√£o
python3 -m train.scripts.train_xtts

# Sa√≠da:
# - ‚ö†Ô∏è  TEMPLATE MODE warnings
# - Dummy model criado
# - Dummy dataset (10 samples)
# - Loop de treinamento simulado
# - N√£o salva checkpoints reais
```

### Treinamento Real (Requer Implementa√ß√£o)

**Quando implementado, voc√™ ver√°:**

```bash
python3 -m train.scripts.train_xtts

# Output esperado:
# ================================================================================
# XTTS-v2 FINE-TUNING com LoRA
# ================================================================================
# üìù Settings carregadas via Pydantic
# ‚úÖ Using CUDA device: NVIDIA GeForce RTX 3090
# üì¶ Carregando modelo XTTS-v2...
# ‚úÖ Modelo carregado: XttsModel (340M params)
# üîß Configurando LoRA...
#    Trainable params: 2.5M (0.73%)
# üìä Carregando dataset...
#    Train: 4,429 samples (13.76h)
#    Val: 493 samples (1.54h)
# 
# üöÄ Iniciando treinamento...
#    Epochs: 1000
#    Batch size: 2
#    Learning rate: 1e-05
# 
# ============================================================
# EPOCH 1/1000
# ============================================================
# Epoch 1/1000 | Step 1/2215 | Loss: 0.8542 | Avg: 0.8542 | LR: 1.00e-05
# Epoch 1/1000 | Step 10/2215 | Loss: 0.7234 | Avg: 0.7891 | LR: 1.00e-05
# ...
```

### Monitorar Treinamento

#### TensorBoard

```bash
# Em outro terminal
tensorboard --logdir train/runs --port 6006

# Abrir navegador: http://localhost:6006
# Ver:
# - train/loss, train/avg_loss
# - epoch/train_loss, epoch/val_loss
# - train/lr (learning rate)
```

#### Logs

```bash
# Ver logs em tempo real
tail -f logs/info.log

# Buscar erros
grep "ERROR" logs/error.log
```

#### Checkpoints

```bash
# Listar checkpoints salvos
ls -lh train/checkpoints/

# Estrutura:
# checkpoint_epoch_10.pt
# checkpoint_epoch_20.pt
# best_model.pt  # Melhor modelo (menor val_loss)
```

---

## üêõ Problemas Comuns

### 1. CUDA Out of Memory (OOM)

**Erro:**
```
RuntimeError: CUDA out of memory. Tried to allocate X.XX GiB
```

**Solu√ß√µes:**

```bash
# Reduzir batch size
export TRAIN_BATCH_SIZE=1

# Ativar mixed precision (economiza VRAM)
export TRAIN_USE_AMP=true

# Reduzir num_workers
export TRAIN_NUM_WORKERS=0

# Limpar cache CUDA
python3 -c "import torch; torch.cuda.empty_cache()"
```

### 2. Dataset N√£o Encontrado

**Erro:**
```
WARNING - ‚ö†Ô∏è  Dataset n√£o encontrado - usando modo TEMPLATE
```

**Solu√ß√£o:**

```bash
# Verificar se dataset existe
ls -la train/data/MyTTSDataset/

# Deve conter:
# - metadata_train.csv
# - metadata_val.csv
# - wavs/

# Se n√£o existe, rodar pipeline completo:
python3 -m train.scripts.download_youtube
python3 -m train.scripts.segment_audio
python3 -m train.scripts.transcribe_audio_parallel
python3 -m train.scripts.build_ljs_dataset
```

### 3. Modelo N√£o Carrega (Template Mode)

**Warning:**
```
‚ö†Ô∏è  SMOKE TEST MODE: Using dummy model (not loading full XTTS)
```

**Explica√ß√£o:**
- v2.0 est√° em modo TEMPLATE
- N√£o carrega modelo XTTS real
- Para implementa√ß√£o real, ver coment√°rios no c√≥digo

**Para Implementar:**

```python
# Em train/scripts/train_xtts.py, fun√ß√£o load_pretrained_model():

# Descomentar e adaptar:
# from TTS.tts.models.xtts import Xtts
# from TTS.tts.configs.xtts_config import XttsConfig
# 
# config = XttsConfig()
# model = Xtts.init_from_config(config)
# model.load_checkpoint(config, checkpoint_path)
```

### 4. LoRA N√£o Funciona

**Error:**
```
AttributeError: 'DummyModel' object has no attribute 'prepare_inputs_for_generation'
```

**Causa:**
- PEFT/LoRA precisa de modelo real com m√©todos espec√≠ficos
- Dummy model em template mode n√£o tem esses m√©todos

**Solu√ß√£o:**
- Implementar modelo XTTS real
- LoRA funcionar√° automaticamente ap√≥s implementa√ß√£o

### 5. Transcription Muito Lenta

**Problema:** Whisper transcribe muito devagar

**Solu√ß√µes:**

```bash
# Usar vers√£o parallel (15x faster)
python3 -m train.scripts.transcribe_audio_parallel

# Ou usar modelo menor
# Editar train/config/dataset_config.yaml:
whisper:
  model: "base"  # ou "small" ao inv√©s de "medium"
```

### 6. Segmentos Muito Curtos/Longos

**Problema:** Muitos segmentos rejeitados

**Solu√ß√£o:**

```bash
# Editar train/config/dataset_config.yaml
segmentation:
  min_duration: 3.0  # Reduzir m√≠nimo
  max_duration: 20.0  # Aumentar m√°ximo
  silence_threshold: -35  # Ajustar threshold
```

---

## üìñ Refer√™ncias

### Documenta√ß√£o Oficial

- [Coqui TTS GitHub](https://github.com/coqui-ai/TTS)
- [XTTS-v2 Model Card](https://huggingface.co/coqui/XTTS-v2)
- [PEFT/LoRA Documentation](https://huggingface.co/docs/peft)
- [Whisper AI](https://github.com/openai/whisper)

### Tutoriais

- [XTTS Fine-tuning Guide](https://docs.coqui.ai/en/latest/tutorial_for_nervous_beginners.html)
- [LoRA Paper](https://arxiv.org/abs/2106.09685)
- [Dataset Preparation Best Practices](https://docs.coqui.ai/en/latest/formatting_your_dataset.html)

### Este Projeto

- `README.md` - Vis√£o geral do pipeline
- `train/train_settings.py` - Configura√ß√£o Pydantic
- `/docs/SESSION_SUMMARY.md` - Sprint TRAIN-3 completion

---

## üéØ Pr√≥ximos Passos

1. ‚úÖ **Prepare Dataset**: Rode pipeline completo
2. ‚è≥ **Implemente Modelo XTTS**: Adapte `load_pretrained_model()`
3. ‚è≥ **Teste Treinamento**: Rode epoch 1-10 para validar
4. ‚è≥ **Treinamento Completo**: 1000 epochs (6-12h)
5. ‚è≥ **Avalie Modelo**: Teste s√≠ntese com checkpoint
6. ‚è≥ **Fine-tune Hiperpar√¢metros**: Ajuste LR, batch size, etc.

**Status v2.0:** Template implementado ‚úÖ | Modelo XTTS real ‚è≥

---

**√öltima atualiza√ß√£o:** 2025-12-07  
**Vers√£o:** v2.0 (Pydantic Settings)
