# Fine-tuning do F5-TTS com Modelo Pr√©-treinado PT-BR

## Vis√£o Geral

Este guia explica como fazer fine-tuning do F5-TTS usando o modelo pr√©-treinado em portugu√™s brasileiro (pt-br) como ponto de partida.

## Arquitetura do Modelo

O F5-TTS usa um modelo DiT (Diffusion Transformer) com EMA (Exponential Moving Average) para melhorar a estabilidade do treinamento.

### Componentes Principais

1. **Modelo Principal**: Pesos do transformer (DiT)
2. **EMA**: M√©dia m√≥vel exponencial dos pesos (melhora qualidade)
3. **Vocabul√°rio**: Tokenizer customizado para pt-br

## Configura√ß√£o do Fine-tuning

### 1. Dataset

O dataset deve estar em `train/data/f5_dataset/` com a seguinte estrutura:

```
f5_dataset/
‚îú‚îÄ‚îÄ metadata.csv       # audio_path|text
‚îú‚îÄ‚îÄ duration.json      # {"duration": [1.5, 2.3, ...]}
‚îú‚îÄ‚îÄ vocab.txt          # Vocabul√°rio (um token por linha)
‚îî‚îÄ‚îÄ wavs/              # Arquivos de √°udio
    ‚îú‚îÄ‚îÄ audio_001.wav
    ‚îú‚îÄ‚îÄ audio_002.wav
    ‚îî‚îÄ‚îÄ ...
```

### 2. Modelo Pr√©-treinado

O modelo pt-br est√° em formato `.pt` (PyTorch nativo) e cont√©m:

- `model`: Pesos do modelo principal
- `ema_model_state_dict`: Pesos do modelo EMA (opcional mas recomendado)
- `optimizer`: Estado do otimizador (opcional)
- `scheduler`: Estado do scheduler (opcional)

**Caminho**: `train/pretrained/F5-TTS-pt-br/pt-br/model_200000.pt`

### 3. Configura√ß√£o (.env)

```bash
# Ativar fine-tuning
BASE_MODEL=firstpixel/F5-TTS-pt-br
PRETRAIN_MODEL_PATH=train/pretrained/F5-TTS-pt-br/pt-br/model_200000.pt
AUTO_DOWNLOAD_PRETRAINED=true

# Dataset
DATASET_NAME=f5_dataset
DATASET_PATH=train/data/f5_dataset

# Hiperpar√¢metros (ajustar conforme VRAM)
BATCH_SIZE=4
BATCH_SIZE_TYPE=sample
LEARNING_RATE=0.0001  # ou 1e-5 para fine-tuning mais conservador
GRAD_ACCUMULATION_STEPS=4
EPOCHS=1000
```

## Problemas Comuns e Solu√ß√µes

### Erro de EMA

**Problema**: "KeyError: 'ema_model_state_dict'" ou modelo n√£o carrega EMA

**Causa**: O modelo .pt pode n√£o ter sido salvo com EMA, ou o c√≥digo de loading est√° esperando um formato diferente.

**Solu√ß√£o 1 - Desabilitar EMA no in√≠cio**:
```python
# Em finetune_cli.py, adicionar flag:
--no-ema  # Desabilita EMA nas primeiras epochs
```

**Solu√ß√£o 2 - Carregar apenas modelo principal**:
```python
# O c√≥digo j√° trata isso:
checkpoint = torch.load(pretrain_path, map_location='cpu')
if 'model' in checkpoint:
    model.load_state_dict(checkpoint['model'])
else:
    model.load_state_dict(checkpoint)  # Arquivo cont√©m apenas pesos
```

**Solu√ß√£o 3 - Converter modelo para SafeTensors** (recomendado para produ√ß√£o):
```bash
python scripts/convert_pt_to_safetensors.py \
    --input train/pretrained/F5-TTS-pt-br/pt-br/model_200000.pt \
    --output train/pretrained/F5-TTS-pt-br/pt-br/model_200000.safetensors
```

### Erro de Vocabul√°rio

**Problema**: "Token n√£o encontrado no vocabul√°rio"

**Solu√ß√£o**: Usar o mesmo `vocab.txt` do modelo pr√©-treinado:
```bash
cp train/pretrained/F5-TTS-pt-br/pt-br/vocab.txt train/data/f5_dataset/
```

### Out of Memory (OOM)

**Problema**: GPU fica sem mem√≥ria

**Solu√ß√µes**:
1. Reduzir `BATCH_SIZE` (ex: 2 ou 1)
2. Aumentar `GRAD_ACCUMULATION_STEPS` (simula batch maior)
3. Usar `MIXED_PRECISION=fp16` ou `bf16`
4. Ativar gradient checkpointing: `gradient_checkpointing: true`

### Perda n√£o diminui

**Problema**: Loss fica est√°vel ou aumenta

**Causas poss√≠veis**:
1. Learning rate muito alto ‚Üí Reduzir para `1e-5` ou `5e-6`
2. Dataset muito pequeno ‚Üí Precisa de pelo menos 1 hora de √°udio
3. Transcri√ß√µes incorretas ‚Üí Verificar `metadata.csv`
4. Batch size muito pequeno ‚Üí Aumentar ou usar gradient accumulation

## Melhores Pr√°ticas

### 1. Prepara√ß√£o do Dataset

- **Dura√ß√£o dos √°udios**: 3-30 segundos (ideal: 5-15s)
- **Qualidade**: Taxa de amostragem 24kHz, mono
- **Transcri√ß√µes**: 100% precisas, sem erros
- **Quantidade**: M√≠nimo 1 hora, ideal 10+ horas
- **Variedade**: M√∫ltiplos speakers para melhor generaliza√ß√£o

### 2. Hiperpar√¢metros Recomendados

#### Para datasets pequenos (1-5 horas):
```bash
BATCH_SIZE=2
LEARNING_RATE=5e-5
GRAD_ACCUMULATION_STEPS=8
EPOCHS=500
NUM_WARMUP_UPDATES=100
```

#### Para datasets m√©dios (5-50 horas):
```bash
BATCH_SIZE=4
LEARNING_RATE=1e-4
GRAD_ACCUMULATION_STEPS=4
EPOCHS=200
NUM_WARMUP_UPDATES=200
```

#### Para datasets grandes (50+ horas):
```bash
BATCH_SIZE=8
LEARNING_RATE=7.5e-5
GRAD_ACCUMULATION_STEPS=2
EPOCHS=100
NUM_WARMUP_UPDATES=500
```

### 3. Monitoramento

Use TensorBoard para acompanhar:
```bash
tensorboard --logdir train/runs --port 6006
```

M√©tricas importantes:
- **Loss**: Deve diminuir consistentemente
- **Learning Rate**: Deve seguir warmup schedule
- **Samples**: Verificar qualidade do √°udio gerado

### 4. Early Stopping

Configure para evitar overfitting:
```bash
EARLY_STOP_PATIENCE=5  # Para ap√≥s 5 epochs sem melhora
EARLY_STOP_MIN_DELTA=0.001  # Melhora m√≠nima significativa
```

## Troubleshooting Avan√ßado

### Verificar se modelo carregou corretamente

```python
import torch

# Carregar checkpoint
ckpt = torch.load('train/pretrained/F5-TTS-pt-br/pt-br/model_200000.pt')

# Ver chaves
print("Chaves:", ckpt.keys())

# Verificar se tem EMA
if 'ema_model_state_dict' in ckpt:
    print("‚úÖ Modelo tem EMA")
else:
    print("‚ùå Modelo n√£o tem EMA")

# Verificar tamanho do modelo
if 'model' in ckpt:
    print(f"Par√¢metros: {sum(p.numel() for p in ckpt['model'].values()) / 1e6:.1f}M")
```

### Converter checkpoint se necess√°rio

Se o modelo n√£o tem a estrutura esperada:

```python
import torch

# Carregar
old = torch.load('model_200000.pt')

# Criar nova estrutura
new = {
    'model': old if isinstance(old, dict) and 'model' not in old else old.get('model'),
    'iteration': 200000,
}

# Salvar
torch.save(new, 'model_200000_fixed.pt')
```

## Refer√™ncias

- [F5-TTS Official Training Guide](https://github.com/SWivid/F5-TTS/tree/main/src/f5_tts/train)
- [Finetune Discussion #57](https://github.com/SWivid/F5-TTS/discussions/57)
- [Modelo PT-BR HuggingFace](https://huggingface.co/firstpixel/F5-TTS-pt-br)

## Pr√≥ximos Passos

1. ‚úÖ Configurar .env com modelo pr√©-treinado
2. ‚úÖ Preparar dataset em train/data/f5_dataset
3. ‚úÖ Iniciar treinamento: `python -m train.run_training`
4. ‚è≥ Monitorar via TensorBoard
5. üéØ Avaliar checkpoints gerados
6. üöÄ Usar modelo fine-tuned em produ√ß√£o
