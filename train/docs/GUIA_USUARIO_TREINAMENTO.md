# ğŸ“š Guia do UsuÃ¡rio - Treinamento XTTS-v2

**Guia completo para treinar seu prÃ³prio modelo de sÃ­ntese de voz (TTS) personalizado**

Este guia foi criado para que qualquer pessoa, **mesmo sem conhecimento tÃ©cnico avanÃ§ado**, consiga treinar um modelo de voz personalizado usando o sistema XTTS-v2.

---

## ğŸ“‹ Ãndice

1. [O que vocÃª vai conseguir fazer](#o-que-vocÃª-vai-conseguir-fazer)
2. [Requisitos do Sistema](#requisitos-do-sistema)
3. [PreparaÃ§Ã£o dos Dados](#preparaÃ§Ã£o-dos-dados)
4. [ConfiguraÃ§Ã£o do Treinamento](#configuraÃ§Ã£o-do-treinamento)
5. [Executando o Treinamento](#executando-o-treinamento)
6. [Monitorando o Progresso](#monitorando-o-progresso)
7. [Testando Seu Modelo](#testando-seu-modelo)
8. [SoluÃ§Ã£o de Problemas](#soluÃ§Ã£o-de-problemas)
9. [Perguntas Frequentes](#perguntas-frequentes)

---

## ğŸ¯ O que vocÃª vai conseguir fazer

ApÃ³s seguir este guia, vocÃª serÃ¡ capaz de:

âœ… **Criar um modelo de voz personalizado** que imita qualquer voz que vocÃª quiser  
âœ… **Gerar Ã¡udio sintÃ©tico** com a voz treinada dizendo qualquer texto  
âœ… **Clonar vozes** com apenas alguns minutos de Ã¡udio de referÃªncia  
âœ… **Melhorar a qualidade** do modelo atravÃ©s de ajustes e mais treinamento  

**Exemplo prÃ¡tico**: VocÃª pode treinar um modelo com gravaÃ§Ãµes da sua prÃ³pria voz e depois fazer esse modelo "ler" livros, artigos ou qualquer texto!

---

## ğŸ’» Requisitos do Sistema

### Hardware MÃ­nimo

| Componente | MÃ­nimo | Recomendado |
|------------|--------|-------------|
| **GPU** | NVIDIA GTX 1080 (8GB VRAM) | NVIDIA RTX 3090 (24GB VRAM) |
| **RAM** | 16 GB | 32 GB ou mais |
| **Armazenamento** | 50 GB livres | 100 GB SSD |
| **CPU** | 4 cores | 8+ cores |

âš ï¸ **Importante**: VocÃª **PRECISA** de uma placa de vÃ­deo NVIDIA com suporte CUDA. CPUs comuns nÃ£o conseguirÃ£o treinar o modelo em tempo razoÃ¡vel.

### Software NecessÃ¡rio

âœ… **Linux** (Ubuntu 20.04+ recomendado) ou **Windows 10/11**  
âœ… **Python 3.9 ou 3.10** (nÃ£o use 3.11+, ainda nÃ£o Ã© totalmente compatÃ­vel)  
âœ… **CUDA 11.8** (para GPUs NVIDIA)  
âœ… **Git** (para clonar o repositÃ³rio)  

---

## ğŸ“ PreparaÃ§Ã£o dos Dados

### Passo 1: Grave ou Colete Ãudios

VocÃª precisa de Ã¡udios da voz que deseja clonar. Quanto mais, melhor!

**Requisitos dos Ã¡udios:**

- âœ… **Formato**: WAV (preferencial) ou MP3
- âœ… **Qualidade**: 22050 Hz ou superior
- âœ… **DuraÃ§Ã£o**: Entre 5 segundos e 30 segundos por arquivo
- âœ… **Quantidade**: MÃ­nimo 30 minutos, ideal 2-10 horas
- âœ… **SilÃªncio**: Pouco ruÃ­do de fundo
- âœ… **ConteÃºdo**: Voz clara, sem mÃºsica ou efeitos

**Dicas para gravaÃ§Ã£o:**

ğŸ¤ Grave em ambiente silencioso (sem eco, sem barulho de fundo)  
ğŸ¤ Use um microfone decente (nÃ£o precisa ser profissional)  
ğŸ¤ Fale naturalmente, com entonaÃ§Ã£o variada  
ğŸ¤ Leia frases completas (nÃ£o palavras isoladas)  
ğŸ¤ Varie o conteÃºdo (perguntas, afirmaÃ§Ãµes, emoÃ§Ãµes diferentes)  

### Passo 2: Organize os Arquivos

Crie uma pasta com seus Ã¡udios:

```
meus_audios/
â”œâ”€â”€ audio001.wav
â”œâ”€â”€ audio002.wav
â”œâ”€â”€ audio003.wav
â””â”€â”€ ...
```

### Passo 3: Prepare o Dataset

O sistema precisa dos Ã¡udios em um formato especÃ­fico. Use o script de preparaÃ§Ã£o:

```bash
# Navegar atÃ© a pasta do projeto
cd /home/tts-webui-proxmox-passthrough

# Executar script de preparaÃ§Ã£o
python -m train.scripts.prepare_dataset \
    --input_dir meus_audios/ \
    --output_dir train/data/MyTTSDataset \
    --language pt
```

**O que esse comando faz:**

1. âœ… Converte todos os Ã¡udios para o formato correto (WAV 22050 Hz)
2. âœ… Divide automaticamente em treino (90%) e validaÃ§Ã£o (10%)
3. âœ… Cria arquivos de metadados necessÃ¡rios
4. âœ… Verifica qualidade dos Ã¡udios

**Resultado esperado:**

```
âœ… Dataset preparado com sucesso!

ğŸ“Š EstatÃ­sticas:
   Total de Ã¡udios: 250
   Treino: 225 samples (90%)
   ValidaÃ§Ã£o: 25 samples (10%)
   DuraÃ§Ã£o total: 2h 15min
   
ğŸ“ Arquivos criados:
   train/data/MyTTSDataset/wavs/       (Ã¡udios processados)
   train/data/MyTTSDataset/metadata_train.csv
   train/data/MyTTSDataset/metadata_val.csv
```

---

## âš™ï¸ ConfiguraÃ§Ã£o do Treinamento

### Passo 1: Editar Arquivo de ConfiguraÃ§Ã£o

Abra o arquivo de configuraÃ§Ã£o com seu editor preferido:

```bash
nano train/config/train_config.yaml
```

### Passo 2: Ajustar ParÃ¢metros Principais

#### **Para iniciantes** (configuraÃ§Ã£o segura):

```yaml
# Quanto tempo treinar
training:
  num_epochs: 50              # 50 Ã©pocas Ã© um bom comeÃ§o
  learning_rate: 1.0e-5       # Taxa de aprendizado (NÃƒO MUDE se nÃ£o souber)
  
# Recursos da GPU
data:
  batch_size: 2               # Use 2 se tem 8-12 GB VRAM
                              # Use 4-6 se tem 24 GB VRAM
                              
# A cada quantas Ã©pocas salvar
logging:
  save_every_n_epochs: 5      # Salva checkpoint a cada 5 Ã©pocas
  log_every_n_steps: 50       # Log a cada 50 passos
```

#### **ConfiguraÃ§Ã£o avanÃ§ada** (usuÃ¡rios experientes):

```yaml
training:
  num_epochs: 100             # Mais Ã©pocas = melhor qualidade (demora mais)
  learning_rate: 5.0e-6       # Learning rate menor = mais estÃ¡vel
  use_amp: false              # Mixed precision (pode dar erro em algumas GPUs)
  
data:
  batch_size: 6               # Maior batch = mais rÃ¡pido (precisa mais VRAM)
  num_workers: 4              # Mais workers = carregamento mais rÃ¡pido
  
logging:
  save_every_n_epochs: 1      # Salva a cada Ã©poca (mais checkpoints)
  use_tensorboard: true       # Monitoramento visual (recomendado!)
```

### Tabela de ReferÃªncia - Batch Size vs VRAM

| VRAM DisponÃ­vel | Batch Size Recomendado |
|-----------------|------------------------|
| 8 GB | 1-2 |
| 12 GB | 2-4 |
| 16 GB | 4-6 |
| 24 GB | 6-8 |

âš ï¸ **Se der erro "Out of Memory"**: Diminua o `batch_size` para 1

---

## ğŸš€ Executando o Treinamento

### OpÃ§Ã£o 1: Treinamento Completo (Recomendado)

Execute o comando abaixo e deixe o treinamento rodar:

```bash
python -m train.scripts.train_xtts --config train/config/train_config.yaml
```

**SaÃ­da esperada:**

```
ğŸš€ Iniciando treinamento XTTS-v2...
   Epochs: 50
   Batch size: 2
   Learning rate: 1e-05
   Device: cuda

ğŸ“Š Datasets carregados:
   Train: 225 samples
   Val: 25 samples
   Steps per epoch: 112

============================================================
EPOCH 1/50
============================================================

Epoch 1/50 | Step 10/112 | Loss: 0.5641 | Avg: 0.5534 | LR: 1.00e-05
Epoch 1/50 | Step 20/112 | Loss: 0.5421 | Avg: 0.5498 | LR: 1.00e-05
...
```

### OpÃ§Ã£o 2: Teste RÃ¡pido (Smoke Test)

Antes de treinar por horas, teste se tudo estÃ¡ funcionando:

```bash
python -m train.scripts.train_xtts --config train/config/smoke_test.yaml
```

Este teste roda apenas **2 Ã©pocas** e termina em ~10 minutos. Se funcionar, seu sistema estÃ¡ pronto!

### Quanto Tempo Demora?

| Dataset | GPU | Ã‰pocas | Tempo Estimado |
|---------|-----|--------|----------------|
| 30 min Ã¡udio | RTX 3090 | 50 | 2-4 horas |
| 2 horas Ã¡udio | RTX 3090 | 50 | 8-12 horas |
| 10 horas Ã¡udio | RTX 3090 | 100 | 24-48 horas |
| 30 min Ã¡udio | GTX 1080 | 50 | 6-10 horas |

ğŸ’¡ **Dica**: Deixe treinando durante a noite ou quando nÃ£o estiver usando o computador.

---

## ğŸ“Š Monitorando o Progresso

### OpÃ§Ã£o 1: Logs no Terminal

Acompanhe o progresso direto no terminal:

```
ğŸ“Š EPOCH 5 COMPLETO
   Train Loss: 0.4123
   Val Loss: 0.3987
   
ğŸ’¾ Checkpoint salvo: checkpoint_epoch_5.pt
ğŸ“¢ Sample: epoch_5_step_560_output.wav + reference.wav
```

**O que significam os nÃºmeros:**

- **Train Loss**: Erro no treino (quanto menor, melhor)
- **Val Loss**: Erro na validaÃ§Ã£o (quanto menor, melhor)
- **ğŸ† Novo melhor modelo**: Aparece quando o modelo melhora

**Valores tÃ­picos:**

- InÃ­cio: Loss ~0.6-0.8 (normal, modelo ainda aprendendo)
- ApÃ³s 20 Ã©pocas: Loss ~0.3-0.5 (jÃ¡ estÃ¡ ficando bom)
- ApÃ³s 50 Ã©pocas: Loss ~0.2-0.3 (qualidade boa)
- ApÃ³s 100 Ã©pocas: Loss <0.2 (excelente qualidade)

### OpÃ§Ã£o 2: TensorBoard (Visual)

TensorBoard mostra grÃ¡ficos bonitos do progresso!

**1. Em outro terminal, execute:**

```bash
tensorboard --logdir train/runs --port 6006
```

**2. Abra no navegador:**

```
http://localhost:6006
```

**O que vocÃª verÃ¡:**

ğŸ“ˆ **GrÃ¡fico de Loss**: Curva descendo = modelo melhorando  
ğŸ“ˆ **Learning Rate**: Veja como a taxa de aprendizado muda  
ğŸ“ˆ **ComparaÃ§Ã£o Treino vs ValidaÃ§Ã£o**: Se divergirem muito, pode estar overfitting  

---

## ğŸµ Testando Seu Modelo

### Passo 1: Encontre o Melhor Checkpoint

Os checkpoints ficam salvos em:

```
train/output/checkpoints/
â”œâ”€â”€ best_model.pt              â† MELHOR MODELO (use este!)
â”œâ”€â”€ checkpoint_epoch_5.pt
â”œâ”€â”€ checkpoint_epoch_10.pt
â””â”€â”€ ...
```

### Passo 2: Teste com Script AutomÃ¡tico

Execute o teste de voice cloning:

```bash
python -m train.scripts.test_voice_clone
```

**O que esse script faz:**

1. âœ… Carrega seu modelo treinado (`best_model.pt`)
2. âœ… Pega um Ã¡udio de referÃªncia
3. âœ… Transcreve o Ã¡udio automaticamente (usando Whisper)
4. âœ… Gera novo Ã¡udio com a voz clonada
5. âœ… Compara qualidade entre original e clonado
6. âœ… DÃ¡ uma nota de 0 a 5 para a qualidade

**SaÃ­da esperada:**

```
ğŸ“ ETAPA 1: TranscriÃ§Ã£o do Ã¡udio de referÃªncia
âœ… TranscriÃ§Ã£o completa:
   "Este Ã© um teste do sistema de sÃ­ntese de voz."

ğŸ™ï¸  ETAPA 2: GeraÃ§Ã£o de Ã¡udio clonado
âœ… Ãudio clonado gerado: cloned_output.wav

ğŸ“Š ETAPA 3: AnÃ¡lise de qualidade comparativa
â±ï¸  DuraÃ§Ã£o:
   ReferÃªncia: 3.45s
   Clonado: 3.52s
   DiferenÃ§a: 0.07s (102.0%)

ğŸµ Similaridade Espectral (MFCC):
   Similaridade: 0.8234 (0-1, maior = mais similar)
   Qualidade: âœ… Excelente

â­ Score Geral (estimado MOS 0-5):
   â­ SCORE FINAL: 4.12/5.0
   Qualidade: âœ… EXCELENTE - Clonagem de alta qualidade
```

### Passo 3: OuÃ§a os Ãudios

Os resultados ficam em `train/test/results/`:

```
train/test/results/
â”œâ”€â”€ cloned_output.wav      â† Ãudio gerado pelo modelo
â”œâ”€â”€ transcription.txt      â† Texto transcrito
â””â”€â”€ test_results.json      â† MÃ©tricas detalhadas
```

**Compare vocÃª mesmo:**

ğŸ§ OuÃ§a `reference_test.wav` (original)  
ğŸ§ OuÃ§a `cloned_output.wav` (gerado)  

### Passo 4: Teste com Seu PrÃ³prio Texto

Crie um script Python simples:

```python
from train.scripts.xtts_inference import XTTSInference

# Carregar modelo treinado
model = XTTSInference(
    checkpoint_path="train/output/checkpoints/best_model.pt"
)

# Gerar Ã¡udio com voz clonada
model.synthesize_to_file(
    text="OlÃ¡! Este Ã© meu modelo de voz personalizado.",
    output_path="meu_audio.wav",
    language="pt",
    speaker_wav="train/test/audio/reference_test.wav"
)

print("âœ… Ãudio gerado: meu_audio.wav")
```

Execute:

```bash
python meu_teste.py
```

---

## ğŸ”§ SoluÃ§Ã£o de Problemas

### âŒ Erro: "CUDA Out of Memory"

**Problema**: GPU sem memÃ³ria suficiente.

**SoluÃ§Ã£o**:

1. Abra `train/config/train_config.yaml`
2. Diminua `batch_size` de 2 para 1
3. Tente novamente

```yaml
data:
  batch_size: 1  # Era 2, agora Ã© 1
```

### âŒ Erro: "No module named 'TTS'"

**Problema**: Biblioteca TTS (Coqui) nÃ£o instalada.

**SoluÃ§Ã£o**:

```bash
pip install TTS
```

### âŒ Erro: "Whisper not found"

**Problema**: Whisper nÃ£o instalado (necessÃ¡rio para transcriÃ§Ã£o).

**SoluÃ§Ã£o**:

```bash
pip install openai-whisper
```

### âŒ Loss nÃ£o diminui / fica estagnado

**Problema**: Modelo nÃ£o estÃ¡ aprendendo.

**PossÃ­veis causas e soluÃ§Ãµes**:

1. **Dataset muito pequeno**: Adicione mais Ã¡udios (ideal >1 hora)
2. **Learning rate muito alto**: Diminua para `5.0e-6`
3. **Overfitting**: Adicione mais dados de validaÃ§Ã£o
4. **Ãudios ruins**: Verifique qualidade (sem ruÃ­do, voz clara)

### âŒ Ãudio gerado com qualidade ruim

**Problema**: Modelo gera Ã¡udio, mas qualidade Ã© baixa.

**SoluÃ§Ãµes**:

1. **Treine mais Ã©pocas**: Tente 100-200 Ã©pocas em vez de 50
2. **Melhore dataset**: 
   - Remova Ã¡udios com ruÃ­do
   - Adicione mais variedade
   - Garanta que todos estejam no formato correto
3. **Ajuste hyperparÃ¢metros**:
   ```yaml
   training:
     learning_rate: 5.0e-6  # Menor = mais estÃ¡vel
     num_epochs: 100
   ```

### âŒ TensorBoard nÃ£o abre

**Problema**: Porta 6006 jÃ¡ estÃ¡ em uso.

**SoluÃ§Ã£o**: Use porta diferente:

```bash
tensorboard --logdir train/runs --port 6007
# Abra: http://localhost:6007
```

---

## â“ Perguntas Frequentes

### 1. Quanto Ã¡udio preciso para treinar?

**Resposta**:

- **MÃ­nimo**: 30 minutos (qualidade bÃ¡sica)
- **Bom**: 1-2 horas (qualidade razoÃ¡vel)
- **Excelente**: 5-10 horas (alta qualidade)
- **Profissional**: 20+ horas (qualidade mÃ¡xima)

### 2. Posso treinar com Ã¡udios de podcast/YouTube?

**Resposta**: Sim, mas com cuidados:

âœ… **Permitido**: Se vocÃª tem direitos sobre o Ã¡udio  
âš ï¸ **Qualidade**: Remova mÃºsicas, efeitos sonoros, mÃºltiplas vozes  
âš ï¸ **Legal**: Respeite direitos autorais (use apenas com permissÃ£o)  

### 3. Quanto custa treinar (em energia elÃ©trica)?

**Resposta**: Estimativa aproximada:

- RTX 3090: ~350W
- 10 horas de treino = 3.5 kWh
- Custo: R$ 2-5 (dependendo da tarifa)

### 4. Posso parar o treinamento e continuar depois?

**Resposta**: SIM! O sistema salva checkpoints automaticamente.

Para continuar de onde parou:

```bash
python -m train.scripts.train_xtts \
    --config train/config/train_config.yaml \
    --resume_from train/output/checkpoints/checkpoint_epoch_20.pt
```

### 5. Qual a diferenÃ§a entre treino e fine-tuning?

**Resposta**:

- **Treino do zero**: Demora semanas, precisa centenas de horas de Ã¡udio
- **Fine-tuning** (o que fazemos aqui): Ajusta modelo prÃ©-treinado, demora horas, precisa 30min-10h de Ã¡udio

Estamos fazendo **fine-tuning**, que Ã© muito mais rÃ¡pido e prÃ¡tico!

### 6. O modelo funciona em tempo real?

**Resposta**: Depende da GPU:

- RTX 3090: ~1-2 segundos para gerar 10 segundos de Ã¡udio
- RTX 4090: <1 segundo para 10 segundos de Ã¡udio
- GTX 1080: ~3-5 segundos para 10 segundos de Ã¡udio

**NÃ£o Ã© exatamente tempo real**, mas Ã© rÃ¡pido o suficiente para muitas aplicaÃ§Ãµes!

### 7. Posso usar o modelo comercialmente?

**Resposta**: Depende:

- âœ… **CÃ³digo**: MIT License (livre para uso comercial)
- âš ï¸ **Modelo XTTS-v2**: Verifique licenÃ§a do Coqui TTS
- âš ï¸ **Voz clonada**: Precisa de permissÃ£o do dono da voz

**RecomendaÃ§Ã£o**: Consulte um advogado para uso comercial.

### 8. Como melhorar a qualidade do Ã¡udio gerado?

**Checklist de qualidade**:

- [ ] Dataset com >2 horas de Ã¡udio
- [ ] Ãudios sem ruÃ­do de fundo
- [ ] Microfone decente (nÃ£o precisa ser caro)
- [ ] Ambiente silencioso
- [ ] Variedade no conteÃºdo (nÃ£o repetir frases)
- [ ] Treinar por 100+ Ã©pocas
- [ ] Val Loss <0.25
- [ ] Usar `best_model.pt` (nÃ£o checkpoints intermediÃ¡rios)

### 9. Posso treinar mÃºltiplas vozes no mesmo modelo?

**Resposta**: NÃƒO recomendado. Treine um modelo separado para cada voz.

Se misturar vozes:
- âŒ Qualidade cai
- âŒ Modelo fica confuso
- âŒ DifÃ­cil controlar qual voz serÃ¡ usada

### 10. O que fazer se meu computador travar durante o treino?

**Resposta**:

1. âœ… **NÃ£o se preocupe**: Checkpoints sÃ£o salvos automaticamente
2. âœ… **Reinicie** e continue de onde parou (veja pergunta 4)
3. âœ… **PrevenÃ§Ã£o futura**:
   - Monitore temperatura da GPU
   - Use batch_size menor
   - Feche outros programas pesados

---

## ğŸ“– Recursos Adicionais

### DocumentaÃ§Ã£o TÃ©cnica

- ğŸ“„ [XTTS-v2 Paper](https://arxiv.org/abs/2406.04904)
- ğŸ“„ [Coqui TTS Docs](https://docs.coqui.ai/)
- ğŸ“„ [TensorBoard Guide](https://www.tensorflow.org/tensorboard)

### Comunidade

- ğŸ’¬ Discord: [Coqui Community](https://discord.gg/coqui)
- ğŸ™ GitHub: [XTTS Issues](https://github.com/coqui-ai/TTS/issues)

### Tutoriais em VÃ­deo

- ğŸ¥ "Voice Cloning with XTTS" - YouTube
- ğŸ¥ "TensorBoard for Beginners" - YouTube
- ğŸ¥ "Audio Preprocessing Tutorial" - YouTube

---

## ğŸ“ ConclusÃ£o

ParabÃ©ns! ğŸ‰ Agora vocÃª sabe como:

âœ… Preparar um dataset de Ã¡udio  
âœ… Configurar e executar o treinamento  
âœ… Monitorar o progresso com TensorBoard  
âœ… Testar e usar seu modelo personalizado  
âœ… Resolver problemas comuns  

**PrÃ³ximos passos**:

1. ğŸš€ Treine seu primeiro modelo com 1-2 horas de Ã¡udio
2. ğŸ§ Teste a qualidade e compare com o original
3. ğŸ”§ Ajuste parÃ¢metros para melhorar resultados
4. ğŸ“ˆ Aumente o dataset para melhor qualidade
5. ğŸ¯ Use seu modelo em produÃ§Ã£o!

**Precisa de ajuda?**

- ğŸ“§ Abra uma issue no GitHub
- ğŸ’¬ Pergunte na comunidade Discord
- ğŸ“š Consulte a documentaÃ§Ã£o tÃ©cnica

**Boa sorte com seu treinamento!** ğŸš€ğŸ¤

---

*Ãšltima atualizaÃ§Ã£o: Dezembro 2024*  
*VersÃ£o do guia: 1.0*  
*CompatÃ­vel com: XTTS-v2, Python 3.9-3.10, CUDA 11.8*
