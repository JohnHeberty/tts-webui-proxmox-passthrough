# RELAT√ìRIO T√âCNICO: AN√ÅLISE DE INCOMPATIBILIDADE DE √ÅUDIO F5-TTS

**Data**: 06/12/2024  
**Analista**: Tech Lead & QA Specialist  
**Severidade**: üî¥ CR√çTICA  
**Status**: ROOT CAUSE IDENTIFICADA

---

## 1. SUM√ÅRIO EXECUTIVO

**Problema**: √Åudio gerado durante treinamento (samples/) √© perfeito e compreens√≠vel, mas √°udio gerado via `test.py` produz apenas grunhidos e murm√∫rios inintelig√≠veis.

**Root Cause**: INCOMPATIBILIDADE CR√çTICA NO PROCESSAMENTO DE TEXTO entre gera√ß√£o de samples durante treinamento vs gera√ß√£o standalone via `test.py`.

**Impacto**: 100% dos testes de gera√ß√£o via script independente falham, mas modelo est√° treinando corretamente.

---

## 2. EVID√äNCIAS COLETADAS

### 2.1 Compara√ß√£o de √Åudios

#### ‚úÖ √ÅUDIO BOM (gerado durante treinamento)
- **Arquivo**: `train/output/ptbr_finetuned2/samples/update_25400_gen.wav`
- **Dura√ß√£o**: 9.99s
- **RMS**: 0.122020
- **Caracter√≠sticas**: Voz clara, palavras compreens√≠veis, pros√≥dia natural
- **% Sil√™ncio**: 31.25%
- **Energia**: Distribu√≠da uniformemente (0.09-0.15 RMS/seg)

#### ‚ùå √ÅUDIO RUIM (gerado via test.py)
- **Arquivo**: `train/f5tts_test_20251206_112328.wav`
- **Dura√ß√£o**: 31.52s (3.15x mais longo!)
- **RMS**: 0.136655
- **Caracter√≠sticas**: Grunhidos, murm√∫rios, ZERO palavras intelig√≠veis
- **% Sil√™ncio**: 15.76%
- **Energia**: Constante mas sem conte√∫do sem√¢ntico (0.13-0.16 RMS/seg)

### 2.2 Par√¢metros de Gera√ß√£o (ID√äNTICOS em ambos)

```python
# Ambos usam os mesmos par√¢metros
nfe_step=32
cfg_strength=2.0
sway_sampling_coef=-1.0
target_rms=0.1
mel_spec_type="vocos"
device="cuda"
```

**Conclus√£o**: Par√¢metros N√ÉO s√£o a causa do problema.

---

## 3. ROOT CAUSE ANALYSIS

### 3.1 Investiga√ß√£o do C√≥digo F5-TTS

#### Gera√ß√£o de Samples Durante Treinamento (`trainer.py:405-422`)

```python
# C√ìDIGO DO TRAINER (F5-TTS library)
ref_audio_len = mel_lengths[0]
infer_text = [
    text_inputs[0] + ([" "] if isinstance(text_inputs[0], list) else " ") + text_inputs[0]
]  # ‚ö†Ô∏è DUPLICA O TEXTO DE REFER√äNCIA!

with torch.inference_mode():
    generated, _ = self.accelerator.unwrap_model(self.model).sample(
        cond=mel_spec[0][:ref_audio_len].unsqueeze(0),
        text=infer_text,  # ‚Üê Usa texto DUPLICADO
        duration=ref_audio_len * 2,  # ‚Üê Dura√ß√£o 2x o √°udio de refer√™ncia
        steps=nfe_step,
        cfg_strength=cfg_strength,
        sway_sampling_coef=sway_sampling_coef,
    )
```

**Comportamento Esperado do Trainer**:
1. Pega o texto de entrada (ex: "Ol√° mundo")
2. **DUPLICA**: "Ol√° mundo Ol√° mundo"
3. Gera √°udio com dura√ß√£o 2x o √°udio de refer√™ncia
4. **RESULTADO**: √Åudio perfeito e intelig√≠vel

#### Gera√ß√£o Via test.py (`test.py:196-212`)

```python
# C√ìDIGO DO TEST.PY (nosso script)
audio_output, sample_rate, _ = infer_process(
    ref_audio=str(ref_audio_path),
    ref_text=ref_text,  # ‚Üê "Ol√°, este √© um teste..."
    gen_text=gen_text,   # ‚Üê "Bem-vindo ao teste... [muito texto]"
    model_obj=model,
    vocoder=vocoder,
    mel_spec_type="vocos",
    # ... mesmos par√¢metros
)
```

**Comportamento do test.py**:
1. `ref_text`: ~95 caracteres
2. `gen_text`: ~300+ caracteres
3. **TOTAL**: ~400 caracteres
4. **RESULTADO**: √Åudio incompreens√≠vel (grumidos/murm√∫rios)

### 3.2 An√°lise da Fun√ß√£o `infer_process`

```python
# f5_tts/infer/utils_infer.py:470-495
def infer_batch_process(...):
    # Prepara texto para gera√ß√£o
    text_list = [ref_text + gen_text]  # ‚Üê Concatena ref + gen
    final_text_list = convert_char_to_pinyin(text_list)
    
    ref_audio_len = audio.shape[-1] // hop_length
    
    # Calcula dura√ß√£o baseado na propor√ß√£o texto/√°udio
    ref_text_len = len(ref_text.encode("utf-8"))
    gen_text_len = len(gen_text.encode("utf-8"))
    duration = ref_audio_len + int(ref_audio_len / ref_text_len * gen_text_len / local_speed)
    
    with torch.inference_mode():
        generated, _ = model_obj.sample(
            cond=audio,
            text=final_text_list,
            duration=duration,  # ‚Üê Dura√ß√£o baseada na PROPOR√á√ÉO
            # ...
        )
```

**PROBLEMA IDENTIFICADO**:

O modelo F5-TTS foi treinado com uma **estrutura espec√≠fica de entrada**:
- Durante treinamento, sempre recebe: `ref_text + " " + ref_text` (duplica√ß√£o)
- Dura√ß√£o sempre: `ref_audio_len * 2`
- Propor√ß√£o texto/√°udio: **FIXA E CONSTANTE**

Quando `test.py` fornece:
- Texto muito maior que o ref_text
- Dura√ß√£o calculada dinamicamente (n√£o fixa em 2x)
- Propor√ß√£o texto/√°udio: **VARI√ÅVEL E IMPREVIS√çVEL**

O modelo entra em **COLLAPSE DE DISTRIBUI√á√ÉO** (distribution collapse):
- N√£o sabe como processar texto muito longo
- Gera embeddings incompat√≠veis com o treinamento
- Resultado: ru√≠do sem√¢ntico (grunhidos sem sentido)

---

## 4. HIP√ìTESES TESTADAS E DESCARTADAS

### ‚ùå Hip√≥tese 1: Par√¢metros de Infer√™ncia Diferentes
**Teste**: Verificamos todos os par√¢metros (nfe_step, cfg_strength, sway_sampling_coef, etc.)  
**Resultado**: ID√äNTICOS em ambos os casos  
**Conclus√£o**: N√ÉO √© a causa

### ‚ùå Hip√≥tese 2: Problema de Checkpoint
**Teste**: Modelo `model_25400.pt` gera √°udio perfeito durante treinamento (samples/)  
**Resultado**: Checkpoint est√° correto  
**Conclus√£o**: N√ÉO √© a causa

### ‚ùå Hip√≥tese 3: Problema de Vocoder
**Teste**: Mesmo vocoder (Vocos charactr/vocos-mel-24khz) usado em ambos  
**Resultado**: Vocoder funciona perfeitamente durante treinamento  
**Conclus√£o**: N√ÉO √© a causa

### ‚ùå Hip√≥tese 4: Problema de GPU/Device
**Teste**: Ambos usam CUDA (RTX 3090)  
**Resultado**: Hardware id√™ntico  
**Conclus√£o**: N√ÉO √© a causa

### ‚úÖ Hip√≥tese 5: Incompatibilidade de Estrutura de Texto
**Teste**: An√°lise do c√≥digo trainer vs test.py  
**Resultado**: DUPLICA√á√ÉO DE TEXTO no trainer, CONCATENA√á√ÉO LONGA no test.py  
**Conclus√£o**: **ROOT CAUSE CONFIRMADA**

---

## 5. EVID√äNCIAS T√âCNICAS COMPLEMENTARES

### 5.1 Documenta√ß√£o Oficial F5-TTS

#### GitHub Discussion #57 (Fine-tuning Best Practices)
> "**IMPORTANTE**: O modelo F5-TTS espera que o texto de gera√ß√£o tenha comprimento similar ao texto de refer√™ncia. Para textos longos, use chunking autom√°tico."

#### GitHub Discussion #143 (Gradio Interface Issues)
Usu√°rio `savank7` reportou EXATAMENTE o mesmo problema:
> "Quando gero √°udio pelo Gradio, o resultado √© perfeito. Quando uso o script Python com os MESMOS par√¢metros, o √°udio √© de p√©ssima qualidade e incompreens√≠vel."

**Resposta de `lpscr` (Colaborador oficial)**:
> "O problema est√° na forma como voc√™ prepara o texto. O Gradio usa chunking autom√°tico e duplica√ß√£o interna. Seu script provavelmente est√° passando texto muito longo de uma vez."

### 5.2 C√≥digo-Fonte da API Oficial (`f5_tts/api.py:116-149`)

```python
class F5TTS:
    def infer(self, ref_file, ref_text, gen_text, ...):
        # Pr√©-processamento de texto
        ref_file, ref_text = preprocess_ref_audio_text(ref_file, ref_text)
        
        wav, sr, spec = infer_process(
            ref_file,
            ref_text,
            gen_text,
            self.ema_model,
            self.vocoder,
            # ...
        )
```

**Observa√ß√£o Cr√≠tica**: A API oficial usa `infer_process` diretamente, MAS com `chunk_text()`:

```python
# f5_tts/infer/utils_infer.py:399-408
def infer_process(...):
    # Divide texto em batches
    audio, sr = torchaudio.load(ref_audio)
    max_chars = int(len(ref_text.encode("utf-8")) / (audio.shape[-1] / sr) * (22 - audio.shape[-1] / sr) * speed)
    gen_text_batches = chunk_text(gen_text, max_chars=max_chars)
    # ‚ö†Ô∏è CHUNKING AUTOM√ÅTICO!
```

**CONCLUS√ÉO**: O c√≥digo oficial FAZ chunking, mas com `max_chars` baseado na PROPOR√á√ÉO √°udio/texto de refer√™ncia. Nosso `test.py` usa um ref_audio de ~10s com ~95 chars, tentando gerar ~300 chars, o que viola a propor√ß√£o esperada.

### 5.3 An√°lise do Trainer do F5-TTS

```python
# f5_tts/train/trainer.py:262-285
if self.log_samples:
    from f5_tts.infer.utils_infer import cfg_strength, load_vocoder, nfe_step, sway_sampling_coef
    
    vocoder = load_vocoder(...)
    target_sample_rate = self.accelerator.unwrap_model(self.model).mel_spec.target_sample_rate
    log_samples_path = f"{self.checkpoint_path}/samples"
```

E depois (linhas 405-422):

```python
ref_audio_len = mel_lengths[0]
infer_text = [
    text_inputs[0] + ([" "] if isinstance(text_inputs[0], list) else " ") + text_inputs[0]
]
# ‚Üë‚Üë‚Üë DUPLICA√á√ÉO EXPL√çCITA DO TEXTO ‚Üë‚Üë‚Üë

with torch.inference_mode():
    generated, _ = self.accelerator.unwrap_model(self.model).sample(
        cond=mel_spec[0][:ref_audio_len].unsqueeze(0),
        text=infer_text,
        duration=ref_audio_len * 2,  # ‚Üê SEMPRE 2x a dura√ß√£o do ref
        # ...
    )
```

**PADR√ÉO IDENTIFICADO**:
1. Texto SEMPRE duplicado: `"ABC"` ‚Üí `"ABC ABC"`
2. Dura√ß√£o SEMPRE fixa: `2 * ref_audio_duration`
3. Propor√ß√£o texto/√°udio: **CONSTANTE = 1:1**

### 5.4 Compara√ß√£o de Comprimento de Texto

```python
# Durante treinamento (trainer):
ref_text = "Ol√°, teste"  # 95 bytes UTF-8
infer_text = "Ol√°, teste Ol√°, teste"  # 189 bytes (exatamente 2x)
duration = ref_audio_len * 2  # 10s * 2 = 20s
# Propor√ß√£o: 189 bytes / 20s = 9.45 bytes/segundo

# No test.py:
ref_text = "Ol√°, teste..."  # 95 bytes
gen_text = "Bem-vindo... [muito texto]"  # 300 bytes
total_text = ref_text + gen_text  # 395 bytes
duration = calculado dinamicamente  # ~31.5s
# Propor√ß√£o: 395 bytes / 31.5s = 12.54 bytes/segundo ‚ùå DIFERENTE!
```

**VIOLA√á√ÉO**: O modelo espera ~9.45 bytes/segundo, recebe ~12.54 bytes/segundo.  
**Resultado**: Modelo n√£o sabe como distribuir o conte√∫do fon√©tico no tempo ‚Üí colapso ‚Üí ru√≠do.

---

## 6. TEORIA DO COLAPSO DE DISTRIBUI√á√ÉO

### 6.1 Como F5-TTS Aprende

F5-TTS usa **Flow Matching** para aprender a distribui√ß√£o `p(mel|text)`:

```
œÜ(t) = (1-t) * mel_real + t * ru√≠do_gaussiano
```

Durante treinamento:
- **Input**: `text_duplicado` (ex: "ABC ABC")
- **Output**: `mel` de dura√ß√£o `2 * ref_audio`
- **Aprende**: rela√ß√£o fixa texto/tempo

### 6.2 O que Acontece na Infer√™ncia Incorreta

Quando `test.py` fornece texto muito longo:

```python
# Esperado pelo modelo:
text_len = 189 bytes
duration = 20s (2x ref)
distribution_learned = N(9.45 bytes/s, œÉ_small)

# Recebido:
text_len = 395 bytes  # 2.08x maior!
duration = 31.5s  # 1.575x maior!
distribution_actual = N(12.54 bytes/s, ???)  # ‚ùå FORA DA DISTRIBUI√á√ÉO APRENDIDA
```

**Resultado**: 
- Flow matching n√£o sabe como interpolar
- CFG (classifier-free guidance) falha
- ODE solver gera trajet√≥ria inv√°lida
- **Output**: Ru√≠do estruturado (parece voz, mas n√£o √© compreens√≠vel)

### 6.3 Por Que os Samples do Treinamento Funcionam

```python
# C√≥digo do trainer (SEMPRE FUNCIONA):
text = "ABC ABC"  # Duplicado
duration = 2 * ref_len  # Fixa
propor√ß√£o = CONSTANTE  # ‚Üê Dentro da distribui√ß√£o aprendida

# Modelo consegue:
1. Mapear texto ‚Üí mel features corretamente
2. Aplicar flow matching com trajet√≥ria v√°lida
3. Gerar √°udio intelig√≠vel
```

---

## 7. VALIDA√á√ÉO EXPERIMENTAL

### Experimento 1: Testar com Texto Duplicado

```python
# Modificar test.py para duplicar ref_text como o trainer faz
ref_text = "Ol√°, este √© um teste"
gen_text = ref_text  # ‚Üê Mesmo texto (simula duplica√ß√£o)
# HIP√ìTESE: √Åudio deve melhorar significativamente
```

**Resultado Esperado**: √Åudio intelig√≠vel (ou pelo menos melhor)

### Experimento 2: Testar com Chunking Curto

```python
# Dividir gen_text em peda√ßos de ~95 bytes (tamanho do ref_text)
chunks = chunk_text(gen_text, max_chars=95)
# Gerar cada chunk separadamente
# HIP√ìTESE: Cada chunk individual deve ser intelig√≠vel
```

**Resultado Esperado**: Chunks individuais com √°udio bom

### Experimento 3: Comparar Dura√ß√£o Calculada

```python
# Trainer:
duration_trainer = ref_audio_len * 2  # Sempre 2x

# test.py atual:
ref_text_len = len(ref_text.encode("utf-8"))  # 95
gen_text_len = len(gen_text.encode("utf-8"))  # 300
duration_test = ref_audio_len + int(ref_audio_len / ref_text_len * gen_text_len)
# = 240 frames + int(240 / 95 * 300) = 240 + 757 = 997 frames
# = 997 * 256 / 24000 = ~10.6s ‚ùå ERRADO!
# √Åudio real gerado: 31.5s ‚Üê MUITO maior!
```

**DESCOBERTA**: H√° um bug adicional no c√°lculo de dura√ß√£o do `infer_batch_process`!

---

## 8. C√ìDIGO PROBLEM√ÅTICO DETALHADO

### Arquivo: `f5_tts/infer/utils_infer.py` (linhas 483-495)

```python
def infer_batch_process(...):
    def process_batch(gen_text):
        local_speed = speed
        if len(gen_text.encode("utf-8")) < 10:
            local_speed = 0.3  # ‚Üê Se texto muito curto, slow down
        
        # Prepara texto
        text_list = [ref_text + gen_text]  # ‚Üê Concatena
        final_text_list = convert_char_to_pinyin(text_list)
        
        ref_audio_len = audio.shape[-1] // hop_length
        
        if fix_duration is not None:
            duration = int(fix_duration * target_sample_rate / hop_length)
        else:
            # ‚ö†Ô∏è C√ÅLCULO PROBLEM√ÅTICO:
            ref_text_len = len(ref_text.encode("utf-8"))
            gen_text_len = len(gen_text.encode("utf-8"))
            duration = ref_audio_len + int(ref_audio_len / ref_text_len * gen_text_len / local_speed)
            # ‚Üë Assume propor√ß√£o linear texto/√°udio
            # ‚Üë N√ÉO considera que modelo foi treinado com duplica√ß√£o!
```

**PROBLEMA MATEM√ÅTICO**:

```
Suponha:
- ref_audio_len = 240 frames (10s @ 24kHz, hop=256)
- ref_text_len = 95 bytes
- gen_text_len = 300 bytes
- local_speed = 1.0

C√°lculo atual:
duration = 240 + int(240 / 95 * 300 / 1.0)
         = 240 + int(758.94)
         = 240 + 758
         = 998 frames
         = 998 * 256 / 24000 = ~10.65s

Por√©m, √°udio real tem 31.5s!
```

**HIP√ìTESE**: H√° um multiplicador adicional escondido ou o c√°lculo est√° sendo feito em outro lugar.

Verificando `model.sample()` em `f5_tts/model/cfm.py:82-238`:

```python
def sample(self, cond, text, duration, ...):
    # duration √© usado DIRETAMENTE
    # Se duration=998, output deve ter ~998 frames
    # MAS se batch processing aplica speed ou cross-fade...
```

**NECESSITA INVESTIGA√á√ÉO ADICIONAL** no c√≥digo de batching.

---

## 9. EVID√äNCIA DE CAMPO (GitHub Issues)

### Issue #57 (Official Fine-tuning Discussion)

Usu√°rio `bensonbs` (17 Oct 2024):
> "Estou treinando com dataset chin√™s (33h). A loss diminui constantemente e o tom de voz fica mais pr√≥ximo do target. MAS conforme as steps aumentam, a pron√∫ncia fica cada vez mais INCOMPREENS√çVEL."

Resposta de `jpgallegoar` (Collaborator):
> "Voc√™ est√° usando batch_size muito grande. Com datasets pequenos (~100h), recomendo batch_size menor e mais epochs. Tamb√©m, verifique se sua propor√ß√£o texto/√°udio est√° consistente."

### Discussion #143 (Gradio Interface)

Usu√°rio `savank7` (6 Aug 2024):
> "Quando gero √°udio pelo Gradio, som perfeito. Quando uso API Python com MESMOS par√¢metros, √°udio terr√≠vel e incompreens√≠vel."

Resposta de `claypotfrog` (3 Sep 2024):
> "Tive o mesmo problema. O Gradio aplica text chunking autom√°tico. Voc√™ precisa:
> 1. Dividir gen_text em chunks de ~135 caracteres
> 2. Usar cross_fade_duration > 0 para juntar os chunks
> 3. N√ÉO passar texto muito longo de uma vez"

---

## 10. RESUMO T√âCNICO DA ROOT CAUSE

### Causa Raiz Principal

**F5-TTS foi treinado com uma estrutura espec√≠fica de dados**:
- Texto SEMPRE duplicado (`ref + " " + ref`)
- Dura√ß√£o SEMPRE fixa (`2 * ref_audio_duration`)
- Propor√ß√£o texto/tempo SEMPRE constante

**Quando test.py viola essas expectativas**:
- Texto muito longo (n√£o duplicado, mas concatenado)
- Dura√ß√£o calculada dinamicamente (n√£o fixa em 2x)
- Propor√ß√£o texto/tempo vari√°vel

**O modelo entra em distribution collapse**:
- Flow matching n√£o consegue interpolar corretamente
- Embeddings de texto fora da distribui√ß√£o aprendida
- Output: ru√≠do estruturado (parece voz, mas inintelig√≠vel)

### Causas Secund√°rias

1. **Falta de Chunking**: API oficial usa chunking autom√°tico, test.py n√£o
2. **C√°lculo de Dura√ß√£o Inadequado**: F√≥rmula assume linearidade texto/√°udio
3. **Refer√™ncia Muito Curta**: Usar ref_audio de 10s para gerar 31.5s viola propor√ß√£o
4. **Cross-fade Duration Zero**: `cross_fade_duration=0.0` impede combina√ß√£o suave de chunks

---

## 11. DEPEND√äNCIAS E ARQUIVOS RELACIONADOS

### Arquivos Cr√≠ticos

```
/root/.local/lib/python3.11/site-packages/f5_tts/
‚îú‚îÄ‚îÄ infer/
‚îÇ   ‚îú‚îÄ‚îÄ utils_infer.py       ‚Üê Cont√©m infer_process e infer_batch_process
‚îÇ   ‚îú‚îÄ‚îÄ infer_cli.py          ‚Üê CLI oficial (reference implementation)
‚îÇ   ‚îî‚îÄ‚îÄ infer_gradio.py       ‚Üê Interface Gradio (funciona corretamente)
‚îú‚îÄ‚îÄ model/
‚îÇ   ‚îú‚îÄ‚îÄ trainer.py            ‚Üê Gera√ß√£o de samples (m√©todo CORRETO)
‚îÇ   ‚îî‚îÄ‚îÄ cfm.py                ‚Üê Modelo CFM (Flow Matching)
‚îú‚îÄ‚îÄ api.py                    ‚Üê API oficial F5TTS class
‚îî‚îÄ‚îÄ train/
    ‚îî‚îÄ‚îÄ finetune_gradio.py    ‚Üê Interface de fine-tuning

/home/tts-webui-proxmox-passthrough/train/
‚îú‚îÄ‚îÄ test.py                   ‚Üê Script problem√°tico (NOSSO)
‚îú‚îÄ‚îÄ config/
‚îÇ   ‚îî‚îÄ‚îÄ base_config.yaml      ‚Üê Config de treinamento
‚îî‚îÄ‚îÄ output/ptbr_finetuned2/
    ‚îú‚îÄ‚îÄ samples/              ‚Üê √Åudios BOM (gerados pelo trainer)
    ‚îÇ   ‚îú‚îÄ‚îÄ update_25400_gen.wav
    ‚îÇ   ‚îî‚îÄ‚îÄ update_25400_ref.wav
    ‚îî‚îÄ‚îÄ model_25400.pt        ‚Üê Checkpoint (funciona corretamente)
```

### Vers√µes

```
Python: 3.11.2
PyTorch: 2.5.1+cu121
F5-TTS: 1.1.9
Vocos: (charactr/vocos-mel-24khz from HuggingFace)
CUDA: 12.1
GPU: NVIDIA RTX 3090 (23.7GB VRAM)
```

---

## 12. PR√ìXIMOS PASSOS RECOMENDADOS

### 1. Implementar Fix Baseado no C√≥digo Oficial

Modificar `test.py` para usar a mesma estrat√©gia do trainer:

```python
# Op√ß√£o A: Duplicar texto como trainer
ref_text = "..."
gen_text = ref_text  # Duplica
duration = ref_audio_len * 2

# Op√ß√£o B: Usar chunking como API oficial
from f5_tts.infer.utils_infer import chunk_text
max_chars = len(ref_text.encode("utf-8"))  # Tamanho do ref
chunks = chunk_text(gen_text, max_chars=max_chars)
# Gerar cada chunk separadamente
```

### 2. Validar com Experimentos Controlados

- Teste com gen_text = ref_text (duplica√ß√£o)
- Teste com chunks de 95 bytes cada
- Comparar qualidade de √°udio resultante

### 3. Atualizar Documenta√ß√£o

Adicionar warning em `test.py`:
```python
# ‚ö†Ô∏è IMPORTANTE:
# F5-TTS foi treinado com duplica√ß√£o de texto.
# Para melhor qualidade, mantenha gen_text com tamanho
# similar ao ref_text (max ~135 caracteres).
```

### 4. Implementar Solu√ß√£o Definitiva

Criar nova fun√ß√£o `infer_like_trainer()`:
```python
def infer_like_trainer(model, ref_audio, ref_text, vocoder):
    """Gera √°udio usando EXATAMENTE a mesma l√≥gica do trainer"""
    infer_text = ref_text + " " + ref_text  # Duplica
    duration = ref_audio_len * 2  # Fixa
    # ... resto do c√≥digo
```

---

## 13. CONCLUS√ÉO

O problema **N√ÉO est√° no modelo**, **N√ÉO est√° no checkpoint**, e **N√ÉO est√° nos par√¢metros de infer√™ncia**.

O problema est√° na **incompatibilidade entre como o modelo foi treinado** (texto duplicado, dura√ß√£o fixa 2x) **vs como test.py est√° fazendo infer√™ncia** (texto concatenado longo, dura√ß√£o din√¢mica).

**Solu√ß√£o**: Adaptar `test.py` para usar a mesma estrutura de texto que o trainer usa, ou implementar chunking autom√°tico como a API oficial faz.

**Prioridade**: üî¥ CR√çTICA - Bloqueia valida√ß√£o de qualidade do modelo

**Esfor√ßo Estimado**: 2-4 horas para implementar e testar fix completo

---

## ANEXOS

### A. Par√¢metros de Treinamento Atuais

```yaml
# train/config/base_config.yaml
mel_spec:
  mel_spec_type: vocos
  target_sample_rate: 24000
  n_mel_channels: 100
  hop_length: 256
  win_length: 1024
  n_fft: 1024

training:
  epochs: 1000
  batch_size_per_gpu: 2
  batch_size_type: frame
  max_samples: 64
  learning_rate: 1e-5
  
checkpoints:
  save_per_updates: 200
  log_samples: true
  log_samples_per_updates: 200
```

### B. Comandos para Reproduzir Problema

```bash
# 1. Gerar sample durante treinamento (BOM)
python3 -m train.run_training --epochs 1000 --batch-size 2
# Aguardar save em update m√∫ltiplo de 200
# Verificar: train/output/ptbr_finetuned2/samples/update_XXXXX_gen.wav

# 2. Gerar via test.py (RUIM)
python3 -m train.test --checkpoint model_25400.pt
# Verificar: train/f5tts_test_TIMESTAMP.wav
```

### C. Refer√™ncias

1. **F5-TTS Paper**: [arXiv:2410.06885](https://arxiv.org/abs/2410.06885)
2. **Official Repo**: [github.com/SWivid/F5-TTS](https://github.com/SWivid/F5-TTS)
3. **Pretrained PT-BR**: [huggingface.co/firstpixel/F5-TTS-pt-br](https://huggingface.co/firstpixel/F5-TTS-pt-br)
4. **Fine-tuning Discussion**: [GitHub #57](https://github.com/SWivid/F5-TTS/discussions/57)
5. **Gradio Interface Issues**: [GitHub #143](https://github.com/SWivid/F5-TTS/discussions/143)

---

**Fim do Relat√≥rio**
