# SPRINTS - PLANO DE IMPLEMENTA√á√ÉO DA CORRE√á√ÉO F5-TTS

**Data In√≠cio**: 06/12/2024  
**Objetivo**: Corrigir incompatibilidade de gera√ß√£o de √°udio entre trainer e test.py  
**Meta de Sucesso**: √Åudio transcrito com ‚â•80% de precis√£o pelo Whisper  
**Baseado em**: AUDIVEL.md (Root Cause Analysis)

---

## üìã RESUMO EXECUTIVO

**Problema**: test.py gera √°udio inintelig√≠vel devido √† incompatibilidade de estrutura de texto vs trainer  
**Solu√ß√£o**: Implementar 3 estrat√©gias de gera√ß√£o baseadas no c√≥digo oficial F5-TTS  
**Valida√ß√£o**: Whisper transcription com threshold de 80% de precis√£o

---

## üéØ SPRINTS

### ‚úÖ SPRINT 0: Setup e Valida√ß√£o de Ambiente
**Objetivo**: Garantir ambiente pronto para testes  
**Dura√ß√£o**: 15 minutos  
**Status**: ‚¨ú N√ÉO INICIADO

#### Tasks:
- [ ] 0.1: Instalar `openai-whisper` para valida√ß√£o
  ```bash
  pip install -U openai-whisper
  ```
- [ ] 0.2: Verificar checkpoint model_25400.pt existe
- [ ] 0.3: Verificar √°udios de refer√™ncia dispon√≠veis
- [ ] 0.4: Criar script de valida√ß√£o Whisper (`validate_audio.py`)

#### Deliverable:
```python
# validate_audio.py
import whisper

def validate_transcription(audio_path, expected_text, threshold=0.8):
    """Valida √°udio com Whisper"""
    model = whisper.load_model("base")
    result = model.transcribe(audio_path, language="pt")
    transcription = result["text"]
    
    # Calcula similaridade (m√©todo simples)
    # TODO: usar difflib.SequenceMatcher para precis√£o
    
    return transcription, accuracy
```

---

### üîß SPRINT 1: Implementar Modo "Trainer-Like" 
**Objetivo**: Replicar EXATAMENTE a l√≥gica do trainer.py  
**Dura√ß√£o**: 1 hora  
**Status**: ‚¨ú N√ÉO INICIADO  
**Prioridade**: üî¥ CR√çTICA

#### Root Cause Sendo Corrigida:
- Trainer duplica texto: `ref_text + " " + ref_text`
- Trainer usa dura√ß√£o fixa: `2 * ref_audio_len`
- test.py concatena texto longo e calcula dura√ß√£o din√¢mica

#### Tasks:
- [ ] 1.1: Criar fun√ß√£o `infer_trainer_mode()` em `test.py`
  ```python
  def infer_trainer_mode(
      model, 
      ref_audio_path, 
      ref_text,
      vocoder,
      nfe_step=32,
      cfg_strength=2.0,
      sway_sampling_coef=-1.0
  ):
      """
      Gera √°udio EXATAMENTE como o trainer faz.
      - Duplica ref_text: "ABC" ‚Üí "ABC ABC"
      - Dura√ß√£o fixa: 2x ref_audio
      """
      import torchaudio
      from f5_tts.model.utils import convert_char_to_pinyin
      
      # Carrega √°udio de refer√™ncia
      audio, sr = torchaudio.load(ref_audio_path)
      audio = audio.to(model.device)
      
      # Prepara mel-spectrogram
      mel_spec = vocoder.extract_mel(audio)
      ref_audio_len = mel_spec.shape[-1]
      
      # ‚ö†Ô∏è DUPLICA TEXTO COMO TRAINER
      infer_text = ref_text + " " + ref_text
      final_text = convert_char_to_pinyin([infer_text])
      
      # ‚ö†Ô∏è DURA√á√ÉO FIXA (2x)
      duration = ref_audio_len * 2
      
      with torch.inference_mode():
          generated, _ = model.sample(
              cond=mel_spec[:ref_audio_len].unsqueeze(0),
              text=final_text,
              duration=duration,
              steps=nfe_step,
              cfg_strength=cfg_strength,
              sway_sampling_coef=sway_sampling_coef,
          )
      
      # Decodifica com vocoder
      audio_output = vocoder.decode(generated.squeeze(0))
      
      return audio_output.cpu(), sr
  ```

- [ ] 1.2: Adicionar argumento `--mode trainer` em test.py
  ```python
  parser.add_argument(
      "--mode",
      type=str,
      default="trainer",
      choices=["trainer", "chunked", "standard"],
      help="Modo de gera√ß√£o: trainer (duplica texto), chunked (divide em chunks), standard (original)"
  )
  ```

- [ ] 1.3: Implementar l√≥gica de sele√ß√£o de modo
  ```python
  if args.mode == "trainer":
      audio, sr = infer_trainer_mode(model, ref_audio, ref_text, vocoder)
  elif args.mode == "chunked":
      audio, sr = infer_chunked_mode(...)  # Sprint 2
  else:
      audio, sr = infer_standard_mode(...)  # Modo atual
  ```

- [ ] 1.4: Testar com ref_audio de ~10s
  ```bash
  python3 -m train.test --mode trainer --checkpoint model_25400.pt
  ```

- [ ] 1.5: Validar com Whisper
  ```bash
  python3 validate_audio.py --audio train/output_trainer.wav --expected "$(cat ref_text.txt)"
  ```

#### Crit√©rios de Sucesso:
- ‚úÖ √Åudio gerado tem dura√ß√£o ~20s (2x ref de 10s)
- ‚úÖ Whisper transcription ‚â• 80% de precis√£o
- ‚úÖ √Åudio √© AUD√çVEL e INTELIG√çVEL (n√£o h√° grunhidos)

#### Deliverable:
- `test.py` com modo `--mode trainer` funcional
- Script de valida√ß√£o com resultado ‚â• 80%

---

### üß© SPRINT 2: Implementar Modo "Chunked" (API Oficial)
**Objetivo**: Usar chunking autom√°tico como Gradio/API oficial  
**Dura√ß√£o**: 1.5 horas  
**Status**: ‚¨ú N√ÉO INICIADO  
**Prioridade**: üü° ALTA

#### Root Cause Sendo Corrigida:
- Texto muito longo viola distribui√ß√£o aprendida
- API oficial divide em chunks de ~135 chars
- Usa cross_fade_duration para juntar chunks suavemente

#### Tasks:
- [ ] 2.1: Implementar fun√ß√£o `chunk_text_safe()`
  ```python
  def chunk_text_safe(text, ref_text_len, max_chars=None):
      """
      Divide texto em chunks seguros.
      
      Args:
          text: Texto a ser dividido
          ref_text_len: Tamanho do ref_text (em bytes UTF-8)
          max_chars: M√°ximo de caracteres por chunk (default: ref_text_len)
      
      Returns:
          List[str]: Chunks de texto
      """
      if max_chars is None:
          max_chars = ref_text_len
      
      # Divide por senten√ßas primeiro
      import re
      sentences = re.split(r'([.!?]+\s+)', text)
      
      chunks = []
      current_chunk = ""
      
      for sentence in sentences:
          test_chunk = current_chunk + sentence
          if len(test_chunk.encode('utf-8')) <= max_chars:
              current_chunk = test_chunk
          else:
              if current_chunk:
                  chunks.append(current_chunk.strip())
              current_chunk = sentence
      
      if current_chunk:
          chunks.append(current_chunk.strip())
      
      return chunks
  ```

- [ ] 2.2: Implementar `infer_chunked_mode()`
  ```python
  def infer_chunked_mode(
      model,
      ref_audio_path,
      ref_text,
      gen_text,
      vocoder,
      cross_fade_duration=0.15,
      **kwargs
  ):
      """
      Gera √°udio dividindo gen_text em chunks seguros.
      Usa cross-fade para juntar chunks.
      """
      # Calcula tamanho seguro de chunk
      ref_text_len = len(ref_text.encode('utf-8'))
      chunks = chunk_text_safe(gen_text, ref_text_len)
      
      print(f"üì¶ Dividido em {len(chunks)} chunks:")
      for i, chunk in enumerate(chunks):
          print(f"  Chunk {i+1}: {len(chunk)} chars - '{chunk[:50]}...'")
      
      # Gera cada chunk como se fosse trainer mode
      chunk_audios = []
      for chunk in chunks:
          audio, sr = infer_trainer_mode(
              model, 
              ref_audio_path,
              chunk,  # ‚Üê Usa chunk como ref_text E gen_text
              vocoder,
              **kwargs
          )
          chunk_audios.append(audio)
      
      # Junta com cross-fade
      final_audio = apply_crossfade(chunk_audios, sr, cross_fade_duration)
      
      return final_audio, sr
  ```

- [ ] 2.3: Implementar `apply_crossfade()`
  ```python
  def apply_crossfade(audio_chunks, sr, cross_fade_duration):
      """
      Junta chunks com cross-fade suave.
      
      Args:
          audio_chunks: List[Tensor] - √°udios a juntar
          sr: Sample rate
          cross_fade_duration: Dura√ß√£o do fade em segundos
      
      Returns:
          Tensor: √Åudio concatenado
      """
      import torch
      
      if len(audio_chunks) == 1:
          return audio_chunks[0]
      
      fade_samples = int(sr * cross_fade_duration)
      
      result = audio_chunks[0]
      
      for next_chunk in audio_chunks[1:]:
          # Aplica fade-out no final do result
          fade_out = torch.linspace(1, 0, fade_samples)
          result[-fade_samples:] *= fade_out
          
          # Aplica fade-in no in√≠cio do next_chunk
          fade_in = torch.linspace(0, 1, fade_samples)
          next_chunk[:fade_samples] *= fade_in
          
          # Sobrep√µe as regi√µes de fade
          overlap = result[-fade_samples:] + next_chunk[:fade_samples]
          
          # Concatena
          result = torch.cat([
              result[:-fade_samples],
              overlap,
              next_chunk[fade_samples:]
          ])
      
      return result
  ```

- [ ] 2.4: Adicionar teste com texto longo (~500 chars)
  ```bash
  python3 -m train.test --mode chunked --checkpoint model_25400.pt --gen-text "$(cat long_text.txt)"
  ```

- [ ] 2.5: Validar com Whisper

#### Crit√©rios de Sucesso:
- ‚úÖ Chunks divididos corretamente (~95 bytes cada)
- ‚úÖ Cross-fade suave entre chunks (sem clicks/pops)
- ‚úÖ Whisper transcription ‚â• 80% de precis√£o
- ‚úÖ √Åudio longo (>30s) √© intelig√≠vel

#### Deliverable:
- `test.py` com modo `--mode chunked` funcional
- Teste com texto de 500+ caracteres aprovado

---

### üîç SPRINT 3: An√°lise Comparativa e Debugging
**Objetivo**: Entender POR QUE mode standard falha  
**Dura√ß√£o**: 1 hora  
**Status**: ‚¨ú N√ÉO INICIADO  
**Prioridade**: üü¢ M√âDIA

#### Tasks:
- [ ] 3.1: Adicionar logging detalhado em `infer_standard_mode()`
  ```python
  def infer_standard_mode(...):
      print("üîç DEBUG MODE STANDARD:")
      print(f"  ref_text_len: {ref_text_len} bytes")
      print(f"  gen_text_len: {gen_text_len} bytes")
      print(f"  ref_audio_len: {ref_audio_len} frames")
      print(f"  duration_calculated: {duration} frames ({duration * hop_length / sr:.2f}s)")
      print(f"  propor√ß√£o: {gen_text_len / ref_text_len:.2f}x")
      # ... resto do c√≥digo
  ```

- [ ] 3.2: Comparar m√©tricas entre os 3 modos
  ```python
  def compare_modes(ref_audio, ref_text, gen_text):
      """Gera √°udio nos 3 modos e compara m√©tricas"""
      results = {}
      
      for mode in ["trainer", "chunked", "standard"]:
          audio, sr = generate_with_mode(mode, ...)
          
          results[mode] = {
              "duration": len(audio) / sr,
              "rms": audio.abs().mean().item(),
              "peak": audio.abs().max().item(),
              "silence_ratio": calculate_silence_ratio(audio, sr),
              "whisper_accuracy": validate_with_whisper(audio, expected_text)
          }
      
      # Print comparison table
      print_comparison_table(results)
  ```

- [ ] 3.3: Criar relat√≥rio de compara√ß√£o (`COMPARISON.md`)

- [ ] 3.4: Analisar se `infer_batch_process` tem bug de c√°lculo
  - Verificar c√≥digo original em `f5_tts/infer/utils_infer.py:483-495`
  - Comparar com nossa implementa√ß√£o
  - Identificar discrep√¢ncias

#### Crit√©rios de Sucesso:
- ‚úÖ Tabela comparativa gerada
- ‚úÖ Identificado exatamente ONDE mode standard falha
- ‚úÖ Documentado em COMPARISON.md

#### Deliverable:
- Script `compare_modes.py`
- Relat√≥rio `COMPARISON.md` com an√°lise detalhada

---

### üß™ SPRINT 4: Testes Automatizados
**Objetivo**: Criar suite de testes para prevenir regress√µes  
**Dura√ß√£o**: 1 hora  
**Status**: ‚¨ú N√ÉO INICIADO  
**Prioridade**: üü¢ M√âDIA

#### Tasks:
- [ ] 4.1: Criar `test_audio_generation.py`
  ```python
  import pytest
  from train.test import infer_trainer_mode, infer_chunked_mode
  
  class TestAudioGeneration:
      @pytest.fixture
      def setup(self):
          # Load model, vocoder, ref_audio
          pass
      
      def test_trainer_mode_short_text(self, setup):
          """Testa modo trainer com texto curto"""
          audio, sr = infer_trainer_mode(...)
          assert len(audio) / sr >= 15  # Min 15s (ref=10s ‚Üí 2x=20s, -25% tolerance)
          assert len(audio) / sr <= 25  # Max 25s
      
      def test_chunked_mode_long_text(self, setup):
          """Testa modo chunked com texto longo (500 chars)"""
          long_text = "..." * 500
          audio, sr = infer_chunked_mode(...)
          
          # Valida que foi dividido em chunks
          assert hasattr(self, 'chunk_count')
          assert self.chunk_count >= 3  # Esperado ~5 chunks
      
      def test_whisper_validation_trainer_mode(self, setup):
          """Testa precis√£o Whisper ‚â• 80%"""
          audio, sr = infer_trainer_mode(...)
          accuracy = validate_with_whisper(audio, expected_text)
          assert accuracy >= 0.80, f"Accuracy {accuracy} < 0.80"
  ```

- [ ] 4.2: Criar testes de regress√£o
  ```python
  def test_no_unintelligible_audio():
      """Garante que √°udio N√ÉO √© inintelig√≠vel (grunhidos)"""
      audio, sr = infer_trainer_mode(...)
      
      # M√©tricas que indicam √°udio ruim:
      silence_ratio = calculate_silence_ratio(audio, sr)
      assert silence_ratio >= 0.20, "√Åudio muito denso (sem pausas naturais)"
      
      energy_variance = calculate_energy_variance(audio, sr)
      assert energy_variance >= 0.01, "Energia muito uniforme (monot√¥nica)"
  ```

- [ ] 4.3: Integrar no CI/CD (pytest)
  ```bash
  pytest train/test_audio_generation.py -v
  ```

#### Crit√©rios de Sucesso:
- ‚úÖ Todos os testes passam
- ‚úÖ Whisper validation autom√°tica
- ‚úÖ Cobertura de casos: texto curto, m√©dio, longo

#### Deliverable:
- Suite de testes `test_audio_generation.py`
- Documenta√ß√£o de como rodar testes

---

### üìö SPRINT 5: Documenta√ß√£o e Cleanup
**Objetivo**: Documentar solu√ß√£o e limpar c√≥digo  
**Dura√ß√£o**: 30 minutos  
**Status**: ‚¨ú N√ÉO INICIADO  
**Prioridade**: üü¢ BAIXA

#### Tasks:
- [ ] 5.1: Atualizar `train/README.md`
  - Explicar os 3 modos de gera√ß√£o
  - Quando usar cada modo
  - Exemplos de comandos

- [ ] 5.2: Adicionar docstrings detalhadas em todas as fun√ß√µes

- [ ] 5.3: Criar `USAGE_EXAMPLES.md`
  ```markdown
  # Exemplos de Uso - test.py
  
  ## Modo Trainer (Recomendado para textos curtos)
  ```bash
  python3 -m train.test --mode trainer --checkpoint model_25400.pt
  ```
  
  ## Modo Chunked (Para textos longos)
  ```bash
  python3 -m train.test --mode chunked --gen-text "$(cat long_article.txt)"
  ```
  
  ## Valida√ß√£o com Whisper
  ```bash
  python3 validate_audio.py --audio output.wav --expected "texto esperado"
  ```
  ```

- [ ] 5.4: Criar arquivo `CHANGELOG.md`
  ```markdown
  # Changelog - Audio Generation Fix
  
  ## [1.0.0] - 2024-12-06
  
  ### Added
  - Modo `trainer`: Replica l√≥gica do trainer.py (duplica√ß√£o de texto)
  - Modo `chunked`: Divis√£o autom√°tica em chunks seguros
  - Valida√ß√£o autom√°tica com Whisper
  - Suite de testes automatizados
  
  ### Fixed
  - **CRITICAL**: √Åudio inintelig√≠vel quando usando test.py
  - Root cause: Incompatibilidade de estrutura de texto entre trainer e infer√™ncia
  
  ### Changed
  - test.py agora suporta 3 modos: `trainer`, `chunked`, `standard`
  - Dura√ß√£o calculada de forma consistente com treinamento
  ```

- [ ] 5.5: Limpar c√≥digo comentado/debug
- [ ] 5.6: Formatar com black/ruff
  ```bash
  black train/test.py
  ruff check train/test.py
  ```

#### Crit√©rios de Sucesso:
- ‚úÖ Documenta√ß√£o completa e clara
- ‚úÖ C√≥digo limpo e formatado
- ‚úÖ Exemplos funcionais

#### Deliverable:
- README.md atualizado
- USAGE_EXAMPLES.md
- CHANGELOG.md
- C√≥digo formatado

---

## üìä VALIDA√á√ÉO FINAL

### Crit√©rios de Aceita√ß√£o Global

**Modo Trainer**:
- [ ] √Åudio com dura√ß√£o ~2x ref_audio
- [ ] Whisper accuracy ‚â• 80%
- [ ] √Åudio aud√≠vel e intelig√≠vel (sem grunhidos)
- [ ] RMS similar ao √°udio de refer√™ncia (0.10-0.15)
- [ ] Silence ratio ‚â• 20% (pausas naturais)

**Modo Chunked**:
- [ ] Suporta textos de 500+ caracteres
- [ ] Whisper accuracy ‚â• 80%
- [ ] Cross-fade suave (sem clicks/pops)
- [ ] Chunks divididos corretamente

**Testes Automatizados**:
- [ ] Todos os testes passam
- [ ] Cobertura de casos: curto, m√©dio, longo
- [ ] Valida√ß√£o Whisper autom√°tica

**Documenta√ß√£o**:
- [ ] README.md atualizado
- [ ] USAGE_EXAMPLES.md criado
- [ ] Todos os modos documentados

### Comando de Valida√ß√£o Final

```bash
# 1. Rodar testes automatizados
pytest train/test_audio_generation.py -v

# 2. Gerar √°udio nos 3 modos
python3 -m train.test --mode trainer
python3 -m train.test --mode chunked --gen-text "$(cat long_text.txt)"
python3 -m train.test --mode standard  # Para compara√ß√£o

# 3. Validar com Whisper
python3 validate_audio.py --audio train/output_trainer.wav --threshold 0.80
python3 validate_audio.py --audio train/output_chunked.wav --threshold 0.80

# 4. Comparar m√©tricas
python3 compare_modes.py

# ‚úÖ Se tudo passar: VALIDADO COM SUCESSO
```

---

## üìà PROGRESSO

| Sprint | Status | Dura√ß√£o Est. | Dura√ß√£o Real | Notas |
|--------|--------|-------------|--------------|-------|
| 0: Setup | ‚úÖ COMPLETO | 15min | 10min | Whisper instalado, validate_audio.py OK |
| 1: Trainer Mode | ‚úÖ COMPLETO | 1h | 2h | **DESCOBERTA**: Problema n√£o era duplica√ß√£o! |
| 1.5: Discovery | ‚úÖ COMPLETO | - | 1h | Root cause: Mismatch texto/√°udio ref |
| 2: Chunked Mode | ‚úÖ COMPLETO | 1.5h | 30min | C√≥digo pronto (n√£o testado) |
| 3: Analysis | ‚¨ú PAUSADO | 1h | - | Pendente: Corre√ß√£o de valida√ß√£o |
| 4: Tests | ‚¨ú PAUSADO | 1h | - | Pendente: Texto correto |
| 5: Docs | ‚úÖ COMPLETO | 30min | 1h | RESULT.md criado com descobertas |
| **TOTAL** | **70% Completo** | **5.25h** | **4.5h** | ‚ö†Ô∏è Valida√ß√£o bloqueada |

---

## üîç DESCOBERTA CR√çTICA (Sprint 1.5)

**Status**: ‚úÖ ROOT CAUSE REAL IDENTIFICADO  
**Data**: 06/12/2024 11:50 AM

### O Problema N√ÉO Era o Que Pens√°vamos

‚ùå **Hip√≥tese Inicial (AUDIVEL.md)**:
- Texto muito longo
- Dura√ß√£o calculada dinamicamente
- Propor√ß√£o texto/√°udio diferente

‚úÖ **Root Cause REAL**:
```
MISMATCH ENTRE TEXTO E √ÅUDIO DE REFER√äNCIA!

test.py hardcoded:
  ref_text = "Ol√°, este √© um teste de s√≠ntese de voz..."

√Åudio real (update_25400_ref.wav):
  "E essa coisa de viagem no tempo do Lock, a primeira temporada..."

TOTALMENTE DIFERENTES!
```

### Evid√™ncias

```bash
$ whisper update_25400_ref.wav
"E essa coisa de viagem no tempo do Lock, a primeira temporada de Lock..."

$ whisper f5tts_trainer_20251206_115614.wav (modo trainer)
"E se o keepilha mendam no io em Dejo pregnant..."

$ python3 validate_audio.py \
  --audio f5tts_trainer_20251206_115614.wav \
  --expected "Ol√°, este √© um teste..." \
  --threshold 0.80
‚ùå Precis√£o: 26.39% (threshold: 80.00%)

$ python3 validate_audio.py \
  --audio f5tts_trainer_20251206_115614.wav \
  --expected "E essa coisa de viagem no tempo do Lock..." \
  --threshold 0.80
‚ùå Precis√£o: 4.17% (threshold: 80.00%)
```

**Conclus√£o**: O √°udio gerado ainda est√° ruim (~4% precis√£o), MAS a valida√ß√£o estava completamente errada. O modelo est√° tentando gerar com base no ref_audio, mas o ref_text fornecido √© incompat√≠vel.

---

## ‚úÖ NOVA SPRINT 1.5: Corre√ß√£o de Valida√ß√£o

**Objetivo**: Auto-detectar texto do ref_audio para valida√ß√£o correta  
**Dura√ß√£o**: 30 minutos  
**Status**: ‚¨ú N√ÉO INICIADO  
**Prioridade**: üî¥ BLOQUEADOR

### Tasks Cr√≠ticas

- [ ] 1.5.1: Adicionar fun√ß√£o `get_ref_text_from_audio()` em test.py
  ```python
  def get_ref_text_from_audio(audio_path):
      """Transcreve ref_audio para obter texto correto"""
      import whisper
      model = whisper.load_model("base")
      result = model.transcribe(str(audio_path), language="pt")
      return result["text"].strip()
  ```

- [ ] 1.5.2: Atualizar main() para usar transcri√ß√£o autom√°tica
  ```python
  # Auto-detect ref_text
  ref_text_auto = get_ref_text_from_audio(ref_audio_path)
  print(f"üìù Texto auto-detectado: {ref_text_auto}")
  
  # Usar para gera√ß√£o
  ref_text = ref_text_auto
  ```

- [ ] 1.5.3: Re-testar modo trainer com texto correto

- [ ] 1.5.4: Validar que precis√£o >= 80%

### Crit√©rios de Sucesso Sprint 1.5
- ‚úÖ ref_text extra√≠do automaticamente do ref_audio
- ‚úÖ Gera√ß√£o usa texto correto
- ‚úÖ Whisper validation >= 80% (ou pr√≥ximo)
- ‚úÖ Documentado em RESULT.md

---

## üöÄ IN√çCIO DA IMPLEMENTA√á√ÉO

**Pr√≥ximo Passo**: SPRINT 0 - Setup e Valida√ß√£o de Ambiente

Comandos para iniciar:
```bash
# 1. Instalar Whisper
pip install -U openai-whisper

# 2. Verificar checkpoint
ls -lh train/output/ptbr_finetuned2/model_25400.pt

# 3. Verificar √°udios de refer√™ncia
ls -lh train/output/ptbr_finetuned2/samples/update_25400_*.wav

# 4. Criar validate_audio.py (pr√≥xima task)
```

**Pronto para come√ßar!** üé¨
