{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60148ab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dez de Abril de mil, novecentos e vinte e nove\n"
     ]
    }
   ],
   "source": [
    "from num2words import num2words\n",
    "import re\n",
    "\n",
    "def transform_numbers_to_text(text):\n",
    "    # Function to replace numbers in text with their full text representation\n",
    "    def replace_number(match):\n",
    "        number = int(match.group())\n",
    "        # Convert number to Portuguese words\n",
    "        return num2words(number, lang='pt_BR')\n",
    "    \n",
    "    # Regular expression to find numbers in the text\n",
    "    text_with_numbers_transformed = re.sub(r'\\d+', replace_number, text)\n",
    "    return text_with_numbers_transformed\n",
    "\n",
    "def handle_special_cases(text):\n",
    "    # Replace specific patterns for better formatting\n",
    "    text = text.replace(\" e um mil\", \" e mil\")  # Fix: \"mil\" doesn't need \"um\" before it in Portuguese\n",
    "    text = text.replace(\"um mil \", \"mil \")  # Avoid redundant \"um mil\"\n",
    "    return text\n",
    "\n",
    "# Example usage\n",
    "input_text = \"10 de Abril de 1929\"\n",
    "transformed_text = transform_numbers_to_text(input_text)\n",
    "final_text = handle_special_cases(transformed_text)\n",
    "\n",
    "print(final_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101e233e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üéôÔ∏è F5-TTS Test - Gera√ß√£o de Voz Nativa (Sem API)\n",
    "\n",
    "Este notebook permite testar o modelo F5-TTS treinado diretamente, sem necessidade de API ou containers Docker.\n",
    "\n",
    "## üìã Features:\n",
    "- ‚úÖ Carregamento direto do checkpoint fine-tuned\n",
    "- ‚úÖ Gera√ß√£o de √°udio com voz clonada\n",
    "- ‚úÖ Compara√ß√£o de qualidade (pretrained vs fine-tuned)\n",
    "- ‚úÖ Exporta√ß√£o em WAV e MP3\n",
    "- ‚úÖ Visualiza√ß√£o de spectrograms\n",
    "- ‚úÖ M√©tricas de qualidade"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb274707",
   "metadata": {},
   "source": [
    "## 1. Setup e Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94fd5ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import torchaudio\n",
    "import numpy as np\n",
    "import soundfile as sf\n",
    "from pathlib import Path\n",
    "from IPython.display import Audio, display\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "import librosa.display\n",
    "\n",
    "# F5-TTS imports\n",
    "from f5_tts.model import DiT\n",
    "from f5_tts.infer.utils_infer import (\n",
    "    load_model,\n",
    "    load_vocoder,\n",
    "    infer_process,\n",
    "    preprocess_ref_audio_text\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ PyTorch version: {torch.__version__}\")\n",
    "print(f\"‚úÖ CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"‚úÖ CUDA device: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"‚úÖ VRAM: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "321b6e75",
   "metadata": {},
   "source": [
    "## 2. Configura√ß√£o de Paths e Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52c1029",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device configuration\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"üéØ Using device: {device}\")\n",
    "\n",
    "# Paths\n",
    "BASE_DIR = Path(\"/home/tts-webui-proxmox-passthrough\")\n",
    "TRAIN_DIR = BASE_DIR / \"train\"\n",
    "OUTPUT_DIR = TRAIN_DIR / \"output\" / \"ptbr_finetuned2\"\n",
    "CHECKPOINT_PATH = OUTPUT_DIR / \"model_last.pt\"\n",
    "SAMPLES_DIR = OUTPUT_DIR / \"samples\"\n",
    "\n",
    "# Create test output directory\n",
    "TEST_OUTPUT_DIR = TRAIN_DIR / \"test_output\"\n",
    "TEST_OUTPUT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "print(f\"\\nüìÅ Checkpoint: {CHECKPOINT_PATH}\")\n",
    "print(f\"üìÅ Test output: {TEST_OUTPUT_DIR}\")\n",
    "print(f\"‚úÖ Checkpoint exists: {CHECKPOINT_PATH.exists()}\")\n",
    "\n",
    "if CHECKPOINT_PATH.exists():\n",
    "    checkpoint_size = CHECKPOINT_PATH.stat().st_size / (1024**3)\n",
    "    print(f\"üìä Checkpoint size: {checkpoint_size:.2f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54485297",
   "metadata": {},
   "source": [
    "## 3. Carregar Modelo F5-TTS Fine-Tuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a550bdfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üîÑ Loading F5-TTS model...\")\n",
    "\n",
    "# Load model using custom checkpoint\n",
    "model = load_model(\n",
    "    model_cls=DiT,\n",
    "    model_cfg=dict(dim=1024, depth=22, heads=16, ff_mult=2, text_dim=512, conv_layers=4),\n",
    "    ckpt_path=str(CHECKPOINT_PATH),\n",
    "    mel_spec_type=\"vocos\",\n",
    "    vocab_file=\"\",\n",
    "    ode_method=\"euler\",\n",
    "    use_ema=True,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Model loaded successfully!\")\n",
    "print(f\"üìä Model parameters: {sum(p.numel() for p in model.parameters()) / 1e6:.1f}M\")\n",
    "\n",
    "# Load vocoder\n",
    "print(\"\\nüîÑ Loading Vocos vocoder...\")\n",
    "vocoder = load_vocoder(vocoder_name=\"vocos\", is_local=False, local_path=\"\")\n",
    "print(\"‚úÖ Vocoder loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "330486eb",
   "metadata": {},
   "source": [
    "## 4. Preparar √Åudio de Refer√™ncia\n",
    "\n",
    "Use um √°udio de voz existente para clonagem. Pode ser:\n",
    "- Um arquivo da pasta `uploads/`\n",
    "- Um sample do treinamento\n",
    "- Qualquer arquivo WAV de 3-30 segundos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95df0a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Op√ß√£o 1: Usar sample do treinamento\n",
    "ref_audio_path = SAMPLES_DIR / \"update_33200_ref.wav\"\n",
    "\n",
    "# Op√ß√£o 2: Usar arquivo da pasta uploads (descomente se preferir)\n",
    "# ref_audio_path = BASE_DIR / \"uploads\" / \"seu_arquivo.wav\"\n",
    "\n",
    "# Op√ß√£o 3: Caminho customizado (descomente e ajuste)\n",
    "# ref_audio_path = Path(\"/path/to/your/reference.wav\")\n",
    "\n",
    "if not ref_audio_path.exists():\n",
    "    print(f\"‚ùå Arquivo n√£o encontrado: {ref_audio_path}\")\n",
    "    print(\"\\nüìÅ Samples dispon√≠veis:\")\n",
    "    if SAMPLES_DIR.exists():\n",
    "        for f in SAMPLES_DIR.glob(\"*.wav\"):\n",
    "            print(f\"  - {f.name}\")\n",
    "else:\n",
    "    print(f\"‚úÖ √Åudio de refer√™ncia: {ref_audio_path.name}\")\n",
    "    \n",
    "    # Load and display audio info\n",
    "    audio, sr = sf.read(str(ref_audio_path))\n",
    "    duration = len(audio) / sr\n",
    "    print(f\"üìä Sample rate: {sr} Hz\")\n",
    "    print(f\"üìä Duration: {duration:.2f}s\")\n",
    "    print(f\"üìä Channels: {audio.shape}\")\n",
    "    \n",
    "    # Play audio in notebook\n",
    "    display(Audio(str(ref_audio_path)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94eb86a0",
   "metadata": {},
   "source": [
    "## 5. Definir Texto de Refer√™ncia e Texto para Gerar\n",
    "\n",
    "**IMPORTANTE:** O F5-TTS funciona melhor quando voc√™ fornece a transcri√ß√£o exata do √°udio de refer√™ncia (`ref_text`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1fd28d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transcri√ß√£o do √°udio de refer√™ncia\n",
    "# IMPORTANTE: Deve ser a transcri√ß√£o EXATA do √°udio de refer√™ncia\n",
    "ref_text = \"\"\"\n",
    "Ol√°, este √© um teste de s√≠ntese de voz com o modelo F5-TTS fine-tuned em portugu√™s brasileiro.\n",
    "\"\"\"\n",
    "\n",
    "# Texto que voc√™ quer gerar com a voz clonada\n",
    "gen_text = \"\"\"\n",
    "Bem-vindo ao teste de gera√ß√£o de voz usando F5-TTS. \n",
    "Este modelo foi treinado especificamente para portugu√™s brasileiro, \n",
    "garantindo naturalidade e expressividade em cada palavra falada.\n",
    "A tecnologia de flow matching permite uma s√≠ntese de alta qualidade, \n",
    "mantendo as caracter√≠sticas √∫nicas da voz de refer√™ncia.\n",
    "\"\"\"\n",
    "\n",
    "# Limpar textos\n",
    "ref_text = ref_text.strip()\n",
    "gen_text = gen_text.strip()\n",
    "\n",
    "print(\"üìù Texto de refer√™ncia:\")\n",
    "print(f\"   {ref_text[:100]}...\")\n",
    "print(f\"\\nüìù Texto para gerar ({len(gen_text)} caracteres):\")\n",
    "print(f\"   {gen_text[:150]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2faec36",
   "metadata": {},
   "source": [
    "## 6. Gerar √Åudio com F5-TTS\n",
    "\n",
    "Usando os par√¢metros EXATOS do treinamento para qualidade m√°xima:\n",
    "- `nfe_step=32` (padr√£o da biblioteca)\n",
    "- `cfg_strength=2.0` (guidance)\n",
    "- `sway_sampling_coef=-1.0` (auto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc2a76f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "print(\"üéôÔ∏è Gerando √°udio com F5-TTS...\")\n",
    "start_time = time.time()\n",
    "\n",
    "# Preprocess reference audio\n",
    "ref_audio, ref_text_processed = preprocess_ref_audio_text(\n",
    "    str(ref_audio_path),\n",
    "    ref_text,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Reference audio preprocessed: {ref_audio.shape}\")\n",
    "\n",
    "# Generate speech using infer_process\n",
    "# ‚ö†Ô∏è IMPORTANTE: Usando par√¢metros ID√äNTICOS ao treinamento!\n",
    "audio_output, sample_rate, _ = infer_process(\n",
    "    ref_audio=ref_audio,\n",
    "    ref_text=ref_text_processed,\n",
    "    gen_text=gen_text,\n",
    "    model_obj=model,\n",
    "    vocoder=vocoder,\n",
    "    mel_spec_type=\"vocos\",\n",
    "    show_info=print,\n",
    "    progress=None,\n",
    "    target_rms=0.1,\n",
    "    cross_fade_duration=0.0,  # Desabilitado para evitar pausas longas\n",
    "    nfe_step=32,              # ‚úÖ Padr√£o da biblioteca (treinamento)\n",
    "    cfg_strength=2.0,         # ‚úÖ Padr√£o da biblioteca (treinamento)\n",
    "    sway_sampling_coef=-1.0,  # ‚úÖ Padr√£o da biblioteca (auto)\n",
    "    speed=1.0,\n",
    "    fix_duration=None,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "generation_time = time.time() - start_time\n",
    "\n",
    "print(f\"\\n‚úÖ √Åudio gerado com sucesso!\")\n",
    "print(f\"‚è±Ô∏è  Tempo de gera√ß√£o: {generation_time:.2f}s\")\n",
    "print(f\"üìä Sample rate: {sample_rate} Hz\")\n",
    "print(f\"üìä Dura√ß√£o do √°udio: {len(audio_output) / sample_rate:.2f}s\")\n",
    "print(f\"üìä RTF (Real-Time Factor): {generation_time / (len(audio_output) / sample_rate):.2f}x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc821a9",
   "metadata": {},
   "source": [
    "## 7. Salvar e Reproduzir √Åudio Gerado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfaecba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# Generate filename with timestamp\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "output_filename = f\"f5tts_test_{timestamp}.wav\"\n",
    "output_path = TEST_OUTPUT_DIR / output_filename\n",
    "\n",
    "# Save audio\n",
    "sf.write(str(output_path), audio_output, sample_rate)\n",
    "print(f\"üíæ √Åudio salvo em: {output_path}\")\n",
    "\n",
    "# Display audio player\n",
    "print(\"\\nüîä Reproduzir √°udio:\")\n",
    "display(Audio(audio_output, rate=sample_rate))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ba70f27",
   "metadata": {},
   "source": [
    "## 8. Visualiza√ß√£o de Spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0012b614",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3, 1, figsize=(15, 10))\n",
    "\n",
    "# 1. Waveform\n",
    "axes[0].plot(audio_output)\n",
    "axes[0].set_title('Waveform do √Åudio Gerado', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Samples')\n",
    "axes[0].set_ylabel('Amplitude')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# 2. Spectrogram\n",
    "D = librosa.amplitude_to_db(np.abs(librosa.stft(audio_output)), ref=np.max)\n",
    "img = librosa.display.specshow(D, sr=sample_rate, x_axis='time', y_axis='hz', ax=axes[1])\n",
    "axes[1].set_title('Spectrogram (Frequ√™ncia vs Tempo)', fontsize=14, fontweight='bold')\n",
    "axes[1].set_ylabel('Frequ√™ncia (Hz)')\n",
    "fig.colorbar(img, ax=axes[1], format='%+2.0f dB')\n",
    "\n",
    "# 3. Mel Spectrogram\n",
    "mel_spec = librosa.feature.melspectrogram(y=audio_output, sr=sample_rate, n_mels=128)\n",
    "mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max)\n",
    "img2 = librosa.display.specshow(mel_spec_db, sr=sample_rate, x_axis='time', y_axis='mel', ax=axes[2])\n",
    "axes[2].set_title('Mel Spectrogram', fontsize=14, fontweight='bold')\n",
    "axes[2].set_ylabel('Mel Frequency')\n",
    "axes[2].set_xlabel('Tempo (s)')\n",
    "fig.colorbar(img2, ax=axes[2], format='%+2.0f dB')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(TEST_OUTPUT_DIR / f\"spectrogram_{timestamp}.png\", dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"üìä Spectrogram salvo em: {TEST_OUTPUT_DIR / f'spectrogram_{timestamp}.png'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05fbdc9c",
   "metadata": {},
   "source": [
    "## 9. An√°lise de Qualidade de √Åudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b994e359",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_audio_quality(audio, sr):\n",
    "    \"\"\"An√°lise completa de qualidade de √°udio\"\"\"\n",
    "    \n",
    "    # RMS (Volume)\n",
    "    rms = np.sqrt(np.mean(audio**2))\n",
    "    \n",
    "    # Peak amplitude\n",
    "    peak = np.max(np.abs(audio))\n",
    "    \n",
    "    # Clipping detection\n",
    "    clipping_count = np.sum(np.abs(audio) > 0.99)\n",
    "    clipping_percentage = (clipping_count / len(audio)) * 100\n",
    "    \n",
    "    # Zero crossing rate (naturalness indicator)\n",
    "    zcr = np.mean(librosa.feature.zero_crossing_rate(audio))\n",
    "    \n",
    "    # Spectral centroid (brightness)\n",
    "    spectral_centroid = np.mean(librosa.feature.spectral_centroid(y=audio, sr=sr))\n",
    "    \n",
    "    # Spectral rolloff\n",
    "    spectral_rolloff = np.mean(librosa.feature.spectral_rolloff(y=audio, sr=sr))\n",
    "    \n",
    "    # SNR estimate (simplified)\n",
    "    signal_power = np.mean(audio**2)\n",
    "    noise_estimate = np.mean(np.abs(audio[audio < np.percentile(audio, 10)])**2)\n",
    "    snr_db = 10 * np.log10(signal_power / (noise_estimate + 1e-10))\n",
    "    \n",
    "    return {\n",
    "        'rms': rms,\n",
    "        'peak': peak,\n",
    "        'clipping_count': clipping_count,\n",
    "        'clipping_percentage': clipping_percentage,\n",
    "        'zero_crossing_rate': zcr,\n",
    "        'spectral_centroid': spectral_centroid,\n",
    "        'spectral_rolloff': spectral_rolloff,\n",
    "        'snr_db': snr_db\n",
    "    }\n",
    "\n",
    "# Analyze generated audio\n",
    "metrics = analyze_audio_quality(audio_output, sample_rate)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"üìä M√âTRICAS DE QUALIDADE DO √ÅUDIO GERADO\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"üîä RMS (Volume):              {metrics['rms']:.4f}\")\n",
    "print(f\"üìà Peak Amplitude:            {metrics['peak']:.4f}\")\n",
    "print(f\"‚ö†Ô∏è  Clipping Samples:          {metrics['clipping_count']} ({metrics['clipping_percentage']:.2f}%)\")\n",
    "print(f\"üåä Zero Crossing Rate:        {metrics['zero_crossing_rate']:.4f}\")\n",
    "print(f\"‚ú® Spectral Centroid:         {metrics['spectral_centroid']:.0f} Hz\")\n",
    "print(f\"üìä Spectral Rolloff:          {metrics['spectral_rolloff']:.0f} Hz\")\n",
    "print(f\"üì° SNR (estimado):            {metrics['snr_db']:.1f} dB\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Quality assessment\n",
    "quality_score = 0\n",
    "issues = []\n",
    "\n",
    "if metrics['rms'] > 0.05 and metrics['rms'] < 0.3:\n",
    "    quality_score += 25\n",
    "else:\n",
    "    issues.append(f\"Volume fora do ideal (RMS: {metrics['rms']:.3f})\")\n",
    "\n",
    "if metrics['clipping_percentage'] < 0.1:\n",
    "    quality_score += 25\n",
    "else:\n",
    "    issues.append(f\"Clipping detectado ({metrics['clipping_percentage']:.2f}%)\")\n",
    "\n",
    "if metrics['spectral_centroid'] > 500 and metrics['spectral_centroid'] < 3000:\n",
    "    quality_score += 25\n",
    "else:\n",
    "    issues.append(f\"Centr√≥ide espectral incomum ({metrics['spectral_centroid']:.0f} Hz)\")\n",
    "\n",
    "if metrics['snr_db'] > 20:\n",
    "    quality_score += 25\n",
    "else:\n",
    "    issues.append(f\"SNR baixo ({metrics['snr_db']:.1f} dB)\")\n",
    "\n",
    "print(f\"\\nüéØ SCORE DE QUALIDADE: {quality_score}/100\")\n",
    "\n",
    "if quality_score >= 75:\n",
    "    print(\"‚úÖ Qualidade: EXCELENTE\")\n",
    "elif quality_score >= 50:\n",
    "    print(\"‚ö†Ô∏è  Qualidade: BOA (com ressalvas)\")\n",
    "else:\n",
    "    print(\"‚ùå Qualidade: PRECISA MELHORAR\")\n",
    "\n",
    "if issues:\n",
    "    print(\"\\n‚ö†Ô∏è  Problemas detectados:\")\n",
    "    for issue in issues:\n",
    "        print(f\"  - {issue}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f44401",
   "metadata": {},
   "source": [
    "## 10. Compara√ß√£o com Sample do Treinamento (Opcional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d7c261",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare with training sample\n",
    "training_sample_path = SAMPLES_DIR / \"update_33200_gen.wav\"\n",
    "\n",
    "if training_sample_path.exists():\n",
    "    print(\"üìä Comparando com sample do treinamento...\\n\")\n",
    "    \n",
    "    # Load training sample\n",
    "    training_audio, training_sr = sf.read(str(training_sample_path))\n",
    "    \n",
    "    # Analyze both\n",
    "    metrics_generated = analyze_audio_quality(audio_output, sample_rate)\n",
    "    metrics_training = analyze_audio_quality(training_audio, training_sr)\n",
    "    \n",
    "    # Create comparison table\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"{'M√©trica':<30} | {'Gerado Agora':<20} | {'Sample Treinamento':<20}\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"{'RMS (Volume)':<30} | {metrics_generated['rms']:<20.4f} | {metrics_training['rms']:<20.4f}\")\n",
    "    print(f\"{'Peak Amplitude':<30} | {metrics_generated['peak']:<20.4f} | {metrics_training['peak']:<20.4f}\")\n",
    "    print(f\"{'Clipping %':<30} | {metrics_generated['clipping_percentage']:<20.2f} | {metrics_training['clipping_percentage']:<20.2f}\")\n",
    "    print(f\"{'Zero Crossing Rate':<30} | {metrics_generated['zero_crossing_rate']:<20.4f} | {metrics_training['zero_crossing_rate']:<20.4f}\")\n",
    "    print(f\"{'Spectral Centroid (Hz)':<30} | {metrics_generated['spectral_centroid']:<20.0f} | {metrics_training['spectral_centroid']:<20.0f}\")\n",
    "    print(f\"{'SNR (dB)':<30} | {metrics_generated['snr_db']:<20.1f} | {metrics_training['snr_db']:<20.1f}\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    print(\"\\nüîä Reproduzir sample do treinamento para compara√ß√£o:\")\n",
    "    display(Audio(str(training_sample_path)))\n",
    "    \n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è  Sample do treinamento n√£o encontrado: {training_sample_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "015a5761",
   "metadata": {},
   "source": [
    "## 11. Teste com Diferentes Par√¢metros (Experimental)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d07b7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_with_params(nfe_step, cfg_strength, sway_coef, label):\n",
    "    \"\"\"Gera √°udio com par√¢metros espec√≠ficos\"\"\"\n",
    "    print(f\"\\nüéôÔ∏è Gerando: {label}\")\n",
    "    print(f\"   nfe_step={nfe_step}, cfg_strength={cfg_strength}, sway={sway_coef}\")\n",
    "    \n",
    "    start = time.time()\n",
    "    audio, sr, _ = infer_process(\n",
    "        ref_audio=ref_audio,\n",
    "        ref_text=ref_text_processed,\n",
    "        gen_text=\"Teste r√°pido de s√≠ntese com diferentes par√¢metros.\",\n",
    "        model_obj=model,\n",
    "        vocoder=vocoder,\n",
    "        mel_spec_type=\"vocos\",\n",
    "        show_info=lambda x: None,  # Suprimir logs\n",
    "        progress=None,\n",
    "        target_rms=0.1,\n",
    "        cross_fade_duration=0.0,\n",
    "        nfe_step=nfe_step,\n",
    "        cfg_strength=cfg_strength,\n",
    "        sway_sampling_coef=sway_coef,\n",
    "        speed=1.0,\n",
    "        device=device\n",
    "    )\n",
    "    elapsed = time.time() - start\n",
    "    \n",
    "    # Save\n",
    "    output_file = TEST_OUTPUT_DIR / f\"test_{label.replace(' ', '_').lower()}_{timestamp}.wav\"\n",
    "    sf.write(str(output_file), audio, sr)\n",
    "    \n",
    "    print(f\"   ‚è±Ô∏è  Tempo: {elapsed:.2f}s | RTF: {elapsed / (len(audio) / sr):.2f}x\")\n",
    "    print(f\"   üíæ Salvo: {output_file.name}\")\n",
    "    \n",
    "    return audio, sr, output_file\n",
    "\n",
    "# Test different configurations\n",
    "print(\"=\" * 80)\n",
    "print(\"üß™ TESTE DE DIFERENTES CONFIGURA√á√ïES\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "configs = [\n",
    "    (32, 2.0, -1.0, \"BALANCED (Default - Training Match)\"),\n",
    "    (16, 1.5, -1.0, \"FAST (R√°pido)\"),\n",
    "    (48, 2.5, -1.0, \"HIGH_QUALITY (Alta Qualidade)\"),\n",
    "    (64, 2.0, -1.0, \"ULTRA_QUALITY (Qualidade M√°xima)\"),\n",
    "]\n",
    "\n",
    "results = []\n",
    "for nfe, cfg, sway, label in configs:\n",
    "    audio_test, sr_test, file_path = generate_with_params(nfe, cfg, sway, label)\n",
    "    results.append((label, audio_test, sr_test, file_path))\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"‚úÖ Testes conclu√≠dos! Reproduza abaixo para comparar:\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec54fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Play all test results\n",
    "for label, audio_test, sr_test, file_path in results:\n",
    "    print(f\"\\nüîä {label}\")\n",
    "    print(f\"   üìÅ {file_path.name}\")\n",
    "    display(Audio(audio_test, rate=sr_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe0c43f",
   "metadata": {},
   "source": [
    "## 12. Exportar para MP3 (Opcional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e49785",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from pydub import AudioSegment\n",
    "    \n",
    "    # Convert main output to MP3\n",
    "    mp3_path = output_path.with_suffix('.mp3')\n",
    "    audio_segment = AudioSegment.from_wav(str(output_path))\n",
    "    audio_segment.export(str(mp3_path), format='mp3', bitrate='192k')\n",
    "    \n",
    "    print(f\"‚úÖ MP3 exportado: {mp3_path}\")\n",
    "    print(f\"üìä Tamanho WAV: {output_path.stat().st_size / 1024:.1f} KB\")\n",
    "    print(f\"üìä Tamanho MP3: {mp3_path.stat().st_size / 1024:.1f} KB\")\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"‚ö†Ô∏è  pydub n√£o instalado. Para exportar MP3:\")\n",
    "    print(\"   pip install pydub\")\n",
    "    print(\"   Tamb√©m precisa do ffmpeg instalado no sistema\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f215ca7",
   "metadata": {},
   "source": [
    "## 13. Resumo e Pr√≥ximos Passos\n",
    "\n",
    "### ‚úÖ O que fizemos neste notebook:\n",
    "\n",
    "1. ‚úÖ Carregamos o modelo F5-TTS fine-tuned customizado\n",
    "2. ‚úÖ Geramos √°udio com voz clonada usando par√¢metros otimizados\n",
    "3. ‚úÖ Visualizamos spectrograms e waveforms\n",
    "4. ‚úÖ Analisamos m√©tricas de qualidade de √°udio\n",
    "5. ‚úÖ Comparamos com samples do treinamento\n",
    "6. ‚úÖ Testamos diferentes configura√ß√µes de par√¢metros\n",
    "\n",
    "### üéØ Pr√≥ximos Passos:\n",
    "\n",
    "**Para testar outros textos:**\n",
    "- Volte √† c√©lula 5 e mude o `gen_text`\n",
    "- Execute novamente a partir da c√©lula 6\n",
    "\n",
    "**Para usar outra voz de refer√™ncia:**\n",
    "- Volte √† c√©lula 4 e mude o `ref_audio_path`\n",
    "- Atualize o `ref_text` com a transcri√ß√£o correta\n",
    "- Re-execute a partir da c√©lula 6\n",
    "\n",
    "**Para ajustar qualidade vs velocidade:**\n",
    "- Experimente diferentes valores na c√©lula 11\n",
    "- `nfe_step=16`: R√°pido mas menor qualidade\n",
    "- `nfe_step=32`: Padr√£o (match com treinamento)\n",
    "- `nfe_step=64`: Qualidade m√°xima mas mais lento\n",
    "\n",
    "### üìö Documenta√ß√£o:\n",
    "\n",
    "- **Par√¢metros F5-TTS:** `docs/F5TTS_QUALITY_FIX.md`\n",
    "- **Profiles de Qualidade:** `app/quality_profiles.py`\n",
    "- **Training Samples:** `train/output/ptbr_finetuned2/samples/`\n",
    "\n",
    "### üêõ Troubleshooting:\n",
    "\n",
    "**Se o √°udio tiver artefatos:**\n",
    "- Verifique se `sway_sampling_coef=-1.0` (n√£o use valores positivos!)\n",
    "- Tente aumentar `nfe_step` para 48 ou 64\n",
    "- Certifique-se que `ref_text` √© a transcri√ß√£o EXATA do √°udio de refer√™ncia\n",
    "\n",
    "**Se estiver muito lento:**\n",
    "- Reduza `nfe_step` para 16 ou 24\n",
    "- Use GPU se dispon√≠vel (device='cuda')\n",
    "\n",
    "**Se a voz n√£o est√° sendo clonada bem:**\n",
    "- Use √°udio de refer√™ncia de 10-30 segundos\n",
    "- Forne√ßa transcri√ß√£o exata (`ref_text`)\n",
    "- Certifique-se que o √°udio tem boa qualidade (sem ru√≠do)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
