# ğŸš€ Scripts de SegmentaÃ§Ã£o de Ãudio - Guia RÃ¡pido

## ğŸ“ Arquivos DisponÃ­veis

| Script | Uso | RAM | Velocidade |
|--------|-----|-----|------------|
| `prepare_segments.py` | âŒ Deprecated | 27 GB | Lento |
| `prepare_segments_optimized.py` | âœ… V2 | 400 MB | MÃ©dio |
| **`prepare_segments_v2.py`** | â­ **V3 RECOMENDADO** | **185 MB** | **RÃ¡pido** |

---

## âš¡ Quick Start

### Processamento BÃ¡sico (V3)

```bash
# Processamento sequencial (economiza RAM)
python3 -m train.scripts.prepare_segments_v2

# Processamento paralelo (4 cores)
python3 -m train.scripts.prepare_segments_v2 --parallel --workers 4
```

### Comparar VersÃµes

```bash
# Benchmark V2 vs V3
python3 train/scripts/benchmark_segmentation.py

# Comparar resultados
python3 train/scripts/migrate_segmentation.py --compare --validate --report migration_report.md
```

---

## ğŸ“Š Quando Usar Cada VersÃ£o

### Use V2 (`prepare_segments_optimized.py`) se:
- Arquivo pequeno (<30 minutos)
- RAM disponÃ­vel > 2GB
- Quer cÃ³digo mais simples

### Use V3 (`prepare_segments_v2.py`) se: â­
- Arquivo grande (>1 hora)
- Muitos arquivos para processar
- RAM limitada (<2GB)
- Quer processamento paralelo
- Arquivo maior que RAM disponÃ­vel

---

## ğŸ› ï¸ Troubleshooting

### Problema: "Out of Memory"

**V2:**
```yaml
# dataset_config.yaml
segmentation:
  vad_chunk_duration: 15.0  # Reduzir de 30s
```

**V3:**
```bash
# Desabilitar normalizaÃ§Ã£o pesada
# Editar dataset_config.yaml:
audio:
  normalize_audio: false
```

### Problema: Muito Lento

```bash
# Use processamento paralelo
python3 -m train.scripts.prepare_segments_v2 --parallel --workers 8

# Ou aumente chunk size (usa mais RAM mas Ã© mais rÃ¡pido)
# dataset_config.yaml:
# vad_chunk_duration: 60.0
```

### Problema: Segmentos Muito Pequenos

```yaml
# dataset_config.yaml
segmentation:
  min_duration: 5.0        # Aumentar mÃ­nimo
  vad_threshold: -35       # Menos sensÃ­vel (era -40)
  min_silence_duration: 1.0  # Mais silÃªncio necessÃ¡rio
```

---

## ğŸ“– DocumentaÃ§Ã£o Completa

- **Guia de OtimizaÃ§Ã£o:** `OPTIMIZATION_GUIDE.md`
- **README do Training:** `../README.md`
- **Config:** `../config/dataset_config.yaml`

---

## ğŸ”¬ ValidaÃ§Ã£o

```bash
# Validar integridade dos segmentos
python3 train/scripts/migrate_segmentation.py --validate

# Comparar V2 vs V3
python3 train/scripts/migrate_segmentation.py --compare
```

---

## ğŸ’¡ Dicas

1. **Sempre faÃ§a backup** antes de processar arquivos grandes
2. **Teste com 1 arquivo** antes de processar tudo
3. **Use --parallel** apenas se tiver mÃºltiplos CPUs
4. **Monitor RAM** com `htop` durante processamento
5. **Logs** estÃ£o em `train/logs/prepare_segments_v2.log`

---

## ğŸ“ˆ Performance Esperada

**Arquivo de 2h @ 48kHz:**

| MÃ©trica | V2 | V3 (1 core) | V3 (4 cores) |
|---------|----|----|--------------|
| RAM | 420 MB | 185 MB | 680 MB |
| Tempo | 6 min | 5 min | 3 min |
| Segmentos | ~1250 | ~1250 | ~1250 |

**50 arquivos de 30 min:**

| MÃ©trica | V2 | V3 (4 cores) |
|---------|----|----|
| RAM | 1.2 GB | 680 MB |
| Tempo | 4.5h | 1.2h |
| Taxa | 11 GB/h | 42 GB/h |
