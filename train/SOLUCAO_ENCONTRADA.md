# üéØ PROBLEMA IDENTIFICADO - MODELO QUEBRADO PARA INFER√äNCIA

**Data**: 06/12/2024 13:00 PM  
**Status**: ‚ö†Ô∏è MODELO FINE-TUNED N√ÉO FUNCIONA PARA INFER√äNCIA

---

## üîç TESTES REALIZADOS

### ‚úÖ Teste 1: Modelo Pre-trained Original
```bash
Checkpoint: train/pretrained/F5-TTS-pt-br/pt-br/model_200000.pt
Resultado: 19.9% similaridade ‚ùå FALHOU
```

### ‚úÖ Teste 2: Convers√£o √Åudio‚ÜíMEL‚ÜíVocoder
```bash
Processo: audio ‚Üí model.mel_spec() ‚Üí vocoder.decode()
Transcri√ß√£o: "Vamos! E essa coisa de viagem no tempo do Lock..."
Resultado: PERFEITO ‚úÖ
```

### ‚úÖ Teste 3: model.sample() com √Åudio Raw
```bash
Par√¢metros: cond=audio, text=duplicated, duration=ref_len*2
Similaridade: 3.6% ‚ùå FALHOU
```

### ‚úÖ Teste 4: model.sample() com MEL Direto
```bash
Par√¢metros: cond=mel_spec, text=duplicated (sem pinyin)
Similaridade: 4.9% ‚ùå FALHOU
```

---

## üí• CONCLUS√ÉO

**TODOS OS MODELOS FALHAM NA INFER√äNCIA:**
- ‚ùå Modelo fine-tuned (25400 steps)
- ‚ùå Modelo pre-trained original (200k steps)
- ‚ùå Com √°udio raw ou MEL direto
- ‚ùå Com ou sem convert_char_to_pinyin()

**MAS:**
- ‚úÖ Vocoder funciona perfeitamente
- ‚úÖ Convers√£o √°udio‚ÜíMEL funciona
- ‚úÖ Samples do trainer s√£o PERFEITOS

---

## üß© DIFEREN√áA CR√çTICA

### O que FUNCIONA (trainer.py):
```python
self.accelerator.unwrap_model(self.model).sample(
    cond=mel_spec[0][:ref_audio_len].unsqueeze(0),
    text=infer_text,
    ...
)
```

### O que FALHA (infer_process):
```python
model_obj.sample(
    cond=audio,  # ou mel_spec
    text=final_text_list,
    ...
)
```

**HIP√ìTESE PRINCIPAL:**
O problema est√° no **Accelerator wrapping** ou na **forma como o modelo √© carregado**.

---

## üì¶ CHECKPOINT ANALYSIS

```
Checkpoint: model_25400.pt
- model_state_dict: 364 items
- ema_model_state_dict: 366 items (2 extras: "initted", "step")
- optimizer_state_dict: 2 items
- scheduler_state_dict: 4 items
```

**Modelo EMA carregado corretamente:**
```python
# load_checkpoint() com use_ema=True:
checkpoint["model_state_dict"] = {
    k.replace("ema_model.", ""): v
    for k, v in checkpoint["ema_model_state_dict"].items()
    if k not in ["initted", "step"]
}
model.load_state_dict(checkpoint["model_state_dict"])
```

---

## üéØ PR√ìXIMOS PASSOS RECOMENDADOS

### Op√ß√£o A: Testar SEM Accelerator (Mais Prov√°vel)

Criar script que carrega modelo EXATAMENTE como trainer, mas SEM treinar:

```python
from accelerate import Accelerator
from f5_tts.model import DiT, CFM
import torch

# Setup accelerator
accelerator = Accelerator()

# Cria modelo
model = CFM(...)
checkpoint = torch.load('model_25400.pt')
model.load_state_dict(checkpoint['ema_model_state_dict'])

# Wrap com accelerator
model = accelerator.prepare(model)

# Gera como trainer faz
generated, _ = accelerator.unwrap_model(model).sample(...)
```

### Op√ß√£o B: Verificar Vocab/Tokenizer

O trainer pode estar usando vocab diferente do infer_process:

```bash
# Verificar vocab usado no treinamento
cat train/data/f5_dataset/vocab.txt

# Comparar com vocab do infer
cat /root/.local/lib/python3.11/site-packages/f5_tts/infer/examples/vocab.txt
```

### Op√ß√£o C: Testar Checkpoint Anterior

```bash
# Testar com checkpoint 25200
python3 train/test.py --checkpoint model_25200.pt
```

### Op√ß√£o D: Reportar Bug na F5-TTS

Se nenhuma solu√ß√£o funcionar, √© prov√°vel que seja um bug na biblioteca.

---

## üö® RESUMO EXECUTIVO

**O modelo fine-tuned N√ÉO funciona para infer√™ncia via `infer_process()`, e o modelo pre-trained TAMB√âM falha.**

Isso indica que:
1. ‚ùå N√ÉO √© problema do fine-tuning
2. ‚ùå N√ÉO √© problema do checkpoint
3. ‚ùå N√ÉO √© problema do vocoder
4. ‚ùå N√ÉO √© problema de texto/MEL

**Poss√≠vel causa:**
- Diferen√ßa fundamental entre como trainer.py gera samples vs como infer_process gera
- Prov√°vel: **Accelerator wrapping** altera comportamento do modelo
- Alternativa: **Vocab/tokenizer diferente** entre train e infer

**Recomenda√ß√£o:**
1. Testar Op√ß√£o A (Accelerator)
2. Se falhar, reportar bug na F5-TTS
