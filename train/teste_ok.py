#!/usr/bin/env python3
"""
TESTE OK - Processo que FUNCIONA PERFEITAMENTE
===============================================

Este script demonstra o que ESTÃ FUNCIONANDO:
- âœ… ExtraÃ§Ã£o de MEL spectrogram do modelo fine-tuned
- âœ… ReconstruÃ§Ã£o de Ã¡udio pelo Vocoder
- âœ… Qualidade de Ã¡udio perfeita

O que NÃƒO estÃ¡ incluÃ­do aqui (e que estÃ¡ quebrado):
- âŒ GeraÃ§Ã£o de novo Ã¡udio via model.sample()
- âŒ InferÃªncia com texto customizado

Este Ã© apenas um teste de validaÃ§Ã£o do pipeline vocoder.
"""

from f5_tts.infer.utils_infer import load_model, load_vocoder
from f5_tts.model import DiT
import torch
import torchaudio
import argparse

def main():
    parser = argparse.ArgumentParser(description="Teste do pipeline que FUNCIONA")
    parser.add_argument("--audio", required=True, help="Arquivo de Ã¡udio de entrada")
    parser.add_argument("--checkpoint", default="train/output/ptbr_finetuned2/model_25400.pt",
                       help="Checkpoint do modelo")
    parser.add_argument("--output", default="train/teste_ok_output.wav",
                       help="Arquivo de saÃ­da")
    args = parser.parse_args()

    print("=" * 80)
    print("ğŸ§ª TESTE OK - Pipeline que FUNCIONA")
    print("=" * 80)
    
    # ConfiguraÃ§Ã£o do modelo
    model_cfg = dict(
        dim=1024,
        depth=22,
        heads=16,
        ff_mult=2,
        text_dim=512,
        conv_layers=4
    )
    
    print(f"\nğŸ“¦ Carregando modelo: {args.checkpoint}")
    model = load_model(
        DiT,
        model_cfg,
        args.checkpoint,
        mel_spec_type='vocos',
        vocab_file='',
        ode_method='euler',
        use_ema=True,
        device='cuda'
    )
    
    print("ğŸ“¦ Carregando vocoder...")
    vocoder = load_vocoder(vocoder_name="vocos", is_local=False, local_path="")
    
    # Carrega Ã¡udio
    print(f"\nğŸ”Š Carregando Ã¡udio: {args.audio}")
    audio, sr = torchaudio.load(args.audio)
    
    # Preprocessamento
    if audio.shape[0] > 1:
        print("   â†’ Convertendo para mono")
        audio = torch.mean(audio, dim=0, keepdim=True)
    
    if sr != 24000:
        print(f"   â†’ Resampling de {sr}Hz para 24000Hz")
        resampler = torchaudio.transforms.Resample(sr, 24000)
        audio = resampler(audio)
    
    audio = audio.cuda()
    print(f"   âœ… Ãudio shape: {audio.shape}")
    
    # PROCESSO QUE FUNCIONA: Ã¡udio â†’ MEL â†’ Ã¡udio
    print("\nğŸ”„ Executando pipeline:")
    print("   1. Extraindo MEL spectrogram...")
    
    with torch.no_grad():
        # Extrai MEL usando modelo fine-tuned
        mel = model.mel_spec(audio)
        mel = mel.permute(0, 2, 1)
        print(f"      âœ… MEL shape: {mel.shape}")
        
        # ReconstrÃ³i Ã¡udio do MEL
        print("   2. Reconstruindo Ã¡udio com vocoder...")
        mel_for_vocoder = mel.permute(0, 2, 1)
        audio_reconstructed = vocoder.decode(mel_for_vocoder)
        print(f"      âœ… Ãudio reconstruÃ­do: {audio_reconstructed.shape}")
    
    # Salva resultado
    print(f"\nğŸ’¾ Salvando em: {args.output}")
    torchaudio.save(args.output, audio_reconstructed.cpu(), 24000)
    
    print("\n" + "=" * 80)
    print("âœ… SUCESSO!")
    print("=" * 80)
    print("\nğŸ“Š O que foi testado:")
    print("   âœ… ExtraÃ§Ã£o de MEL spectrogram (model.mel_spec)")
    print("   âœ… Vocoder (vocos.decode)")
    print("   âœ… Pipeline completo de reconstruÃ§Ã£o")
    print("\nâš ï¸ O que NÃƒO foi testado:")
    print("   âŒ GeraÃ§Ã£o de novo Ã¡udio (model.sample)")
    print("   âŒ SÃ­ntese com texto customizado")
    print("\nğŸ’¡ Para testar sÃ­ntese de texto, use: train/infer_como_trainer.py")
    print()

if __name__ == "__main__":
    main()
