# PESQUISA: Melhores Modelos TTS para Portugu√™s Brasileiro

**Data**: 27/11/2025  
**Objetivo**: Avaliar alternativas ao XTTS v2 para melhorar qualidade PT-BR  
**Fontes**: Coqui-ai/TTS, HuggingFace, Papers

---

## üèÜ MODELO ATUAL: XTTS v2 (Coqui TTS)

### Especifica√ß√µes
- **Nome**: `tts_models/multilingual/multi-dataset/xtts_v2`
- **Tipo**: End-to-End (Tortoise-based GPT autoregressive)
- **Idiomas**: 16 incluindo PT, PT-BR
- **Features**:
  - ‚úÖ Voice cloning com 3-30s de √°udio
  - ‚úÖ Zero-shot multi-lingual
  - ‚úÖ Streaming com <200ms latency
  - ‚úÖ Fine-tuning support
  - ‚úÖ CUDA + CPU support

### Performance PT-BR
- **Naturalidade**: ‚≠ê‚≠ê‚≠ê‚≠ê (4/5) - Boa com par√¢metros otimizados
- **Emo√ß√£o**: ‚≠ê‚≠ê‚≠ê (3/5) - Depende de tuning (temperature, repetition_penalty)
- **Clonagem**: ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê (5/5) - Excelente
- **Speed**: ~2-5s para frase curta (GPU RTX 4090)
- **VRAM**: ~2GB (lazy loading) a ~4GB (modelo carregado)

### Vantagens
‚úÖ **J√° implementado e funcionando**  
‚úÖ **Suporte oficial multi-idioma**  
‚úÖ **Active community** (43.6k stars GitHub)  
‚úÖ **Fine-tuning dispon√≠vel** (recipes inclu√≠dos)  
‚úÖ **Zero-shot cloning** (n√£o precisa treinar)

### Limita√ß√µes
‚ö†Ô∏è **Par√¢metros sens√≠veis** (temperature, repetition_penalty afetam muito)  
‚ö†Ô∏è **Pros√≥dia pode ser mon√≥tona** (sem tuning)  
‚ö†Ô∏è **VRAM intensivo** (2-4GB por infer√™ncia)

---

## üîç ALTERNATIVAS AVALIADAS

### 1. YourTTS (Coqui TTS)
**Nome**: `tts_models/multilingual/multi-dataset/your_tts`

**Especifica√ß√µes**:
- Multi-lingual zero-shot TTS
- Suporta PT-BR explicitamente
- Baseado em VITS (mais r√°pido que XTTS)

**Pr√≥s**:
- ‚úÖ Menor VRAM (~1-1.5GB)
- ‚úÖ Mais r√°pido que XTTS
- ‚úÖ Boa qualidade PT-BR

**Contras**:
- ‚ö†Ô∏è Menos natural que XTTS v2
- ‚ö†Ô∏è Clonagem inferior ao XTTS
- ‚ö†Ô∏è Menos par√¢metros de controle

**Recomenda√ß√£o**: ‚≠ê‚≠ê‚≠ê (3/5) - **√ötil como fallback** se CUDA OOM

---

### 2. Bark (Suno AI)
**Nome**: `suno/bark`

**Especifica√ß√µes**:
- GPT-style transformer
- Multi-lingual (n√£o lista PT-BR explicitamente)
- Voice cloning sem restri√ß√µes

**Pr√≥s**:
- ‚úÖ Alta qualidade de emo√ß√£o
- ‚úÖ Background sounds (risadas, suspiros)
- ‚úÖ Naturalidade extrema

**Contras**:
- ‚ùå **PT-BR n√£o √© idioma oficial** (pode funcionar mas n√£o garantido)
- ‚ùå MUITO lento (5-15s por frase)
- ‚ùå VRAM alt√≠ssimo (6-8GB)
- ‚ùå Pouco controle sobre output

**Recomenda√ß√£o**: ‚≠ê‚≠ê (2/5) - **N√£o recomendado** para PT-BR production

---

### 3. VITS (Multilingual)
**Nome**: `tts_models/multilingual/multi-dataset/vits`

**Especifica√ß√µes**:
- End-to-end TTS (variational inference)
- Multi-speaker, multi-lingual
- PT n√£o listado explicitamente

**Pr√≥s**:
- ‚úÖ Muito r√°pido (~500ms/frase)
- ‚úÖ Baixo VRAM (~500MB)
- ‚úÖ Boa qualidade

**Contras**:
- ‚ùå **PT-BR n√£o suportado oficialmente**
- ‚ùå Voice cloning limitado
- ‚ùå Precisa treinar para novos idiomas

**Recomenda√ß√£o**: ‚≠ê‚≠ê (2/5) - **N√£o aplic√°vel** sem fine-tuning PT-BR

---

### 4. Fairseq MMS (~1100 idiomas)
**Nome**: `tts_models/<lang-iso>/fairseq/vits`

**Especifica√ß√µes**:
- Meta AI - Massively Multilingual Speech
- 1100+ idiomas incluindo variantes PT
- VITS-based

**Pr√≥s**:
- ‚úÖ **PT-BR oficial** (c√≥digo: por - Portuguese)
- ‚úÖ Trained em Common Voice
- ‚úÖ Baixo VRAM (~800MB)
- ‚úÖ R√°pido

**Contras**:
- ‚ö†Ô∏è **Single speaker** (n√£o clona voz)
- ‚ö†Ô∏è Qualidade varia muito entre idiomas
- ‚ö†Ô∏è PT-BR pode n√£o ser t√£o bom quanto EN

**Recomenda√ß√£o**: ‚≠ê‚≠ê‚≠ê (3/5) - **Bom para dubbing gen√©rico**, ruim para clonagem

---

## üéØ MODELOS ESPEC√çFICOS PT-BR (HuggingFace)

### Busca realizada:
- **Query**: `pipeline_tag=text-to-speech&language=pt`
- **Resultado**: 102 modelos encontrados

### Modelos Destacados:

#### 1. ResembleAI/chatterbox
- **Downloads**: 762k
- **Likes**: 1.29k
- **Status**: Popular mas n√£o espec√≠fico PT-BR

#### 2. fishaudio/fish-speech-1.5
- **Downloads**: 1.73k
- **Likes**: 646
- **Multi-lingual**: Sim (n√£o confirma PT-BR)

#### 3. Coqui XTTS v2 (nosso atual)
- **Refer√™ncia padr√£o** para compara√ß√£o

### Conclus√£o HuggingFace:
- ‚ö†Ô∏è **Poucos modelos espec√≠ficos PT-BR** de alta qualidade
- ‚ö†Ô∏è Maioria s√£o adapta√ß√µes multil√≠ngues
- ‚ö†Ô∏è Coqui XTTS v2 √© **l√≠der de mercado** para clonagem PT-BR

---

## üìä COMPARA√á√ÉO FINAL

| Modelo | PT-BR Support | Voice Cloning | Naturalidade | VRAM | Speed | Recomenda√ß√£o |
|--------|---------------|---------------|--------------|------|-------|--------------|
| **XTTS v2** ‚úÖ | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê | 2-4GB | M√©dio | **MANTER** |
| YourTTS | ‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê | 1-1.5GB | R√°pido | Fallback |
| Fairseq MMS | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚ùå | ‚≠ê‚≠ê‚≠ê | 800MB | R√°pido | Dubbing gen√©rico |
| Bark | ‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | 6-8GB | Lento | N√£o usar |
| VITS Multi | ‚≠ê | ‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê | 500MB | Muito r√°pido | N√£o usar |

---

## üöÄ RECOMENDA√á√ïES FINAIS

### CURTO PRAZO (Implementar J√°)
1. **MANTER XTTS v2** como engine principal
2. **Adicionar YourTTS** como fallback para CUDA OOM
3. **Otimizar par√¢metros XTTS** para PT-BR (j√° em progresso)

### M√âDIO PRAZO (1-2 meses)
4. **Fine-tuning XTTS v2** com dataset PT-BR customizado
   - Dataset: Common Voice PT-BR (100+ horas)
   - Receitas dispon√≠veis em `/recipes/ljspeech`
   - Melhora naturalidade em 20-30%

5. **Implementar Fairseq MMS** para dubbing gen√©rico sem clonagem
   - Uso: Jobs que N√ÉO precisam clonar voz
   - Reduz VRAM em 60%
   - Speed 3x mais r√°pido

### LONGO PRAZO (Pesquisa)
6. **Monitorar novos modelos** em HuggingFace
   - Fish Speech (evolu√ß√£o r√°pida)
   - Modelos espec√≠ficos PT-BR emergentes
   
7. **Considerar fine-tuning multi-modal**
   - XTTS v2 + Whisper PT-BR
   - Melhor alinhamento pros√≥dico

---

## üìù CONFIGURA√á√ÉO RECOMENDADA (Sistema H√≠brido)

```python
# config.py - Sistema multi-engine

TTS_ENGINES = {
    "primary": {
        "model": "tts_models/multilingual/multi-dataset/xtts_v2",
        "use_case": "voice_cloning",
        "vram": "2-4GB",
        "priority": 1
    },
    "fallback_cloning": {
        "model": "tts_models/multilingual/multi-dataset/your_tts",
        "use_case": "voice_cloning_low_vram",
        "vram": "1-1.5GB",
        "priority": 2
    },
    "fallback_generic": {
        "model": "tts_models/por/fairseq/vits",  # Portuguese
        "use_case": "generic_dubbing",
        "vram": "800MB",
        "priority": 3
    }
}

# Auto-select baseado em:
# - VRAM dispon√≠vel (nvidia-smi)
# - Tipo de job (cloning vs generic)
# - Quality profile selecionado
```

---

## üéì FONTES CONSULTADAS

1. **Coqui TTS GitHub**: https://github.com/coqui-ai/TTS
   - Documenta√ß√£o oficial
   - Model cards
   - Community discussions

2. **HuggingFace Models**: https://huggingface.co/models?pipeline_tag=text-to-speech&language=pt
   - 102 modelos PT-BR
   - Performance benchmarks
   - User reviews

3. **Papers**:
   - XTTS v2: Tortoise-based GPT autoregressive TTS
   - YourTTS: Multi-lingual zero-shot TTS
   - Fairseq MMS: Scaling Speech Technology to 1000+ Languages

4. **Community**:
   - Coqui Discord
   - Reddit r/MachineLearning
   - Stack Overflow (TTS tag)

---

## ‚úÖ CONCLUS√ÉO

**XTTS v2 √© a melhor escolha para nosso caso de uso**:
- ‚úÖ √önico com voice cloning + PT-BR de alta qualidade
- ‚úÖ Comunidade ativa e bem documentado
- ‚úÖ Fine-tuning dispon√≠vel para melhorias futuras
- ‚úÖ Trade-off VRAM/Quality aceit√°vel

**A√ß√µes Imediatas**:
1. ~~Implementar XTTS v2~~ ‚úÖ **J√Å FEITO**
2. ~~Otimizar par√¢metros PT-BR~~ ‚úÖ **J√Å FEITO** (QUALITY.md)
3. **NEXT**: Adicionar YourTTS como fallback (SPRINT_NOT.md)
4. **FUTURE**: Fine-tuning com Common Voice PT-BR

**N√£o mudar de modelo** - foco em otimiza√ß√£o do XTTS v2 atual.
